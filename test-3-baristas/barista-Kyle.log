********************************************************************************
product = Open Liberty 19.0.0.11 (wlp-1.0.34.cl191120191031-0300)
wlp.install.dir = /opt/ol/wlp/
server.output.dir = /opt/ol/wlp/output/defaultServer/
java.home = /opt/java/openjdk
java.version = 1.8.0_232
java.runtime = OpenJDK Runtime Environment (1.8.0_232-b09)
os = Linux (4.19.76; amd64) (en_US)
process = 11@172.17.0.13
trace.specification = *=info:REACTIVEMESSAGE=all:me.escoffier.quarkus.coffeeshop.*=all:org.apache.kafka.*=all
********************************************************************************
[12/16/19 14:02:51:952 GMT] 00000022 id=00000000 com.ibm.ws.logging.internal.TraceSpecification               I TRAS0018I: The trace state has been changed. The new trace state is *=info:REACTIVEMESSAGE=all:me.escoffier.quarkus.coffeeshop.*=all:org.apache.kafka.*=all.
[12/16/19 14:02:53:304 GMT] 00000001 id=00000000 com.ibm.ws.kernel.launch.internal.FrameworkManager           I CWWKE0002I: The kernel started after 4.645 seconds
[12/16/19 14:02:55:657 GMT] 00000027 id=00000000 com.ibm.ws.kernel.feature.internal.FeatureManager            I CWWKF0007I: Feature update started.
[12/16/19 14:03:04:585 GMT] 00000027 id=8002a777 bm.websphere.org.eclipse.microprofile.reactive.messaging.1.0 1 BundleEvent INSTALLED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.websphere.org.eclipse.microprofile.reactive.messaging.1.0
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.websphere.org.eclipse.microprofile.reactive.messaging.1.0_1.0.34.cl191120191031-0300 [109]]
[12/16/19 14:03:04:873 GMT] 00000027 id=1e565341 om.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl 1 BundleEvent INSTALLED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl_1.0.34.cl191120191031-0300 [110]]
[12/16/19 14:03:05:043 GMT] 00000027 id=7bd29141 112-com.ibm.ws.microprofile.reactive.messaging.kafka.adapter 1 BundleEvent INSTALLED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka.adapter
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka.adapter_1.0.34.cl191120191031-0300 [112]]
[12/16/19 14:03:05:133 GMT] 00000027 id=49d5d84d LogService-113-com.ibm.ws.io.smallrye.reactive.messaging     1 BundleEvent INSTALLED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.io.smallrye.reactive.messaging
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.io.smallrye.reactive.messaging_1.0.34.cl191120191031-0300 [113]]
[12/16/19 14:03:05:227 GMT] 00000027 id=28165a04 Service-114-com.ibm.ws.microprofile.reactive.messaging.kafka 1 BundleEvent INSTALLED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka_1.0.34.cl191120191031-0300 [114]]
[12/16/19 14:03:15:766 GMT] 00000027 id=8002a777 bm.websphere.org.eclipse.microprofile.reactive.messaging.1.0 1 BundleEvent RESOLVED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.websphere.org.eclipse.microprofile.reactive.messaging.1.0
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.websphere.org.eclipse.microprofile.reactive.messaging.1.0_1.0.34.cl191120191031-0300 [109]]
[12/16/19 14:03:15:770 GMT] 00000027 id=1e565341 om.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl 1 BundleEvent RESOLVED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl_1.0.34.cl191120191031-0300 [110]]
[12/16/19 14:03:15:773 GMT] 00000027 id=7bd29141 112-com.ibm.ws.microprofile.reactive.messaging.kafka.adapter 1 BundleEvent RESOLVED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka.adapter
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka.adapter_1.0.34.cl191120191031-0300 [112]]
[12/16/19 14:03:15:790 GMT] 00000027 id=49d5d84d LogService-113-com.ibm.ws.io.smallrye.reactive.messaging     1 BundleEvent RESOLVED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.io.smallrye.reactive.messaging
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.io.smallrye.reactive.messaging_1.0.34.cl191120191031-0300 [113]]
[12/16/19 14:03:15:820 GMT] 00000027 id=28165a04 Service-114-com.ibm.ws.microprofile.reactive.messaging.kafka 1 BundleEvent RESOLVED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka_1.0.34.cl191120191031-0300 [114]]
[12/16/19 14:03:26:930 GMT] 0000002c id=00000000 AnnotationCacheServiceImpl_Service                           I getOsgiWorkArea OSGi Work Path [ /opt/ol/wlp/output/defaultServer/workarea/org.eclipse.osgi/44/data ]
[12/16/19 14:03:28:244 GMT] 0000002d id=00000000 com.ibm.ws.app.manager.internal.monitor.DropinMonitor        A CWWKZ0058I: Monitoring dropins for applications.
[12/16/19 14:03:32:099 GMT] 00000029 id=00000000 com.ibm.ws.tcpchannel.internal.TCPChannel                    I CWWKO0219I: TCP Channel defaultHttpEndpoint has been started and is now listening for requests on host *  (IPv4) port 8090.
[12/16/19 14:03:34:945 GMT] 0000001c id=8002a777 bm.websphere.org.eclipse.microprofile.reactive.messaging.1.0 1 BundleEvent STARTING 
                                                                                                               LoggerName:Events.Bundle.com.ibm.websphere.org.eclipse.microprofile.reactive.messaging.1.0
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.websphere.org.eclipse.microprofile.reactive.messaging.1.0_1.0.34.cl191120191031-0300 [109]]
[12/16/19 14:03:34:951 GMT] 0000001c id=8002a777 bm.websphere.org.eclipse.microprofile.reactive.messaging.1.0 1 BundleEvent STARTED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.websphere.org.eclipse.microprofile.reactive.messaging.1.0
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.websphere.org.eclipse.microprofile.reactive.messaging.1.0_1.0.34.cl191120191031-0300 [109]]
[12/16/19 14:03:34:975 GMT] 0000001c id=1e565341 om.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl 1 BundleEvent STARTING 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl_1.0.34.cl191120191031-0300 [110]]
[12/16/19 14:03:34:989 GMT] 0000001c id=1e565341 om.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl 1 BundleEvent STARTED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl_1.0.34.cl191120191031-0300 [110]]
[12/16/19 14:03:35:045 GMT] 0000001c id=1e565341 om.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl 1 ServiceEvent REGISTERED 
                                                                                                               LoggerName:Events.Service.com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl
                                                                                                               ServiceRef:[com.ibm.wsspi.classloading.ResourceProvider](id=338, pid=null)
                                                                                                               Event:org.osgi.framework.ServiceEvent[source={com.ibm.wsspi.classloading.ResourceProvider}={resources=${app-resources}, service.id=338, service.bundleid=110, service.scope=bundle, component.name=com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl_1_0.ResourceProvider, component.id=261}]
[12/16/19 14:03:35:086 GMT] 0000001c id=7bd29141 112-com.ibm.ws.microprofile.reactive.messaging.kafka.adapter 1 BundleEvent STARTING 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka.adapter
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka.adapter_1.0.34.cl191120191031-0300 [112]]
[12/16/19 14:03:35:102 GMT] 0000001c id=7bd29141 112-com.ibm.ws.microprofile.reactive.messaging.kafka.adapter 1 BundleEvent STARTED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka.adapter
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka.adapter_1.0.34.cl191120191031-0300 [112]]
[12/16/19 14:03:35:142 GMT] 0000001c id=7bd29141 112-com.ibm.ws.microprofile.reactive.messaging.kafka.adapter 1 ServiceEvent REGISTERED 
                                                                                                               LoggerName:Events.Service.com.ibm.ws.microprofile.reactive.messaging.kafka.adapter
                                                                                                               ServiceRef:[com.ibm.wsspi.classloading.ResourceProvider](id=339, pid=null)
                                                                                                               Event:org.osgi.framework.ServiceEvent[source={com.ibm.wsspi.classloading.ResourceProvider}={resources=${app-resources}, service.id=339, service.bundleid=112, service.scope=bundle, component.name=com.ibm.ws.microprofile.reactive.messaging.kafka.adapter_1_0.ResourceProvider, component.id=262}]
[12/16/19 14:03:35:146 GMT] 0000001c id=49d5d84d LogService-113-com.ibm.ws.io.smallrye.reactive.messaging     1 BundleEvent STARTING 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.io.smallrye.reactive.messaging
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.io.smallrye.reactive.messaging_1.0.34.cl191120191031-0300 [113]]
[12/16/19 14:03:35:148 GMT] 0000001c id=49d5d84d LogService-113-com.ibm.ws.io.smallrye.reactive.messaging     1 BundleEvent STARTED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.io.smallrye.reactive.messaging
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.io.smallrye.reactive.messaging_1.0.34.cl191120191031-0300 [113]]
[12/16/19 14:03:35:154 GMT] 0000001c id=49d5d84d LogService-113-com.ibm.ws.io.smallrye.reactive.messaging     1 ServiceEvent REGISTERED 
                                                                                                               LoggerName:Events.Service.com.ibm.ws.io.smallrye.reactive.messaging
                                                                                                               ServiceRef:[com.ibm.ws.cdi.extension.WebSphereCDIExtension](id=340, pid=null)
                                                                                                               Event:org.osgi.framework.ServiceEvent[source={com.ibm.ws.cdi.extension.WebSphereCDIExtension}={application.bdas.visible=true, service.id=340, service.bundleid=113, service.scope=bundle, service.vendor=IBM, component.name=com.ibm.ws.microprofile.reactive.messaging.OLReactiveMessagingExtension, component.id=263}]
[12/16/19 14:03:35:160 GMT] 0000001c id=28165a04 Service-114-com.ibm.ws.microprofile.reactive.messaging.kafka 1 BundleEvent STARTING 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka_1.0.34.cl191120191031-0300 [114]]
[12/16/19 14:03:35:163 GMT] 0000001c id=28165a04 Service-114-com.ibm.ws.microprofile.reactive.messaging.kafka 1 BundleEvent STARTED 
                                                                                                               LoggerName:Events.Bundle.com.ibm.ws.microprofile.reactive.messaging.kafka
                                                                                                               Event:org.osgi.framework.BundleEvent[source=com.ibm.ws.microprofile.reactive.messaging.kafka_1.0.34.cl191120191031-0300 [114]]
[12/16/19 14:03:35:173 GMT] 0000001c id=28165a04 Service-114-com.ibm.ws.microprofile.reactive.messaging.kafka 1 ServiceEvent REGISTERED 
                                                                                                               LoggerName:Events.Service.com.ibm.ws.microprofile.reactive.messaging.kafka
                                                                                                               ServiceRef:[com.ibm.wsspi.classloading.ResourceProvider](id=341, pid=null)
                                                                                                               Event:org.osgi.framework.ServiceEvent[source={com.ibm.wsspi.classloading.ResourceProvider}={resources=${app-resources}, service.id=341, service.bundleid=114, service.scope=bundle, component.name=com.ibm.ws.microprofile.reactive.messaging.kafka_1_0.ResourceProvider, component.id=264}]
[12/16/19 14:03:35:179 GMT] 0000001c id=28165a04 Service-114-com.ibm.ws.microprofile.reactive.messaging.kafka 1 ServiceEvent REGISTERED 
                                                                                                               LoggerName:Events.Service.com.ibm.ws.microprofile.reactive.messaging.kafka
                                                                                                               ServiceRef:[com.ibm.ws.cdi.extension.WebSphereCDIExtension](id=342, pid=null)
                                                                                                               Event:org.osgi.framework.ServiceEvent[source={com.ibm.ws.cdi.extension.WebSphereCDIExtension}={service.id=342, service.bundleid=114, service.scope=bundle, component.name=com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaConnectorCDIExtension, component.id=265}]
[12/16/19 14:03:38:974 GMT] 00000028 id=00000000 com.ibm.ws.app.manager.AppMessageHelper                      I CWWKZ0018I: Starting application barista-kafka-1.0-SNAPSHOT.
[12/16/19 14:03:39:061 GMT] 00000028 id=00000000 bm.ws.app.manager.war.internal.WARDeployedAppInfoFactoryImpl I CWWKZ0136I: The barista-kafka-1.0-SNAPSHOT application is using the archive file at the /opt/ol/wlp/usr/servers/defaultServer/apps/barista-kafka-1.0-SNAPSHOT.war location.
[12/16/19 14:03:45:109 GMT] 00000029 id=00000000 com.ibm.ws.webcontainer.osgi.webapp.WebGroup                 I SRVE0169I: Loading Web Module: health.
[12/16/19 14:03:45:158 GMT] 00000029 id=00000000 com.ibm.ws.webcontainer.osgi.DynamicVirtualHost              I addWebApplication SRVE0250I: Web Module health has been bound to default_host.
[12/16/19 14:03:45:194 GMT] 00000029 id=00000000 com.ibm.ws.http.internal.VirtualHostImpl                     A CWWKT0016I: Web application available (default_host): http://coffee-v1-barista-kafka-7b74db8455-82cg9:8090/health/
[12/16/19 14:03:45:799 GMT] 00000029 id=00000000 SessionMgrComponentImpl                                      I initialize SESN8501I: The session manager did not find a persistent storage location; HttpSession objects will be stored in the local application server's memory.
[12/16/19 14:03:45:827 GMT] 00000037 id=00000000 SessionMgrComponentImpl                                      I initialize SESN8501I: The session manager did not find a persistent storage location; HttpSession objects will be stored in the local application server's memory.
[12/16/19 14:03:45:853 GMT] 00000037 id=00000000 SessionContextRegistryImpl                                   I getSessionContext SESN0176I: A new session context will be created for application key default_host/health
[12/16/19 14:03:45:951 GMT] 00000037 id=00000000 IDGeneratorImpl                                              I IDGeneratorImpl SESN0172I: The session manager is using the Java default SecureRandom implementation for session ID generation.
[12/16/19 14:03:47:024 GMT] 00000037 id=00000000 com.ibm.ws.webcontainer.servlet.ServletWrapper               I init SRVE0242I: [com.ibm.ws.microprofile.health.2.0] [/health] [HealthCheckReadinessServlet]: Initialization successful.
[12/16/19 14:03:47:105 GMT] 00000037 id=00000000 com.ibm.ws.webcontainer.servlet.ServletWrapper               I init SRVE0242I: [com.ibm.ws.microprofile.health.2.0] [/health] [HealthCheckServlet]: Initialization successful.
[12/16/19 14:03:47:185 GMT] 00000037 id=00000000 com.ibm.ws.webcontainer.servlet.ServletWrapper               I init SRVE0242I: [com.ibm.ws.microprofile.health.2.0] [/health] [HealthCheckLivenessServlet]: Initialization successful.
[12/16/19 14:03:50:364 GMT] 00000029 id=00000000 com.ibm.ws.webcontainer.osgi.mbeans.PluginGenerator          I SRVE9103I: A configuration file for a web server plugin was automatically generated for this server at /opt/ol/wlp/output/defaultServer/logs/state/plugin-cfg.xml.
[12/16/19 14:04:02:819 GMT] 00000028 id=00000000 org.jboss.weld.bootstrap.WeldStartup                         I <clinit> WELD-000900: 3.1.1 (Final)
[12/16/19 14:04:09:020 GMT] 0000003d id=00000000 com.ibm.ws.app.manager.AppMessageHelper                      A CWWKZ0022W: Application barista-kafka-1.0-SNAPSHOT has not started in 30.046 seconds.
[12/16/19 14:04:09:751 GMT] 00000027 id=00000000 com.ibm.ws.kernel.feature.internal.FeatureManager            A CWWKF0012I: The server installed the following features: [cdi-2.0, concurrent-1.0, jndi-1.0, json-1.0, jsonb-1.0, jsonp-1.1, mpConfig-1.3, mpHealth-2.0, mpReactiveMessaging-1.0, mpReactiveStreams-1.0, servlet-4.0].
[12/16/19 14:04:09:755 GMT] 00000027 id=00000000 com.ibm.ws.kernel.feature.internal.FeatureManager            I CWWKF0008I: Feature update completed in 76.554 seconds.
[12/16/19 14:04:09:757 GMT] 00000027 id=00000000 com.ibm.ws.kernel.feature.internal.FeatureManager            A CWWKF0011I: The defaultServer server is ready to run a smarter planet. The defaultServer server started in 81.106 seconds.
[12/16/19 14:04:09:886 GMT] 0000003d id=00000000 m.ws.microprofile.health20.internal.HealthCheck20ServiceImpl W CWMH0053W: The readiness health check reported a DOWN overall status because the following applications have not started yet: [barista-kafka-1.0-SNAPSHOT]
[12/16/19 14:04:27:981 GMT] 00000028 id=00000000 lrye.reactive.messaging.extension.ReactiveMessagingExtension I afterDeploymentValidation Analyzing mediator bean: Managed Bean [class me.escoffier.quarkus.coffeeshop.KafkaBarista] with qualifiers [@Any @Default]
[12/16/19 14:04:28:002 GMT] 00000028 id=00000000 io.smallrye.reactive.messaging.extension.MediatorManager     I analyze Scanning Type: class me.escoffier.quarkus.coffeeshop.KafkaBarista
[12/16/19 14:04:28:145 GMT] 00000028 id=00000000 io.smallrye.reactive.messaging.extension.MediatorManager     I initializeAndRun Deployment done... start processing
[12/16/19 14:04:28:215 GMT] 00000028 id=00000000 io.smallrye.reactive.messaging.impl.ConfiguredChannelFactory I <init> Found incoming connectors: []
[12/16/19 14:04:28:216 GMT] 00000028 id=00000000 io.smallrye.reactive.messaging.impl.ConfiguredChannelFactory I <init> Found outgoing connectors: []
[12/16/19 14:04:28:217 GMT] 00000028 id=00000000 io.smallrye.reactive.messaging.impl.ConfiguredChannelFactory I initialize Stream manager initializing...
[12/16/19 14:04:31:699 GMT] 00000028 id=00000000 org.apache.kafka.common.config.AbstractConfig                I logAll ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [my-cluster-kafka-bootstrap.kafka:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = baristas
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[12/16/19 14:04:31:948 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 <init> [Consumer clientId=consumer-1, groupId=baristas] Initializing the Kafka consumer
[12/16/19 14:04:33:749 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=count, group=kafka-metrics-count, description=total number of registered metrics, tags={client-id=consumer-1}]
[12/16/19 14:04:34:978 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name fetch-throttle-time
[12/16/19 14:04:34:994 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=fetch-throttle-time-avg, group=consumer-fetch-manager-metrics, description=The average throttle time in ms, tags={client-id=consumer-1}]
[12/16/19 14:04:35:003 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=fetch-throttle-time-max, group=consumer-fetch-manager-metrics, description=The maximum throttle time in ms, tags={client-id=consumer-1}]
[12/16/19 14:04:35:124 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name connections-closed:
[12/16/19 14:04:35:173 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-close-total, group=consumer-metrics, description=The total number of connections closed, tags={client-id=consumer-1}]
[12/16/19 14:04:35:181 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-close-rate, group=consumer-metrics, description=The number of connections closed per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:191 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name connections-created:
[12/16/19 14:04:35:200 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-creation-total, group=consumer-metrics, description=The total number of new connections established, tags={client-id=consumer-1}]
[12/16/19 14:04:35:221 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-creation-rate, group=consumer-metrics, description=The number of new connections established per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:222 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name successful-authentication:
[12/16/19 14:04:35:238 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-authentication-total, group=consumer-metrics, description=The total number of connections with successful authentication, tags={client-id=consumer-1}]
[12/16/19 14:04:35:252 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-authentication-rate, group=consumer-metrics, description=The number of connections with successful authentication per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:253 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name successful-reauthentication:
[12/16/19 14:04:35:257 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-reauthentication-total, group=consumer-metrics, description=The total number of successful re-authentication of connections, tags={client-id=consumer-1}]
[12/16/19 14:04:35:290 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-reauthentication-rate, group=consumer-metrics, description=The number of successful re-authentication of connections per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:291 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name successful-authentication-no-reauth:
[12/16/19 14:04:35:296 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-authentication-no-reauth-total, group=consumer-metrics, description=The total number of connections with successful authentication where the client does not support re-authentication, tags={client-id=consumer-1}]
[12/16/19 14:04:35:297 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name failed-authentication:
[12/16/19 14:04:35:325 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-authentication-total, group=consumer-metrics, description=The total number of connections with failed authentication, tags={client-id=consumer-1}]
[12/16/19 14:04:35:334 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-authentication-rate, group=consumer-metrics, description=The number of connections with failed authentication per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:334 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name failed-reauthentication:
[12/16/19 14:04:35:335 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-reauthentication-total, group=consumer-metrics, description=The total number of failed re-authentication of connections, tags={client-id=consumer-1}]
[12/16/19 14:04:35:352 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-reauthentication-rate, group=consumer-metrics, description=The number of failed re-authentication of connections per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:352 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name reauthentication-latency:
[12/16/19 14:04:35:355 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=reauthentication-latency-max, group=consumer-metrics, description=The max latency observed due to re-authentication, tags={client-id=consumer-1}]
[12/16/19 14:04:35:356 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=reauthentication-latency-avg, group=consumer-metrics, description=The average latency observed due to re-authentication, tags={client-id=consumer-1}]
[12/16/19 14:04:35:358 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name bytes-sent-received:
[12/16/19 14:04:35:359 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=network-io-total, group=consumer-metrics, description=The total number of network operations (reads or writes) on all connections, tags={client-id=consumer-1}]
[12/16/19 14:04:35:366 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=network-io-rate, group=consumer-metrics, description=The number of network operations (reads or writes) on all connections per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:366 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name bytes-sent:
[12/16/19 14:04:35:367 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-total, group=consumer-metrics, description=The total number of outgoing bytes sent to all servers, tags={client-id=consumer-1}]
[12/16/19 14:04:35:370 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-rate, group=consumer-metrics, description=The number of outgoing bytes sent to all servers per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:372 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-total, group=consumer-metrics, description=The total number of requests sent, tags={client-id=consumer-1}]
[12/16/19 14:04:35:376 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-rate, group=consumer-metrics, description=The number of requests sent per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:377 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-avg, group=consumer-metrics, description=The average size of requests sent., tags={client-id=consumer-1}]
[12/16/19 14:04:35:379 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-max, group=consumer-metrics, description=The maximum size of any request sent., tags={client-id=consumer-1}]
[12/16/19 14:04:35:383 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name bytes-received:
[12/16/19 14:04:35:398 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-total, group=consumer-metrics, description=The total number of bytes read off all sockets, tags={client-id=consumer-1}]
[12/16/19 14:04:35:413 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-rate, group=consumer-metrics, description=The number of bytes read off all sockets per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:421 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-total, group=consumer-metrics, description=The total number of responses received, tags={client-id=consumer-1}]
[12/16/19 14:04:35:435 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-rate, group=consumer-metrics, description=The number of responses received per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:436 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name select-time:
[12/16/19 14:04:35:469 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=select-total, group=consumer-metrics, description=The total number of times the I/O layer checked for new I/O to perform, tags={client-id=consumer-1}]
[12/16/19 14:04:35:473 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=select-rate, group=consumer-metrics, description=The number of times the I/O layer checked for new I/O to perform per second, tags={client-id=consumer-1}]
[12/16/19 14:04:35:485 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-wait-time-ns-avg, group=consumer-metrics, description=The average length of time the I/O thread spent waiting for a socket ready for reads or writes in nanoseconds., tags={client-id=consumer-1}]
[12/16/19 14:04:35:486 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-waittime-total, group=consumer-metrics, description=The total time the I/O thread spent waiting, tags={client-id=consumer-1}]
[12/16/19 14:04:35:533 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-wait-ratio, group=consumer-metrics, description=The fraction of time the I/O thread spent waiting, tags={client-id=consumer-1}]
[12/16/19 14:04:35:536 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name io-time:
[12/16/19 14:04:35:537 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-time-ns-avg, group=consumer-metrics, description=The average length of time for I/O per select call in nanoseconds., tags={client-id=consumer-1}]
[12/16/19 14:04:35:593 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=iotime-total, group=consumer-metrics, description=The total time the I/O thread spent doing I/O, tags={client-id=consumer-1}]
[12/16/19 14:04:35:601 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-ratio, group=consumer-metrics, description=The fraction of time the I/O thread spent doing I/O, tags={client-id=consumer-1}]
[12/16/19 14:04:35:660 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-count, group=consumer-metrics, description=The current number of active connections., tags={client-id=consumer-1}]
[12/16/19 14:04:37:024 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name heartbeat-latency
[12/16/19 14:04:37:062 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=heartbeat-response-time-max, group=consumer-coordinator-metrics, description=The max time taken to receive a response to a heartbeat request, tags={client-id=consumer-1}]
[12/16/19 14:04:37:099 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=heartbeat-total, group=consumer-coordinator-metrics, description=The total number of heartbeats, tags={client-id=consumer-1}]
[12/16/19 14:04:37:125 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=heartbeat-rate, group=consumer-coordinator-metrics, description=The number of heartbeats per second, tags={client-id=consumer-1}]
[12/16/19 14:04:37:127 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name join-latency
[12/16/19 14:04:37:132 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=join-time-avg, group=consumer-coordinator-metrics, description=The average time taken for a group rejoin, tags={client-id=consumer-1}]
[12/16/19 14:04:37:157 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=join-time-max, group=consumer-coordinator-metrics, description=The max time taken for a group rejoin, tags={client-id=consumer-1}]
[12/16/19 14:04:37:184 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=join-total, group=consumer-coordinator-metrics, description=The total number of group joins, tags={client-id=consumer-1}]
[12/16/19 14:04:37:224 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=join-rate, group=consumer-coordinator-metrics, description=The number of group joins per second, tags={client-id=consumer-1}]
[12/16/19 14:04:37:224 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name sync-latency
[12/16/19 14:04:37:241 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=sync-time-avg, group=consumer-coordinator-metrics, description=The average time taken for a group sync, tags={client-id=consumer-1}]
[12/16/19 14:04:37:268 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=sync-time-max, group=consumer-coordinator-metrics, description=The max time taken for a group sync, tags={client-id=consumer-1}]
[12/16/19 14:04:37:287 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=sync-total, group=consumer-coordinator-metrics, description=The total number of group syncs, tags={client-id=consumer-1}]
[12/16/19 14:04:37:296 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=sync-rate, group=consumer-coordinator-metrics, description=The number of group syncs per second, tags={client-id=consumer-1}]
[12/16/19 14:04:37:367 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=last-heartbeat-seconds-ago, group=consumer-coordinator-metrics, description=The number of seconds since the last coordinator heartbeat was sent, tags={client-id=consumer-1}]
[12/16/19 14:04:37:561 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name commit-latency
[12/16/19 14:04:37:566 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=commit-latency-avg, group=consumer-coordinator-metrics, description=The average time taken for a commit request, tags={client-id=consumer-1}]
[12/16/19 14:04:37:571 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=commit-latency-max, group=consumer-coordinator-metrics, description=The max time taken for a commit request, tags={client-id=consumer-1}]
[12/16/19 14:04:37:584 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=commit-total, group=consumer-coordinator-metrics, description=The total number of commit calls, tags={client-id=consumer-1}]
[12/16/19 14:04:37:606 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=commit-rate, group=consumer-coordinator-metrics, description=The number of commit calls per second, tags={client-id=consumer-1}]
[12/16/19 14:04:37:648 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=assigned-partitions, group=consumer-coordinator-metrics, description=The number of partitions currently assigned to this consumer, tags={client-id=consumer-1}]
[12/16/19 14:04:37:707 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name bytes-fetched
[12/16/19 14:04:37:710 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=fetch-size-avg, group=consumer-fetch-manager-metrics, description=The average number of bytes fetched per request, tags={client-id=consumer-1}]
[12/16/19 14:04:37:766 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=fetch-size-max, group=consumer-fetch-manager-metrics, description=The maximum number of bytes fetched per request, tags={client-id=consumer-1}]
[12/16/19 14:04:37:770 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=bytes-consumed-total, group=consumer-fetch-manager-metrics, description=The total number of bytes consumed, tags={client-id=consumer-1}]
[12/16/19 14:04:37:770 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=bytes-consumed-rate, group=consumer-fetch-manager-metrics, description=The average number of bytes consumed per second, tags={client-id=consumer-1}]
[12/16/19 14:04:37:774 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name records-fetched
[12/16/19 14:04:37:776 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-per-request-avg, group=consumer-fetch-manager-metrics, description=The average number of records in each request, tags={client-id=consumer-1}]
[12/16/19 14:04:37:789 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-consumed-total, group=consumer-fetch-manager-metrics, description=The total number of records consumed, tags={client-id=consumer-1}]
[12/16/19 14:04:37:790 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-consumed-rate, group=consumer-fetch-manager-metrics, description=The average number of records consumed per second, tags={client-id=consumer-1}]
[12/16/19 14:04:37:826 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name fetch-latency
[12/16/19 14:04:37:850 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=fetch-latency-avg, group=consumer-fetch-manager-metrics, description=The average time taken for a fetch request., tags={client-id=consumer-1}]
[12/16/19 14:04:37:859 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=fetch-latency-max, group=consumer-fetch-manager-metrics, description=The max time taken for any fetch request., tags={client-id=consumer-1}]
[12/16/19 14:04:37:860 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=fetch-total, group=consumer-fetch-manager-metrics, description=The total number of fetch requests., tags={client-id=consumer-1}]
[12/16/19 14:04:37:871 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=fetch-rate, group=consumer-fetch-manager-metrics, description=The number of fetch requests per second., tags={client-id=consumer-1}]
[12/16/19 14:04:37:896 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name records-lag
[12/16/19 14:04:37:903 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The maximum lag in terms of number of records for any partition in this window, tags={client-id=consumer-1}]
[12/16/19 14:04:37:904 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name records-lead
[12/16/19 14:04:37:958 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The minimum lead in terms of number of records for any partition in this window, tags={client-id=consumer-1}]
[12/16/19 14:04:38:351 GMT] 00000028 id=00000000 org.apache.kafka.common.utils.AppInfoParser$AppInfo          I <init> Kafka version: 2.3.0
[12/16/19 14:04:38:360 GMT] 00000028 id=00000000 org.apache.kafka.common.utils.AppInfoParser$AppInfo          I <init> Kafka commitId: fc1aaa116b661c8a
[12/16/19 14:04:38:405 GMT] 00000028 id=00000000 org.apache.kafka.common.utils.AppInfoParser$AppInfo          I <init> Kafka startTimeMs: 1576505078239
[12/16/19 14:04:38:495 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=version, group=app-info, description=Metric indicating version, tags={client-id=consumer-1}]
[12/16/19 14:04:38:496 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=commit-id, group=app-info, description=Metric indicating commit-id, tags={client-id=consumer-1}]
[12/16/19 14:04:38:497 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=start-time-ms, group=app-info, description=Metric indicating start-time-ms, tags={client-id=consumer-1}]
[12/16/19 14:04:38:505 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 <init> [Consumer clientId=consumer-1, groupId=baristas] Kafka consumer initialized
[12/16/19 14:04:40:136 GMT] 00000028 id=00000000 org.apache.kafka.common.config.AbstractConfig                I logAll ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [my-cluster-kafka-bootstrap.kafka:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[12/16/19 14:04:40:301 GMT] 00000028 id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 <init> [Producer clientId=producer-1] Starting the Kafka producer
[12/16/19 14:04:40:302 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=count, group=kafka-metrics-count, description=total number of registered metrics, tags={client-id=producer-1}]
[12/16/19 14:04:40:460 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name bufferpool-wait-time
[12/16/19 14:04:40:462 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=bufferpool-wait-time-total, group=producer-metrics, description=The total time an appender waits for space allocation., tags={client-id=producer-1}]
[12/16/19 14:04:40:463 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=bufferpool-wait-ratio, group=producer-metrics, description=The fraction of time an appender waits for space allocation., tags={client-id=producer-1}]
[12/16/19 14:04:40:517 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=waiting-threads, group=producer-metrics, description=The number of user threads blocked waiting for buffer memory to enqueue their records, tags={client-id=producer-1}]
[12/16/19 14:04:40:527 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=buffer-total-bytes, group=producer-metrics, description=The maximum amount of buffer memory the client can use (whether or not it is currently used)., tags={client-id=producer-1}]
[12/16/19 14:04:40:537 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=buffer-available-bytes, group=producer-metrics, description=The total amount of buffer memory that is not being used (either unallocated or in the free list)., tags={client-id=producer-1}]
[12/16/19 14:04:40:538 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name buffer-exhausted-records
[12/16/19 14:04:40:548 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=buffer-exhausted-total, group=producer-metrics, description=The total number of record sends that are dropped due to buffer exhaustion, tags={client-id=producer-1}]
[12/16/19 14:04:40:549 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=buffer-exhausted-rate, group=producer-metrics, description=The average per-second number of record sends that are dropped due to buffer exhaustion, tags={client-id=producer-1}]
[12/16/19 14:04:40:632 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name errors
[12/16/19 14:04:40:909 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name produce-throttle-time
[12/16/19 14:04:40:922 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=produce-throttle-time-avg, group=producer-metrics, description=The average time in ms a request was throttled by a broker, tags={client-id=producer-1}]
[12/16/19 14:04:40:932 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=produce-throttle-time-max, group=producer-metrics, description=The maximum time in ms a request was throttled by a broker, tags={client-id=producer-1}]
[12/16/19 14:04:40:938 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name connections-closed:
[12/16/19 14:04:40:956 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-close-total, group=producer-metrics, description=The total number of connections closed, tags={client-id=producer-1}]
[12/16/19 14:04:40:969 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-close-rate, group=producer-metrics, description=The number of connections closed per second, tags={client-id=producer-1}]
[12/16/19 14:04:40:969 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name connections-created:
[12/16/19 14:04:40:984 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-creation-total, group=producer-metrics, description=The total number of new connections established, tags={client-id=producer-1}]
[12/16/19 14:04:40:996 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-creation-rate, group=producer-metrics, description=The number of new connections established per second, tags={client-id=producer-1}]
[12/16/19 14:04:40:997 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name successful-authentication:
[12/16/19 14:04:41:007 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-authentication-total, group=producer-metrics, description=The total number of connections with successful authentication, tags={client-id=producer-1}]
[12/16/19 14:04:41:020 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-authentication-rate, group=producer-metrics, description=The number of connections with successful authentication per second, tags={client-id=producer-1}]
[12/16/19 14:04:41:026 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name successful-reauthentication:
[12/16/19 14:04:41:027 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-reauthentication-total, group=producer-metrics, description=The total number of successful re-authentication of connections, tags={client-id=producer-1}]
[12/16/19 14:04:41:028 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-reauthentication-rate, group=producer-metrics, description=The number of successful re-authentication of connections per second, tags={client-id=producer-1}]
[12/16/19 14:04:41:028 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name successful-authentication-no-reauth:
[12/16/19 14:04:41:029 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-authentication-no-reauth-total, group=producer-metrics, description=The total number of connections with successful authentication where the client does not support re-authentication, tags={client-id=producer-1}]
[12/16/19 14:04:41:107 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name failed-authentication:
[12/16/19 14:04:41:126 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-authentication-total, group=producer-metrics, description=The total number of connections with failed authentication, tags={client-id=producer-1}]
[12/16/19 14:04:41:128 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-authentication-rate, group=producer-metrics, description=The number of connections with failed authentication per second, tags={client-id=producer-1}]
[12/16/19 14:04:41:130 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name failed-reauthentication:
[12/16/19 14:04:41:140 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-reauthentication-total, group=producer-metrics, description=The total number of failed re-authentication of connections, tags={client-id=producer-1}]
[12/16/19 14:04:41:144 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-reauthentication-rate, group=producer-metrics, description=The number of failed re-authentication of connections per second, tags={client-id=producer-1}]
[12/16/19 14:04:41:147 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name reauthentication-latency:
[12/16/19 14:04:41:151 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=reauthentication-latency-max, group=producer-metrics, description=The max latency observed due to re-authentication, tags={client-id=producer-1}]
[12/16/19 14:04:41:154 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=reauthentication-latency-avg, group=producer-metrics, description=The average latency observed due to re-authentication, tags={client-id=producer-1}]
[12/16/19 14:04:41:155 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name bytes-sent-received:
[12/16/19 14:04:41:164 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=network-io-total, group=producer-metrics, description=The total number of network operations (reads or writes) on all connections, tags={client-id=producer-1}]
[12/16/19 14:04:41:172 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=network-io-rate, group=producer-metrics, description=The number of network operations (reads or writes) on all connections per second, tags={client-id=producer-1}]
[12/16/19 14:04:41:173 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name bytes-sent:
[12/16/19 14:04:41:176 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-total, group=producer-metrics, description=The total number of outgoing bytes sent to all servers, tags={client-id=producer-1}]
[12/16/19 14:04:41:178 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-rate, group=producer-metrics, description=The number of outgoing bytes sent to all servers per second, tags={client-id=producer-1}]
[12/16/19 14:04:41:181 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-total, group=producer-metrics, description=The total number of requests sent, tags={client-id=producer-1}]
[12/16/19 14:04:41:185 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-rate, group=producer-metrics, description=The number of requests sent per second, tags={client-id=producer-1}]
[12/16/19 14:04:41:188 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-avg, group=producer-metrics, description=The average size of requests sent., tags={client-id=producer-1}]
[12/16/19 14:04:41:192 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-max, group=producer-metrics, description=The maximum size of any request sent., tags={client-id=producer-1}]
[12/16/19 14:04:41:194 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name bytes-received:
[12/16/19 14:04:41:213 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-total, group=producer-metrics, description=The total number of bytes read off all sockets, tags={client-id=producer-1}]
[12/16/19 14:04:41:216 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-rate, group=producer-metrics, description=The number of bytes read off all sockets per second, tags={client-id=producer-1}]
[12/16/19 14:04:41:221 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-total, group=producer-metrics, description=The total number of responses received, tags={client-id=producer-1}]
[12/16/19 14:04:41:225 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-rate, group=producer-metrics, description=The number of responses received per second, tags={client-id=producer-1}]
[12/16/19 14:04:41:227 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name select-time:
[12/16/19 14:04:41:229 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=select-total, group=producer-metrics, description=The total number of times the I/O layer checked for new I/O to perform, tags={client-id=producer-1}]
[12/16/19 14:04:41:233 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=select-rate, group=producer-metrics, description=The number of times the I/O layer checked for new I/O to perform per second, tags={client-id=producer-1}]
[12/16/19 14:04:41:235 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-wait-time-ns-avg, group=producer-metrics, description=The average length of time the I/O thread spent waiting for a socket ready for reads or writes in nanoseconds., tags={client-id=producer-1}]
[12/16/19 14:04:41:238 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-waittime-total, group=producer-metrics, description=The total time the I/O thread spent waiting, tags={client-id=producer-1}]
[12/16/19 14:04:41:240 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-wait-ratio, group=producer-metrics, description=The fraction of time the I/O thread spent waiting, tags={client-id=producer-1}]
[12/16/19 14:04:41:241 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name io-time:
[12/16/19 14:04:41:245 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-time-ns-avg, group=producer-metrics, description=The average length of time for I/O per select call in nanoseconds., tags={client-id=producer-1}]
[12/16/19 14:04:41:251 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=iotime-total, group=producer-metrics, description=The total time the I/O thread spent doing I/O, tags={client-id=producer-1}]
[12/16/19 14:04:41:252 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-ratio, group=producer-metrics, description=The fraction of time the I/O thread spent doing I/O, tags={client-id=producer-1}]
[12/16/19 14:04:41:266 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-count, group=producer-metrics, description=The current number of active connections., tags={client-id=producer-1}]
[12/16/19 14:04:41:448 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name batch-size
[12/16/19 14:04:41:449 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=batch-size-avg, group=producer-metrics, description=The average number of bytes sent per partition per-request., tags={client-id=producer-1}]
[12/16/19 14:04:41:451 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=batch-size-max, group=producer-metrics, description=The max number of bytes sent per partition per-request., tags={client-id=producer-1}]
[12/16/19 14:04:41:452 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name compression-rate
[12/16/19 14:04:41:464 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=compression-rate-avg, group=producer-metrics, description=The average compression rate of record batches., tags={client-id=producer-1}]
[12/16/19 14:04:41:492 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name queue-time
[12/16/19 14:04:41:493 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-queue-time-avg, group=producer-metrics, description=The average time in ms record batches spent in the send buffer., tags={client-id=producer-1}]
[12/16/19 14:04:41:494 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-queue-time-max, group=producer-metrics, description=The maximum time in ms record batches spent in the send buffer., tags={client-id=producer-1}]
[12/16/19 14:04:41:509 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name request-time
[12/16/19 14:04:41:521 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-avg, group=producer-metrics, description=The average request latency in ms, tags={client-id=producer-1}]
[12/16/19 14:04:41:536 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-max, group=producer-metrics, description=The maximum request latency in ms, tags={client-id=producer-1}]
[12/16/19 14:04:41:555 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name records-per-request
[12/16/19 14:04:41:562 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-send-total, group=producer-metrics, description=The total number of records sent., tags={client-id=producer-1}]
[12/16/19 14:04:41:582 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-send-rate, group=producer-metrics, description=The average number of records sent per second., tags={client-id=producer-1}]
[12/16/19 14:04:41:607 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-per-request-avg, group=producer-metrics, description=The average number of records per request., tags={client-id=producer-1}]
[12/16/19 14:04:41:616 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name record-retries
[12/16/19 14:04:41:634 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-retry-total, group=producer-metrics, description=The total number of retried record sends, tags={client-id=producer-1}]
[12/16/19 14:04:41:636 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-retry-rate, group=producer-metrics, description=The average per-second number of retried record sends, tags={client-id=producer-1}]
[12/16/19 14:04:41:644 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-error-total, group=producer-metrics, description=The total number of record sends that resulted in errors, tags={client-id=producer-1}]
[12/16/19 14:04:41:644 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-error-rate, group=producer-metrics, description=The average per-second number of record sends that resulted in errors, tags={client-id=producer-1}]
[12/16/19 14:04:41:646 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name record-size
[12/16/19 14:04:41:647 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-size-max, group=producer-metrics, description=The maximum record size, tags={client-id=producer-1}]
[12/16/19 14:04:41:648 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-size-avg, group=producer-metrics, description=The average record size, tags={client-id=producer-1}]
[12/16/19 14:04:41:651 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=requests-in-flight, group=producer-metrics, description=The current number of in-flight requests awaiting a response., tags={client-id=producer-1}]
[12/16/19 14:04:41:674 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=metadata-age, group=producer-metrics, description=The age in seconds of the current producer metadata being used., tags={client-id=producer-1}]
[12/16/19 14:04:41:675 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name batch-split-rate
[12/16/19 14:04:41:678 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=batch-split-total, group=producer-metrics, description=The total number of batch splits, tags={client-id=producer-1}]
[12/16/19 14:04:41:679 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=batch-split-rate, group=producer-metrics, description=The average number of batch splits per second, tags={client-id=producer-1}]
[12/16/19 14:04:41:731 GMT] 00000028 id=00000000 org.apache.kafka.common.utils.AppInfoParser$AppInfo          I <init> Kafka version: 2.3.0
[12/16/19 14:04:41:732 GMT] 00000028 id=00000000 org.apache.kafka.common.utils.AppInfoParser$AppInfo          I <init> Kafka commitId: fc1aaa116b661c8a
[12/16/19 14:04:41:733 GMT] 00000028 id=00000000 org.apache.kafka.common.utils.AppInfoParser$AppInfo          I <init> Kafka startTimeMs: 1576505081731
[12/16/19 14:04:41:735 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=version, group=app-info, description=Metric indicating version, tags={client-id=producer-1}]
[12/16/19 14:04:41:736 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=commit-id, group=app-info, description=Metric indicating commit-id, tags={client-id=producer-1}]
[12/16/19 14:04:41:737 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=start-time-ms, group=app-info, description=Metric indicating start-time-ms, tags={client-id=producer-1}]
[12/16/19 14:04:41:737 GMT] 00000028 id=00000000 org.apache.kafka.clients.producer.KafkaProducer              1 <init> [Producer clientId=producer-1] Kafka producer started
[12/16/19 14:04:41:854 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           1 run [Producer clientId=producer-1] Starting Kafka producer I/O thread.
[12/16/19 14:04:41:924 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Producer clientId=producer-1] Found least loaded node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null) with no active connection
[12/16/19 14:04:41:924 GMT] 0000004a id=00000000 rg.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater 1 maybeUpdate [Producer clientId=producer-1] Initialize connection to node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null) for sending metadata request
[12/16/19 14:04:41:934 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       1 initiateConnect [Producer clientId=producer-1] Initiating connection to node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null) using address my-cluster-kafka-bootstrap.kafka/10.109.233.225
[12/16/19 14:04:41:974 GMT] 00000028 id=00000000 io.smallrye.reactive.messaging.extension.MediatorManager     I initializeAndRun Initializing mediators
[12/16/19 14:04:42:568 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node--1.bytes-sent
[12/16/19 14:04:42:569 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-total, group=producer-node-metrics, description=The total number of outgoing bytes, tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:573 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-rate, group=producer-node-metrics, description=The number of outgoing bytes per second, tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:591 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-total, group=producer-node-metrics, description=The total number of requests sent, tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:602 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-rate, group=producer-node-metrics, description=The number of requests sent per second, tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:618 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-avg, group=producer-node-metrics, description=The average size of requests sent., tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:619 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-max, group=producer-node-metrics, description=The maximum size of any request sent., tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:636 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node--1.bytes-received
[12/16/19 14:04:42:652 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-total, group=producer-node-metrics, description=The total number of incoming bytes, tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:653 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-rate, group=producer-node-metrics, description=The number of incoming bytes per second, tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:653 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-total, group=producer-node-metrics, description=The total number of responses received, tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:654 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-rate, group=producer-node-metrics, description=The number of responses received per second, tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:741 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node--1.latency
[12/16/19 14:04:42:742 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-avg, group=producer-node-metrics, description=, tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:743 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-max, group=producer-node-metrics, description=, tags={client-id=producer-1, node-id=node--1}]
[12/16/19 14:04:42:744 GMT] 0000004a id=00000000 org.apache.kafka.common.network.Selector                     1 pollSelectionKeys [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
[12/16/19 14:04:43:222 GMT] 00000028 id=00000000 io.smallrye.reactive.messaging.extension.MediatorManager     I weaving Connecting mediators
[12/16/19 14:04:43:252 GMT] 00000028 id=00000000 io.smallrye.reactive.messaging.extension.MediatorManager     I lambda$weaving$6 Attempt to resolve me.escoffier.quarkus.coffeeshop.KafkaBarista#prepare
[12/16/19 14:04:43:262 GMT] 00000028 id=00000000 io.smallrye.reactive.messaging.extension.MediatorManager     I lambda$null$5 Connecting me.escoffier.quarkus.coffeeshop.KafkaBarista#prepare to `orders` (org.eclipse.microprofile.reactive.streams.operators.core.PublisherBuilderImpl@dfd9116f)
[12/16/19 14:04:43:330 GMT] 00000028 id=00000000 io.smallrye.reactive.messaging.extension.MediatorManager     I weaving Connecting method me.escoffier.quarkus.coffeeshop.KafkaBarista#prepare to sink queue
[12/16/19 14:04:43:723 GMT] 00000028 id=00000000 com.ibm.ws.webcontainer.osgi.webapp.WebGroup                 I SRVE0169I: Loading Web Module: barista-kafka-1.0-SNAPSHOT.
[12/16/19 14:04:43:767 GMT] 00000028 id=00000000 com.ibm.ws.webcontainer.osgi.DynamicVirtualHost              I addWebApplication SRVE0250I: Web Module barista-kafka-1.0-SNAPSHOT has been bound to default_host.
[12/16/19 14:04:43:767 GMT] 00000028 id=00000000 com.ibm.ws.http.internal.VirtualHostImpl                     A CWWKT0016I: Web application available (default_host): http://coffee-v1-barista-kafka-7b74db8455-82cg9:8090/
[12/16/19 14:04:43:884 GMT] 00000046 id=00000000 SessionContextRegistryImpl                                   I getSessionContext SESN0176I: A new session context will be created for application key default_host/
[12/16/19 14:04:43:891 GMT] 00000046 id=00000000 IDGeneratorImpl                                              I IDGeneratorImpl SESN0172I: The session manager is using the Java default SecureRandom implementation for session ID generation.
[12/16/19 14:04:43:940 GMT] 00000028 id=00000000 com.ibm.ws.app.manager.AppMessageHelper                      A CWWKZ0001I: Application barista-kafka-1.0-SNAPSHOT started in 64.967 seconds.
[12/16/19 14:04:44:434 GMT] 00000043 id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              I subscribe [Consumer clientId=consumer-1, groupId=baristas] Subscribed to topic(s): orders
[12/16/19 14:04:44:445 GMT] 00000043 id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Consumer clientId=consumer-1, groupId=baristas] Found least loaded node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null) with no active connection
[12/16/19 14:04:44:449 GMT] 00000043 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendFindCoordinatorRequest [Consumer clientId=consumer-1, groupId=baristas] Sending FindCoordinator request to broker my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null)
[12/16/19 14:04:44:642 GMT] 00000045 id=00000000 com.ibm.ws.webcontainer.osgi.mbeans.PluginGenerator          I SRVE9103I: A configuration file for a web server plugin was automatically generated for this server at /opt/ol/wlp/output/defaultServer/logs/state/plugin-cfg.xml.
[12/16/19 14:04:47:362 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleConnections [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
[12/16/19 14:04:47:384 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleInitiateApiVersionRequests [Producer clientId=producer-1] Initiating API versions fetch from node -1.
[12/16/19 14:04:47:384 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] No version information found when sending API_VERSIONS with correlation id 0 to node -1. Assuming version 2.
[12/16/19 14:04:47:400 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending API_VERSIONS {} with correlation id 0 to node -1
[12/16/19 14:04:47:380 GMT] 00000043 id=00000000 org.apache.kafka.clients.NetworkClient                       1 initiateConnect [Consumer clientId=consumer-1, groupId=baristas] Initiating connection to node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null) using address my-cluster-kafka-bootstrap.kafka/10.109.233.225
[12/16/19 14:04:47:411 GMT] 00000043 id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Consumer clientId=consumer-1, groupId=baristas] Found least loaded connecting node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null)
[12/16/19 14:04:47:412 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node--1.bytes-sent
[12/16/19 14:04:47:413 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-total, group=consumer-node-metrics, description=The total number of outgoing bytes, tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:426 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-rate, group=consumer-node-metrics, description=The number of outgoing bytes per second, tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:535 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Producer clientId=producer-1] Found least loaded connecting node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null)
[12/16/19 14:04:47:446 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-total, group=consumer-node-metrics, description=The total number of requests sent, tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:555 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-rate, group=consumer-node-metrics, description=The number of requests sent per second, tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:567 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-avg, group=consumer-node-metrics, description=The average size of requests sent., tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:568 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-max, group=consumer-node-metrics, description=The maximum size of any request sent., tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:579 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node--1.bytes-received
[12/16/19 14:04:47:580 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Producer clientId=producer-1] Found least loaded connecting node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null)
[12/16/19 14:04:47:598 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-total, group=consumer-node-metrics, description=The total number of incoming bytes, tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:603 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-rate, group=consumer-node-metrics, description=The number of incoming bytes per second, tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:702 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node -1 for API_VERSIONS with correlation id 0, received {error_code=0,api_versions=[{api_key=0,min_version=0,max_version=7},{api_key=1,min_version=0,max_version=11},{api_key=2,min_version=0,max_version=5},{api_key=3,min_version=0,max_version=8},{api_key=4,min_version=0,max_version=2},{api_key=5,min_version=0,max_version=1},{api_key=6,min_version=0,max_version=5},{api_key=7,min_version=0,max_version=2},{api_key=8,min_version=0,max_version=7},{api_key=9,min_version=0,max_version=5},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=5},{api_key=12,min_version=0,max_version=3},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=3},{api_key=15,min_version=0,max_version=3},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=3},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=3},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=2},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=1},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1},{api_key=43,min_version=0,max_version=0},{api_key=44,min_version=0,max_version=0}],throttle_time_ms=0}
[12/16/19 14:04:47:695 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-total, group=consumer-node-metrics, description=The total number of responses received, tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:703 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-rate, group=consumer-node-metrics, description=The number of responses received per second, tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:704 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node--1.latency
[12/16/19 14:04:47:720 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-avg, group=consumer-node-metrics, description=, tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:722 GMT] 00000043 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-max, group=consumer-node-metrics, description=, tags={client-id=consumer-1, node-id=node--1}]
[12/16/19 14:04:47:750 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleApiVersionsResponse [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[12/16/19 14:04:47:759 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Producer clientId=producer-1] Found least loaded node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null) connected with no in-flight requests
[12/16/19 14:04:47:734 GMT] 00000043 id=00000000 org.apache.kafka.common.network.Selector                     1 pollSelectionKeys [Consumer clientId=consumer-1, groupId=baristas] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
[12/16/19 14:04:47:806 GMT] 00000043 id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleConnections [Consumer clientId=consumer-1, groupId=baristas] Completed connection to node -1. Fetching API versions.
[12/16/19 14:04:47:809 GMT] 00000043 id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleInitiateApiVersionRequests [Consumer clientId=consumer-1, groupId=baristas] Initiating API versions fetch from node -1.
[12/16/19 14:04:47:810 GMT] 00000043 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] No version information found when sending API_VERSIONS with correlation id 1 to node -1. Assuming version 2.
[12/16/19 14:04:47:814 GMT] 00000043 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending API_VERSIONS {} with correlation id 1 to node -1
[12/16/19 14:04:47:832 GMT] 0000004a id=00000000 rg.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater 1 maybeUpdate [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null)
[12/16/19 14:04:47:856 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 1 to node -1
[12/16/19 14:04:47:861 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Consumer clientId=consumer-1, groupId=baristas] Found least loaded connecting node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null)
[12/16/19 14:04:47:864 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Consumer clientId=consumer-1, groupId=baristas] Found least loaded connecting node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null)
[12/16/19 14:04:47:866 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node -1 for API_VERSIONS with correlation id 1, received {error_code=0,api_versions=[{api_key=0,min_version=0,max_version=7},{api_key=1,min_version=0,max_version=11},{api_key=2,min_version=0,max_version=5},{api_key=3,min_version=0,max_version=8},{api_key=4,min_version=0,max_version=2},{api_key=5,min_version=0,max_version=1},{api_key=6,min_version=0,max_version=5},{api_key=7,min_version=0,max_version=2},{api_key=8,min_version=0,max_version=7},{api_key=9,min_version=0,max_version=5},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=5},{api_key=12,min_version=0,max_version=3},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=3},{api_key=15,min_version=0,max_version=3},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=3},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=3},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=2},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=1},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1},{api_key=43,min_version=0,max_version=0},{api_key=44,min_version=0,max_version=0}],throttle_time_ms=0}
[12/16/19 14:04:47:874 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleApiVersionsResponse [Consumer clientId=consumer-1, groupId=baristas] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[12/16/19 14:04:47:882 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Consumer clientId=consumer-1, groupId=baristas] Found least loaded node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null) connected with no in-flight requests
[12/16/19 14:04:47:885 GMT] 00000046 id=00000000 rg.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater 1 maybeUpdate [Consumer clientId=consumer-1, groupId=baristas] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='orders')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null)
[12/16/19 14:04:47:890 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending METADATA {topics=[{name=orders}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 2 to node -1
[12/16/19 14:04:47:891 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node -1 for METADATA with correlation id 1, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:04:47:925 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FIND_COORDINATOR {key=baristas,key_type=0} with correlation id 0 to node -1
[12/16/19 14:04:47:927 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node -1 for METADATA with correlation id 2, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[{error_code=0,name=orders,is_internal=false,partitions=[{error_code=0,partition_index=0,leader_id=0,leader_epoch=0,replica_nodes=[0],isr_nodes=[0],offline_replicas=[]},{error_code=0,partition_index=1,leader_id=0,leader_epoch=0,replica_nodes=[0],isr_nodes=[0],offline_replicas=[]},{error_code=0,partition_index=4,leader_id=0,leader_epoch=0,replica_nodes=[0],isr_nodes=[0],offline_replicas=[]},{error_code=0,partition_index=2,leader_id=0,leader_epoch=0,replica_nodes=[0],isr_nodes=[0],offline_replicas=[]},{error_code=0,partition_index=3,leader_id=0,leader_epoch=0,replica_nodes=[0],isr_nodes=[0],offline_replicas=[]}],topic_authorized_operations=0}],cluster_authorized_operations=0}
[12/16/19 14:04:48:140 GMT] 0000004a id=00000000 org.apache.kafka.clients.Metadata                            I update [Producer clientId=producer-1] Cluster ID: 7-jItNsIRea8d5lAaxlkjw
[12/16/19 14:04:48:227 GMT] 0000004a id=00000000 org.apache.kafka.clients.Metadata                            1 update [Producer clientId=producer-1] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = 7-jItNsIRea8d5lAaxlkjw, nodes = [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )], partitions = [], controller = my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ))}
[12/16/19 14:04:48:234 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch null with new epoch 0
[12/16/19 14:04:48:280 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Updating last seen epoch from null to 0 for partition orders-0
[12/16/19 14:04:48:280 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch null with new epoch 0
[12/16/19 14:04:48:282 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Updating last seen epoch from null to 0 for partition orders-1
[12/16/19 14:04:48:282 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch null with new epoch 0
[12/16/19 14:04:48:284 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Updating last seen epoch from null to 0 for partition orders-4
[12/16/19 14:04:48:284 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch null with new epoch 0
[12/16/19 14:04:48:285 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Updating last seen epoch from null to 0 for partition orders-2
[12/16/19 14:04:48:286 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch null with new epoch 0
[12/16/19 14:04:48:286 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Updating last seen epoch from null to 0 for partition orders-3
[12/16/19 14:04:48:300 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            I update [Consumer clientId=consumer-1, groupId=baristas] Cluster ID: 7-jItNsIRea8d5lAaxlkjw
[12/16/19 14:04:48:317 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            1 update [Consumer clientId=consumer-1, groupId=baristas] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = 7-jItNsIRea8d5lAaxlkjw, nodes = [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )], partitions = [Partition(topic = orders, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = []), Partition(topic = orders, partition = 1, leader = 0, replicas = [0], isr = [0], offlineReplicas = []), Partition(topic = orders, partition = 2, leader = 0, replicas = [0], isr = [0], offlineReplicas = []), Partition(topic = orders, partition = 3, leader = 0, replicas = [0], isr = [0], offlineReplicas = []), Partition(topic = orders, partition = 4, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])], controller = my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ))}
[12/16/19 14:04:48:321 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node -1 for FIND_COORDINATOR with correlation id 0, received {throttle_time_ms=0,error_code=0,error_message=NONE,node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092}
[12/16/19 14:04:48:329 GMT] 00000046 id=00000000 internals.AbstractCoordinator$FindCoordinatorResponseHandler 1 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Received FindCoordinator response ClientResponse(receivedTimeMs=1576505088319, latencyMs=955, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=0, host='my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local', port=9092))
[12/16/19 14:04:48:329 GMT] 00000046 id=00000000 internals.AbstractCoordinator$FindCoordinatorResponseHandler I onSuccess [Consumer clientId=consumer-1, groupId=baristas] Discovered group coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:04:48:333 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       1 initiateConnect [Consumer clientId=consumer-1, groupId=baristas] Initiating connection to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null) using address my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local/172.17.0.8
[12/16/19 14:04:48:408 GMT] 0000004d id=00000000 ients.consumer.internals.AbstractCoordinator$HeartbeatThread 1 run [Consumer clientId=consumer-1, groupId=baristas] Heartbeat thread started
[12/16/19 14:04:48:412 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I onJoinPrepare [Consumer clientId=consumer-1, groupId=baristas] Revoking previously assigned partitions []
[12/16/19 14:04:48:414 GMT] 00000046 id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.AckTracker  1 0 removed partitions 
                                                                                                               []
[12/16/19 14:04:48:415 GMT] 00000046 id=00000000 ients.consumer.internals.AbstractCoordinator$HeartbeatThread 1 disable [Consumer clientId=consumer-1, groupId=baristas] Disabling heartbeat thread
[12/16/19 14:04:48:416 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator I sendJoinGroupRequest [Consumer clientId=consumer-1, groupId=baristas] (Re-)joining group
[12/16/19 14:04:48:547 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 metadata [Consumer clientId=consumer-1, groupId=baristas] Joining group with current subscription: [orders]
[12/16/19 14:04:48:591 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendJoinGroupRequest [Consumer clientId=consumer-1, groupId=baristas] Sending JoinGroup (JoinGroupRequestData(groupId='baristas', sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 0])])) to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:04:48:605 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-2147483647.bytes-sent
[12/16/19 14:04:48:609 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-total, group=consumer-node-metrics, description=The total number of outgoing bytes, tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:614 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-rate, group=consumer-node-metrics, description=The number of outgoing bytes per second, tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:641 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-total, group=consumer-node-metrics, description=The total number of requests sent, tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:642 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-rate, group=consumer-node-metrics, description=The number of requests sent per second, tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:643 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-avg, group=consumer-node-metrics, description=The average size of requests sent., tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:646 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-max, group=consumer-node-metrics, description=The maximum size of any request sent., tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:646 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-2147483647.bytes-received
[12/16/19 14:04:48:701 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-total, group=consumer-node-metrics, description=The total number of incoming bytes, tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:745 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-rate, group=consumer-node-metrics, description=The number of incoming bytes per second, tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:772 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-total, group=consumer-node-metrics, description=The total number of responses received, tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:800 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-rate, group=consumer-node-metrics, description=The number of responses received per second, tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:835 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-2147483647.latency
[12/16/19 14:04:48:841 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-avg, group=consumer-node-metrics, description=, tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:862 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-max, group=consumer-node-metrics, description=, tags={client-id=consumer-1, node-id=node-2147483647}]
[12/16/19 14:04:48:880 GMT] 00000046 id=00000000 org.apache.kafka.common.network.Selector                     1 pollSelectionKeys [Consumer clientId=consumer-1, groupId=baristas] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
[12/16/19 14:04:48:881 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleConnections [Consumer clientId=consumer-1, groupId=baristas] Completed connection to node 2147483647. Fetching API versions.
[12/16/19 14:04:48:929 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleInitiateApiVersionRequests [Consumer clientId=consumer-1, groupId=baristas] Initiating API versions fetch from node 2147483647.
[12/16/19 14:04:48:972 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] No version information found when sending API_VERSIONS with correlation id 4 to node 2147483647. Assuming version 2.
[12/16/19 14:04:48:972 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending API_VERSIONS {} with correlation id 4 to node 2147483647
[12/16/19 14:04:49:059 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for API_VERSIONS with correlation id 4, received {error_code=0,api_versions=[{api_key=0,min_version=0,max_version=7},{api_key=1,min_version=0,max_version=11},{api_key=2,min_version=0,max_version=5},{api_key=3,min_version=0,max_version=8},{api_key=4,min_version=0,max_version=2},{api_key=5,min_version=0,max_version=1},{api_key=6,min_version=0,max_version=5},{api_key=7,min_version=0,max_version=2},{api_key=8,min_version=0,max_version=7},{api_key=9,min_version=0,max_version=5},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=5},{api_key=12,min_version=0,max_version=3},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=3},{api_key=15,min_version=0,max_version=3},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=3},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=3},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=2},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=1},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1},{api_key=43,min_version=0,max_version=0},{api_key=44,min_version=0,max_version=0}],throttle_time_ms=0}
[12/16/19 14:04:49:097 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleApiVersionsResponse [Consumer clientId=consumer-1, groupId=baristas] Recorded API versions for node 2147483647: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[12/16/19 14:04:49:097 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending JOIN_GROUP {group_id=baristas,session_timeout_ms=10000,rebalance_timeout_ms=300000,member_id=,group_instance_id=null,protocol_type=consumer,protocols=[{name=range,metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]}]} with correlation id 3 to node 2147483647
[12/16/19 14:04:49:150 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for JOIN_GROUP with correlation id 3, received {throttle_time_ms=0,error_code=79,generation_id=-1,protocol_name=,leader=,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,members=[]}
[12/16/19 14:04:49:199 GMT] 00000046 id=00000000 ients.consumer.internals.AbstractCoordinator$HeartbeatThread 1 disable [Consumer clientId=consumer-1, groupId=baristas] Disabling heartbeat thread
[12/16/19 14:04:49:200 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator I sendJoinGroupRequest [Consumer clientId=consumer-1, groupId=baristas] (Re-)joining group
[12/16/19 14:04:49:218 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 metadata [Consumer clientId=consumer-1, groupId=baristas] Joining group with current subscription: [orders]
[12/16/19 14:04:49:218 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendJoinGroupRequest [Consumer clientId=consumer-1, groupId=baristas] Sending JoinGroup (JoinGroupRequestData(groupId='baristas', sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 0])])) to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:04:49:218 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending JOIN_GROUP {group_id=baristas,session_timeout_ms=10000,rebalance_timeout_ms=300000,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,protocol_type=consumer,protocols=[{name=range,metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]}]} with correlation id 5 to node 2147483647
[12/16/19 14:04:50:163 GMT] 00000047 id=00000000 org.apache.kafka.common.config.AbstractConfig                I logAll AdminClientConfig values: 
	bootstrap.servers = [my-cluster-kafka-bootstrap.kafka:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

[12/16/19 14:04:50:544 GMT] 00000047 id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 1 update [AdminClient clientId=adminclient-1] Setting bootstrap cluster metadata Cluster(id = null, nodes = [my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null)], partitions = [], controller = null).
[12/16/19 14:04:50:547 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=count, group=kafka-metrics-count, description=total number of registered metrics, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:548 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name connections-closed:
[12/16/19 14:04:50:552 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-close-total, group=admin-client-metrics, description=The total number of connections closed, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:558 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-close-rate, group=admin-client-metrics, description=The number of connections closed per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:560 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name connections-created:
[12/16/19 14:04:50:565 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-creation-total, group=admin-client-metrics, description=The total number of new connections established, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:575 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-creation-rate, group=admin-client-metrics, description=The number of new connections established per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:576 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name successful-authentication:
[12/16/19 14:04:50:587 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-authentication-total, group=admin-client-metrics, description=The total number of connections with successful authentication, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:616 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-authentication-rate, group=admin-client-metrics, description=The number of connections with successful authentication per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:617 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name successful-reauthentication:
[12/16/19 14:04:50:635 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-reauthentication-total, group=admin-client-metrics, description=The total number of successful re-authentication of connections, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:636 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-reauthentication-rate, group=admin-client-metrics, description=The number of successful re-authentication of connections per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:636 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name successful-authentication-no-reauth:
[12/16/19 14:04:50:673 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=successful-authentication-no-reauth-total, group=admin-client-metrics, description=The total number of connections with successful authentication where the client does not support re-authentication, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:705 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name failed-authentication:
[12/16/19 14:04:50:738 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-authentication-total, group=admin-client-metrics, description=The total number of connections with failed authentication, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:766 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-authentication-rate, group=admin-client-metrics, description=The number of connections with failed authentication per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:770 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name failed-reauthentication:
[12/16/19 14:04:50:776 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-reauthentication-total, group=admin-client-metrics, description=The total number of failed re-authentication of connections, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:816 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=failed-reauthentication-rate, group=admin-client-metrics, description=The number of failed re-authentication of connections per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:828 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name reauthentication-latency:
[12/16/19 14:04:50:829 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=reauthentication-latency-max, group=admin-client-metrics, description=The max latency observed due to re-authentication, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:830 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=reauthentication-latency-avg, group=admin-client-metrics, description=The average latency observed due to re-authentication, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:849 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name bytes-sent-received:
[12/16/19 14:04:50:856 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=network-io-total, group=admin-client-metrics, description=The total number of network operations (reads or writes) on all connections, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:857 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=network-io-rate, group=admin-client-metrics, description=The number of network operations (reads or writes) on all connections per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:857 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name bytes-sent:
[12/16/19 14:04:50:860 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-total, group=admin-client-metrics, description=The total number of outgoing bytes sent to all servers, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:861 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-rate, group=admin-client-metrics, description=The number of outgoing bytes sent to all servers per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:862 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-total, group=admin-client-metrics, description=The total number of requests sent, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:869 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-rate, group=admin-client-metrics, description=The number of requests sent per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:870 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-avg, group=admin-client-metrics, description=The average size of requests sent., tags={client-id=adminclient-1}]
[12/16/19 14:04:50:871 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-max, group=admin-client-metrics, description=The maximum size of any request sent., tags={client-id=adminclient-1}]
[12/16/19 14:04:50:923 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name bytes-received:
[12/16/19 14:04:50:929 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-total, group=admin-client-metrics, description=The total number of bytes read off all sockets, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:946 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-rate, group=admin-client-metrics, description=The number of bytes read off all sockets per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:949 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-total, group=admin-client-metrics, description=The total number of responses received, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:958 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-rate, group=admin-client-metrics, description=The number of responses received per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:959 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name select-time:
[12/16/19 14:04:50:960 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=select-total, group=admin-client-metrics, description=The total number of times the I/O layer checked for new I/O to perform, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:981 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=select-rate, group=admin-client-metrics, description=The number of times the I/O layer checked for new I/O to perform per second, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:988 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-wait-time-ns-avg, group=admin-client-metrics, description=The average length of time the I/O thread spent waiting for a socket ready for reads or writes in nanoseconds., tags={client-id=adminclient-1}]
[12/16/19 14:04:50:990 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-waittime-total, group=admin-client-metrics, description=The total time the I/O thread spent waiting, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:991 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-wait-ratio, group=admin-client-metrics, description=The fraction of time the I/O thread spent waiting, tags={client-id=adminclient-1}]
[12/16/19 14:04:50:993 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name io-time:
[12/16/19 14:04:51:015 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-time-ns-avg, group=admin-client-metrics, description=The average length of time for I/O per select call in nanoseconds., tags={client-id=adminclient-1}]
[12/16/19 14:04:51:030 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=iotime-total, group=admin-client-metrics, description=The total time the I/O thread spent doing I/O, tags={client-id=adminclient-1}]
[12/16/19 14:04:51:048 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=io-ratio, group=admin-client-metrics, description=The fraction of time the I/O thread spent doing I/O, tags={client-id=adminclient-1}]
[12/16/19 14:04:51:050 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=connection-count, group=admin-client-metrics, description=The current number of active connections., tags={client-id=adminclient-1}]
[12/16/19 14:04:51:193 GMT] 00000047 id=00000000 org.apache.kafka.common.utils.AppInfoParser$AppInfo          I <init> Kafka version: 2.3.0
[12/16/19 14:04:51:197 GMT] 00000047 id=00000000 org.apache.kafka.common.utils.AppInfoParser$AppInfo          I <init> Kafka commitId: fc1aaa116b661c8a
[12/16/19 14:04:51:204 GMT] 00000047 id=00000000 org.apache.kafka.common.utils.AppInfoParser$AppInfo          I <init> Kafka startTimeMs: 1576505091178
[12/16/19 14:04:51:248 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=version, group=app-info, description=Metric indicating version, tags={client-id=adminclient-1}]
[12/16/19 14:04:51:258 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=commit-id, group=app-info, description=Metric indicating commit-id, tags={client-id=adminclient-1}]
[12/16/19 14:04:51:273 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=start-time-ms, group=app-info, description=Metric indicating start-time-ms, tags={client-id=adminclient-1}]
[12/16/19 14:04:51:275 GMT] 00000047 id=00000000 org.apache.kafka.clients.admin.KafkaAdminClient              1 <init> [AdminClient clientId=adminclient-1] Kafka admin client initialized
[12/16/19 14:04:51:410 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Thread starting
[12/16/19 14:04:51:417 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505091410
[12/16/19 14:04:51:426 GMT] 00000047 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505211392) with a timeout 120000 ms from now.
[12/16/19 14:04:51:427 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null) with no active connection
[12/16/19 14:04:51:428 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=fetchMetadata, deadlineMs=1576505211410) to node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null)
[12/16/19 14:04:51:469 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       1 initiateConnect [AdminClient clientId=adminclient-1] Initiating connection to node my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null) using address my-cluster-kafka-bootstrap.kafka/10.109.233.225
[12/16/19 14:04:51:470 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Client is not ready to send to my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null). Must delay 9223372036854775807 ms
[12/16/19 14:04:51:471 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=1200000)
[12/16/19 14:04:51:471 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node--1.bytes-sent
[12/16/19 14:04:51:473 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-total, group=admin-client-node-metrics, description=The total number of outgoing bytes, tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:474 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-rate, group=admin-client-node-metrics, description=The number of outgoing bytes per second, tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:474 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-total, group=admin-client-node-metrics, description=The total number of requests sent, tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:492 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-rate, group=admin-client-node-metrics, description=The number of requests sent per second, tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:493 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-avg, group=admin-client-node-metrics, description=The average size of requests sent., tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:504 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-max, group=admin-client-node-metrics, description=The maximum size of any request sent., tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:505 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node--1.bytes-received
[12/16/19 14:04:51:540 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-total, group=admin-client-node-metrics, description=The total number of incoming bytes, tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:545 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-rate, group=admin-client-node-metrics, description=The number of incoming bytes per second, tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:550 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-total, group=admin-client-node-metrics, description=The total number of responses received, tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:551 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-rate, group=admin-client-node-metrics, description=The number of responses received per second, tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:576 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node--1.latency
[12/16/19 14:04:51:577 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-avg, group=admin-client-node-metrics, description=, tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:577 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-max, group=admin-client-node-metrics, description=, tags={client-id=adminclient-1, node-id=node--1}]
[12/16/19 14:04:51:577 GMT] 0000004e id=00000000 org.apache.kafka.common.network.Selector                     1 pollSelectionKeys [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
[12/16/19 14:04:51:593 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleConnections [AdminClient clientId=adminclient-1] Completed connection to node -1. Fetching API versions.
[12/16/19 14:04:51:593 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleInitiateApiVersionRequests [AdminClient clientId=adminclient-1] Initiating API versions fetch from node -1.
[12/16/19 14:04:51:593 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] No version information found when sending API_VERSIONS with correlation id 0 to node -1. Assuming version 2.
[12/16/19 14:04:51:594 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending API_VERSIONS {} with correlation id 0 to node -1
[12/16/19 14:04:51:594 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:51:608 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505211392)] at 1576505091607
[12/16/19 14:04:51:608 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is not ready: we have not fetched metadata from the bootstrap nodes yet.
[12/16/19 14:04:51:608 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Unable to assign Call(callName=findAllBrokers, deadlineMs=1576505211392) to a node.
[12/16/19 14:04:51:608 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Client is not ready to send to my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null). Must delay 9223372036854775807 ms
[12/16/19 14:04:51:609 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=100)
[12/16/19 14:04:51:636 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:51:637 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505211392)] at 1576505091637
[12/16/19 14:04:51:637 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is not ready: we have not fetched metadata from the bootstrap nodes yet.
[12/16/19 14:04:51:637 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Unable to assign Call(callName=findAllBrokers, deadlineMs=1576505211392) to a node.
[12/16/19 14:04:51:637 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Client is not ready to send to my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null). Must delay 9223372036854775807 ms
[12/16/19 14:04:51:638 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=100)
[12/16/19 14:04:51:656 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node -1 for API_VERSIONS with correlation id 0, received {error_code=0,api_versions=[{api_key=0,min_version=0,max_version=7},{api_key=1,min_version=0,max_version=11},{api_key=2,min_version=0,max_version=5},{api_key=3,min_version=0,max_version=8},{api_key=4,min_version=0,max_version=2},{api_key=5,min_version=0,max_version=1},{api_key=6,min_version=0,max_version=5},{api_key=7,min_version=0,max_version=2},{api_key=8,min_version=0,max_version=7},{api_key=9,min_version=0,max_version=5},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=5},{api_key=12,min_version=0,max_version=3},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=3},{api_key=15,min_version=0,max_version=3},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=3},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=3},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=2},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=1},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1},{api_key=43,min_version=0,max_version=0},{api_key=44,min_version=0,max_version=0}],throttle_time_ms=0}
[12/16/19 14:04:51:669 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleApiVersionsResponse [AdminClient clientId=adminclient-1] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[12/16/19 14:04:51:679 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:51:680 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505211392)] at 1576505091679
[12/16/19 14:04:51:680 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is not ready: we have not fetched metadata from the bootstrap nodes yet.
[12/16/19 14:04:51:682 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Unable to assign Call(callName=findAllBrokers, deadlineMs=1576505211392) to a node.
[12/16/19 14:04:51:706 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-bootstrap.kafka:9092 (id: -1 rack: null). correlationId=1
[12/16/19 14:04:51:713 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 1 to node -1
[12/16/19 14:04:51:721 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=100)
[12/16/19 14:04:51:741 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:51:742 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505211392)] at 1576505091742
[12/16/19 14:04:51:742 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is not ready: we have not fetched metadata from the bootstrap nodes yet.
[12/16/19 14:04:51:742 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Unable to assign Call(callName=findAllBrokers, deadlineMs=1576505211392) to a node.
[12/16/19 14:04:51:742 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=100)
[12/16/19 14:04:51:742 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node -1 for METADATA with correlation id 1, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:04:51:742 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:04:51:765 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 1 update [AdminClient clientId=adminclient-1] Updating cluster metadata to Cluster(id = 7-jItNsIRea8d5lAaxlkjw, nodes = [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )], partitions = [], controller = my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ))
[12/16/19 14:04:51:766 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=fetchMetadata, deadlineMs=1576505211410) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:04:51:766 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505211392)] at 1576505091743
[12/16/19 14:04:51:766 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:04:51:767 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) with no active connection
[12/16/19 14:04:51:767 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505211392) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:51:789 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       1 initiateConnect [AdminClient clientId=adminclient-1] Initiating connection to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) using address my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local/172.17.0.8
[12/16/19 14:04:51:803 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Client is not ready to send to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). Must delay 9223372036854775807 ms
[12/16/19 14:04:51:803 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119649)
[12/16/19 14:04:51:804 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-0.bytes-sent
[12/16/19 14:04:51:804 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-total, group=admin-client-node-metrics, description=The total number of outgoing bytes, tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:804 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-rate, group=admin-client-node-metrics, description=The number of outgoing bytes per second, tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:805 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-total, group=admin-client-node-metrics, description=The total number of requests sent, tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:836 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-rate, group=admin-client-node-metrics, description=The number of requests sent per second, tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:837 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-avg, group=admin-client-node-metrics, description=The average size of requests sent., tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:837 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-max, group=admin-client-node-metrics, description=The maximum size of any request sent., tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:837 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-0.bytes-received
[12/16/19 14:04:51:857 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-total, group=admin-client-node-metrics, description=The total number of incoming bytes, tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:858 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-rate, group=admin-client-node-metrics, description=The number of incoming bytes per second, tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:858 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-total, group=admin-client-node-metrics, description=The total number of responses received, tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:858 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-rate, group=admin-client-node-metrics, description=The number of responses received per second, tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:858 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-0.latency
[12/16/19 14:04:51:859 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-avg, group=admin-client-node-metrics, description=, tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:869 GMT] 0000004e id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-max, group=admin-client-node-metrics, description=, tags={client-id=adminclient-1, node-id=node-0}]
[12/16/19 14:04:51:869 GMT] 0000004e id=00000000 org.apache.kafka.common.network.Selector                     1 pollSelectionKeys [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
[12/16/19 14:04:51:880 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleConnections [AdminClient clientId=adminclient-1] Completed connection to node 0. Fetching API versions.
[12/16/19 14:04:51:880 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleInitiateApiVersionRequests [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 0.
[12/16/19 14:04:51:880 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] No version information found when sending API_VERSIONS with correlation id 2 to node 0. Assuming version 2.
[12/16/19 14:04:51:887 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending API_VERSIONS {} with correlation id 2 to node 0
[12/16/19 14:04:51:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:51:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505091888
[12/16/19 14:04:51:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Client is not ready to send to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). Must delay 9223372036854775807 ms
[12/16/19 14:04:51:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119504)
[12/16/19 14:04:51:902 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:51:902 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505091902
[12/16/19 14:04:51:902 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Client is not ready to send to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). Must delay 9223372036854775807 ms
[12/16/19 14:04:51:902 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119490)
[12/16/19 14:04:51:925 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for API_VERSIONS with correlation id 2, received {error_code=0,api_versions=[{api_key=0,min_version=0,max_version=7},{api_key=1,min_version=0,max_version=11},{api_key=2,min_version=0,max_version=5},{api_key=3,min_version=0,max_version=8},{api_key=4,min_version=0,max_version=2},{api_key=5,min_version=0,max_version=1},{api_key=6,min_version=0,max_version=5},{api_key=7,min_version=0,max_version=2},{api_key=8,min_version=0,max_version=7},{api_key=9,min_version=0,max_version=5},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=5},{api_key=12,min_version=0,max_version=3},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=3},{api_key=15,min_version=0,max_version=3},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=3},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=3},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=2},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=1},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1},{api_key=43,min_version=0,max_version=0},{api_key=44,min_version=0,max_version=0}],throttle_time_ms=0}
[12/16/19 14:04:51:943 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleApiVersionsResponse [AdminClient clientId=adminclient-1] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[12/16/19 14:04:51:952 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:51:953 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505091953
[12/16/19 14:04:51:953 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=3
[12/16/19 14:04:51:953 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 3 to node 0
[12/16/19 14:04:51:967 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119439)
[12/16/19 14:04:51:972 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:51:999 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505091999
[12/16/19 14:04:52:000 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119393)
[12/16/19 14:04:52:012 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 3, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:04:52:023 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:04:52:054 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505211392) with a timeout 119342 ms from now.
[12/16/19 14:04:52:060 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505211392) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:04:52:062 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505211392)] at 1576505092023
[12/16/19 14:04:52:062 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:04:52:068 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505211392) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:52:068 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=4
[12/16/19 14:04:52:071 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 4 to node 0
[12/16/19 14:04:52:071 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119369)
[12/16/19 14:04:52:075 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:52:076 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505092076
[12/16/19 14:04:52:076 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119316)
[12/16/19 14:04:52:080 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 4, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:04:52:087 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:04:52:091 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505211392) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:04:52:092 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505092087
[12/16/19 14:04:52:092 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=299656)
[12/16/19 14:04:52:244 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for JOIN_GROUP with correlation id 5, received {throttle_time_ms=0,error_code=0,generation_id=115,protocol_name=range,leader=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,members=[{member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]}]}
[12/16/19 14:04:52:245 GMT] 00000046 id=00000000 sumer.internals.AbstractCoordinator$JoinGroupResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=115, protocolName='range', leader='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', members=[JoinGroupResponseMember(memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 0])])
[12/16/19 14:04:52:252 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 performAssignment [Consumer clientId=consumer-1, groupId=baristas] Performing assignment using strategy range with subscriptions {consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693=Subscription(topics=[orders])}
[12/16/19 14:04:52:260 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 performAssignment [Consumer clientId=consumer-1, groupId=baristas] Finished assignment for group: {consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693=Assignment(partitions=[orders-0, orders-1, orders-2, orders-3, orders-4])}
[12/16/19 14:04:52:279 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 onJoinLeader [Consumer clientId=consumer-1, groupId=baristas] Sending leader SyncGroup to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null): SyncGroupRequestData(groupId='baristas', generationId=115, memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', groupInstanceId='null', assignments=[SyncGroupRequestAssignment(memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', assignment=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 4, 0, 0, 0, 0])])
[12/16/19 14:04:52:305 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending SYNC_GROUP {group_id=baristas,generation_id=115,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,assignments=[{member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,assignment=java.nio.HeapByteBuffer[pos=0 lim=42 cap=42]}]} with correlation id 6 to node 2147483647
[12/16/19 14:04:52:326 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for SYNC_GROUP with correlation id 6, received {throttle_time_ms=0,error_code=0,assignment=java.nio.HeapByteBuffer[pos=0 lim=42 cap=42]}
[12/16/19 14:04:52:328 GMT] 00000046 id=00000000 pache.kafka.clients.consumer.internals.AbstractCoordinator$1 I onSuccess [Consumer clientId=consumer-1, groupId=baristas] Successfully joined group with generation 115
[12/16/19 14:04:52:329 GMT] 00000046 id=00000000 ients.consumer.internals.AbstractCoordinator$HeartbeatThread 1 enable [Consumer clientId=consumer-1, groupId=baristas] Enabling heartbeat thread
[12/16/19 14:04:52:381 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I onJoinComplete [Consumer clientId=consumer-1, groupId=baristas] Setting newly assigned partitions: orders-0, orders-1, orders-2, orders-3, orders-4
[12/16/19 14:04:52:387 GMT] 00000046 id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.AckTracker  1 5 new partitions 
                                                                                                               [orders-0, orders-1, orders-2, orders-3, orders-4]
[12/16/19 14:04:52:664 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 sendOffsetFetchRequest [Consumer clientId=consumer-1, groupId=baristas] Fetching committed offsets for partitions: [orders-0, orders-1, orders-2, orders-3, orders-4]
[12/16/19 14:04:52:666 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_FETCH {group_id=baristas,topics=[{topic=orders,partitions=[{partition=0},{partition=1},{partition=2},{partition=3},{partition=4}]}]} with correlation id 7 to node 2147483647
[12/16/19 14:04:52:668 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_FETCH with correlation id 7, received {throttle_time_ms=0,responses=[{topic=orders,partition_responses=[{partition=0,offset=258,leader_epoch=0,metadata=,error_code=0},{partition=1,offset=257,leader_epoch=0,metadata=,error_code=0},{partition=2,offset=257,leader_epoch=0,metadata=,error_code=0},{partition=3,offset=257,leader_epoch=0,metadata=,error_code=0},{partition=4,offset=257,leader_epoch=0,metadata=,error_code=0}]}],error_code=0}
[12/16/19 14:04:52:671 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I refreshCommittedOffsetsIfNeeded [Consumer clientId=consumer-1, groupId=baristas] Setting offset for partition orders-0 to the committed offset FetchPosition{offset=258, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:52:673 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:04:52:673 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:04:52:675 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I refreshCommittedOffsetsIfNeeded [Consumer clientId=consumer-1, groupId=baristas] Setting offset for partition orders-1 to the committed offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:52:675 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:04:52:676 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:04:52:676 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I refreshCommittedOffsetsIfNeeded [Consumer clientId=consumer-1, groupId=baristas] Setting offset for partition orders-2 to the committed offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:52:677 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:04:52:677 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:04:52:677 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I refreshCommittedOffsetsIfNeeded [Consumer clientId=consumer-1, groupId=baristas] Setting offset for partition orders-3 to the committed offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:52:677 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:04:52:678 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:04:52:678 GMT] 00000046 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I refreshCommittedOffsetsIfNeeded [Consumer clientId=consumer-1, groupId=baristas] Setting offset for partition orders-4 to the committed offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:52:678 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:04:52:679 GMT] 00000046 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:04:52:699 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       1 initiateConnect [Consumer clientId=consumer-1, groupId=baristas] Initiating connection to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) using address my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local/172.17.0.8
[12/16/19 14:04:52:718 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-0.bytes-sent
[12/16/19 14:04:52:724 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-total, group=consumer-node-metrics, description=The total number of outgoing bytes, tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:725 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-rate, group=consumer-node-metrics, description=The number of outgoing bytes per second, tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:726 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-total, group=consumer-node-metrics, description=The total number of requests sent, tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:729 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-rate, group=consumer-node-metrics, description=The number of requests sent per second, tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:733 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-avg, group=consumer-node-metrics, description=The average size of requests sent., tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:740 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-max, group=consumer-node-metrics, description=The maximum size of any request sent., tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:741 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-0.bytes-received
[12/16/19 14:04:52:741 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-total, group=consumer-node-metrics, description=The total number of incoming bytes, tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:745 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-rate, group=consumer-node-metrics, description=The number of incoming bytes per second, tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:746 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-total, group=consumer-node-metrics, description=The total number of responses received, tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:746 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-rate, group=consumer-node-metrics, description=The number of responses received per second, tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:747 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-0.latency
[12/16/19 14:04:52:747 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-avg, group=consumer-node-metrics, description=, tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:747 GMT] 0000004d id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-max, group=consumer-node-metrics, description=, tags={client-id=consumer-1, node-id=node-0}]
[12/16/19 14:04:52:748 GMT] 0000004d id=00000000 org.apache.kafka.common.network.Selector                     1 pollSelectionKeys [Consumer clientId=consumer-1, groupId=baristas] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
[12/16/19 14:04:52:748 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleConnections [Consumer clientId=consumer-1, groupId=baristas] Completed connection to node 0. Fetching API versions.
[12/16/19 14:04:52:748 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleInitiateApiVersionRequests [Consumer clientId=consumer-1, groupId=baristas] Initiating API versions fetch from node 0.
[12/16/19 14:04:52:748 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] No version information found when sending API_VERSIONS with correlation id 8 to node 0. Assuming version 2.
[12/16/19 14:04:52:752 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending API_VERSIONS {} with correlation id 8 to node 0
[12/16/19 14:04:52:765 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for API_VERSIONS with correlation id 8, received {error_code=0,api_versions=[{api_key=0,min_version=0,max_version=7},{api_key=1,min_version=0,max_version=11},{api_key=2,min_version=0,max_version=5},{api_key=3,min_version=0,max_version=8},{api_key=4,min_version=0,max_version=2},{api_key=5,min_version=0,max_version=1},{api_key=6,min_version=0,max_version=5},{api_key=7,min_version=0,max_version=2},{api_key=8,min_version=0,max_version=7},{api_key=9,min_version=0,max_version=5},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=5},{api_key=12,min_version=0,max_version=3},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=3},{api_key=15,min_version=0,max_version=3},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=3},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=3},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=2},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=1},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1},{api_key=43,min_version=0,max_version=0},{api_key=44,min_version=0,max_version=0}],throttle_time_ms=0}
[12/16/19 14:04:52:769 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleApiVersionsResponse [Consumer clientId=consumer-1, groupId=baristas] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[12/16/19 14:04:52:788 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_FOR_LEADER_EPOCH {replica_id=-1,topics=[{topic=orders,partitions=[{partition=0,current_leader_epoch=0,leader_epoch=0},{partition=1,current_leader_epoch=0,leader_epoch=0},{partition=2,current_leader_epoch=0,leader_epoch=0},{partition=3,current_leader_epoch=0,leader_epoch=0},{partition=4,current_leader_epoch=0,leader_epoch=0}]}]} with correlation id 9 to node 0
[12/16/19 14:04:52:796 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for OFFSET_FOR_LEADER_EPOCH with correlation id 9, received {throttle_time_ms=0,topics=[{topic=orders,partitions=[{error_code=0,partition=0,leader_epoch=0,end_offset=268},{error_code=0,partition=1,leader_epoch=0,end_offset=267},{error_code=0,partition=2,leader_epoch=0,end_offset=267},{error_code=0,partition=3,leader_epoch=0,end_offset=267},{error_code=0,partition=4,leader_epoch=0,end_offset=267}]}]}
[12/16/19 14:04:52:880 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.AsyncClient$1    3 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Received OffsetsForLeaderEpochResponse (type=OffsetsForLeaderEpochResponse, , throttleTimeMs=0, epochEndOffsetsByPartition={orders-0=EpochEndOffset{error=NONE, leaderEpoch=0, endOffset=268}, orders-1=EpochEndOffset{error=NONE, leaderEpoch=0, endOffset=267}, orders-2=EpochEndOffset{error=NONE, leaderEpoch=0, endOffset=267}, orders-3=EpochEndOffset{error=NONE, leaderEpoch=0, endOffset=267}, orders-4=EpochEndOffset{error=NONE, leaderEpoch=0, endOffset=267}}) from broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:52:906 GMT] 00000046 id=00000000 kafka.clients.consumer.internals.OffsetsForLeaderEpochClient 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Handling OffsetsForLeaderEpoch response for orders-0. Got offset 268 for epoch 0
[12/16/19 14:04:52:906 GMT] 00000046 id=00000000 kafka.clients.consumer.internals.OffsetsForLeaderEpochClient 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Handling OffsetsForLeaderEpoch response for orders-1. Got offset 267 for epoch 0
[12/16/19 14:04:52:906 GMT] 00000046 id=00000000 kafka.clients.consumer.internals.OffsetsForLeaderEpochClient 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Handling OffsetsForLeaderEpoch response for orders-2. Got offset 267 for epoch 0
[12/16/19 14:04:52:921 GMT] 00000046 id=00000000 kafka.clients.consumer.internals.OffsetsForLeaderEpochClient 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Handling OffsetsForLeaderEpoch response for orders-3. Got offset 267 for epoch 0
[12/16/19 14:04:52:922 GMT] 00000046 id=00000000 kafka.clients.consumer.internals.OffsetsForLeaderEpochClient 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Handling OffsetsForLeaderEpoch response for orders-4. Got offset 267 for epoch 0
[12/16/19 14:04:53:240 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=258, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:53:244 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:53:249 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:53:250 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:53:254 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:53:256 GMT] 00000046 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 0 with (orders-0, orders-1, orders-2, orders-3, orders-4).
[12/16/19 14:04:53:262 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED FullFetchRequest(orders-0, orders-1, orders-2, orders-3, orders-4) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:53:267 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=0,session_epoch=0,topics=[{topic=orders,partitions=[{partition=0,current_leader_epoch=0,fetch_offset=258,log_start_offset=-1,partition_max_bytes=1048576},{partition=1,current_leader_epoch=0,fetch_offset=257,log_start_offset=-1,partition_max_bytes=1048576},{partition=2,current_leader_epoch=0,fetch_offset=257,log_start_offset=-1,partition_max_bytes=1048576},{partition=3,current_leader_epoch=0,fetch_offset=257,log_start_offset=-1,partition_max_bytes=1048576},{partition=4,current_leader_epoch=0,fetch_offset=257,log_start_offset=-1,partition_max_bytes=1048576}]}],forgotten_topics_data=[],rack_id=} with correlation id 10 to node 0
[12/16/19 14:04:53:269 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:53:270 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:53:270 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:53:270 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:53:270 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:54:298 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 10, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[{topic=orders,partition_responses=[{partition_header={partition=0,error_code=0,high_watermark=268,last_stable_offset=268,log_start_offset=0,aborted_transactions=null,preferred_read_replica=-1},record_set=[(record=DefaultRecord(offset=258, timestamp=1576504966065, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=259, timestamp=1576504966121, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=260, timestamp=1576504966164, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=261, timestamp=1576504966252, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=262, timestamp=1576504966676, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=263, timestamp=1576504966676, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=264, timestamp=1576504967413, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=265, timestamp=1576504967595, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=266, timestamp=1576504967765, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=267, timestamp=1576504967878, key=0 bytes, value=88 bytes))]},{partition_header={partition=1,error_code=0,high_watermark=267,last_stable_offset=267,log_start_offset=0,aborted_transactions=null,preferred_read_replica=-1},record_set=[(record=DefaultRecord(offset=257, timestamp=1576504966076, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=258, timestamp=1576504966137, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=259, timestamp=1576504966173, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=260, timestamp=1576504966261, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=261, timestamp=1576504966676, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=262, timestamp=1576504966716, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=263, timestamp=1576504967443, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=264, timestamp=1576504967641, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=265, timestamp=1576504967797, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=266, timestamp=1576504968000, key=0 bytes, value=88 bytes))]},{partition_header={partition=2,error_code=0,high_watermark=267,last_stable_offset=267,log_start_offset=0,aborted_transactions=null,preferred_read_replica=-1},record_set=[(record=DefaultRecord(offset=257, timestamp=1576504966082, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=258, timestamp=1576504966144, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=259, timestamp=1576504966192, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=260, timestamp=1576504966280, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=261, timestamp=1576504966676, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=262, timestamp=1576504967228, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=263, timestamp=1576504967464, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=264, timestamp=1576504967669, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=265, timestamp=1576504967851, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=266, timestamp=1576504968037, key=0 bytes, value=88 bytes))]},{partition_header={partition=3,error_code=0,high_watermark=267,last_stable_offset=267,log_start_offset=0,aborted_transactions=null,preferred_read_replica=-1},record_set=[(record=DefaultRecord(offset=257, timestamp=1576504966030, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=258, timestamp=1576504966090, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=259, timestamp=1576504966150, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=260, timestamp=1576504966227, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=261, timestamp=1576504966313, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=262, timestamp=1576504966676, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=263, timestamp=1576504967228, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=264, timestamp=1576504967474, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=265, timestamp=1576504967680, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=266, timestamp=1576504967862, key=0 bytes, value=88 bytes))]},{partition_header={partition=4,error_code=0,high_watermark=267,last_stable_offset=267,log_start_offset=0,aborted_transactions=null,preferred_read_replica=-1},record_set=[(record=DefaultRecord(offset=257, timestamp=1576504966056, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=258, timestamp=1576504966113, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=259, timestamp=1576504966156, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=260, timestamp=1576504966246, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=261, timestamp=1576504966327, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=262, timestamp=1576504966676, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=263, timestamp=1576504967242, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=264, timestamp=1576504967583, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=265, timestamp=1576504967725, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=266, timestamp=1576504967873, key=0 bytes, value=88 bytes))]}]}]}
[12/16/19 14:04:54:332 GMT] 00000046 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent a full fetch response that created a new incremental fetch session 425357323 with response=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:54:359 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher$1        1 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Fetch READ_UNCOMMITTED at offset 258 for partition orders-0 returned fetch data (error=NONE, highWaterMark=268, lastStableOffset = 268, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=1578)
[12/16/19 14:04:54:375 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher$1        1 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Fetch READ_UNCOMMITTED at offset 257 for partition orders-1 returned fetch data (error=NONE, highWaterMark=267, lastStableOffset = 267, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=1578)
[12/16/19 14:04:54:379 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher$1        1 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Fetch READ_UNCOMMITTED at offset 257 for partition orders-2 returned fetch data (error=NONE, highWaterMark=267, lastStableOffset = 267, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=1579)
[12/16/19 14:04:54:380 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher$1        1 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Fetch READ_UNCOMMITTED at offset 257 for partition orders-3 returned fetch data (error=NONE, highWaterMark=267, lastStableOffset = 267, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=1578)
[12/16/19 14:04:54:380 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher$1        1 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Fetch READ_UNCOMMITTED at offset 257 for partition orders-4 returned fetch data (error=NONE, highWaterMark=267, lastStableOffset = 267, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=1578)
[12/16/19 14:04:54:380 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Preparing to read 1578 bytes of data for partition orders-0 with offset FetchPosition{offset=258, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:54:418 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating high watermark for partition orders-0 to 268
[12/16/19 14:04:54:418 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating log start offset for partition orders-0 to 0
[12/16/19 14:04:54:419 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating last stable offset for partition orders-0 to 268
[12/16/19 14:04:54:557 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 fetchRecords [Consumer clientId=consumer-1, groupId=baristas] Returning fetched records at offset FetchPosition{offset=258, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} for assigned partition orders-0 and update position to FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:54:586 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name orders-0.records-lag
[12/16/19 14:04:54:590 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag, group=consumer-fetch-manager-metrics, description=The latest lag of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:04:54:590 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The max lag of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:04:54:592 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag-avg, group=consumer-fetch-manager-metrics, description=The average lag of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:04:54:592 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name orders-0.records-lead
[12/16/19 14:04:54:593 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead, group=consumer-fetch-manager-metrics, description=The latest lead of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:04:54:593 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The min lead of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:04:54:593 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead-avg, group=consumer-fetch-manager-metrics, description=The average lead of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:04:54:617 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Preparing to read 1578 bytes of data for partition orders-1 with offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:54:622 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating high watermark for partition orders-1 to 267
[12/16/19 14:04:54:622 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating log start offset for partition orders-1 to 0
[12/16/19 14:04:54:623 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating last stable offset for partition orders-1 to 267
[12/16/19 14:04:54:631 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 fetchRecords [Consumer clientId=consumer-1, groupId=baristas] Returning fetched records at offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} for assigned partition orders-1 and update position to FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:54:635 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name orders-1.records-lag
[12/16/19 14:04:54:636 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag, group=consumer-fetch-manager-metrics, description=The latest lag of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:04:54:637 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The max lag of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:04:54:637 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag-avg, group=consumer-fetch-manager-metrics, description=The average lag of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:04:54:638 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name orders-1.records-lead
[12/16/19 14:04:54:639 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead, group=consumer-fetch-manager-metrics, description=The latest lead of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:04:54:640 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The min lead of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:04:54:641 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead-avg, group=consumer-fetch-manager-metrics, description=The average lead of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:04:54:642 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Preparing to read 1579 bytes of data for partition orders-2 with offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:54:647 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating high watermark for partition orders-2 to 267
[12/16/19 14:04:54:648 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating log start offset for partition orders-2 to 0
[12/16/19 14:04:54:648 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating last stable offset for partition orders-2 to 267
[12/16/19 14:04:54:652 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 fetchRecords [Consumer clientId=consumer-1, groupId=baristas] Returning fetched records at offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} for assigned partition orders-2 and update position to FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:54:652 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name orders-2.records-lag
[12/16/19 14:04:54:653 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag, group=consumer-fetch-manager-metrics, description=The latest lag of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:04:54:658 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The max lag of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:04:54:659 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag-avg, group=consumer-fetch-manager-metrics, description=The average lag of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:04:54:660 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name orders-2.records-lead
[12/16/19 14:04:54:660 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead, group=consumer-fetch-manager-metrics, description=The latest lead of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:04:54:661 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The min lead of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:04:54:662 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead-avg, group=consumer-fetch-manager-metrics, description=The average lead of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:04:54:662 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Preparing to read 1578 bytes of data for partition orders-3 with offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:54:664 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating high watermark for partition orders-3 to 267
[12/16/19 14:04:54:669 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating log start offset for partition orders-3 to 0
[12/16/19 14:04:54:670 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating last stable offset for partition orders-3 to 267
[12/16/19 14:04:54:673 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 fetchRecords [Consumer clientId=consumer-1, groupId=baristas] Returning fetched records at offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} for assigned partition orders-3 and update position to FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:54:674 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name orders-3.records-lag
[12/16/19 14:04:54:678 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag, group=consumer-fetch-manager-metrics, description=The latest lag of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:04:54:679 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The max lag of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:04:54:680 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag-avg, group=consumer-fetch-manager-metrics, description=The average lag of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:04:54:680 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name orders-3.records-lead
[12/16/19 14:04:54:681 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead, group=consumer-fetch-manager-metrics, description=The latest lead of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:04:54:682 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The min lead of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:04:54:682 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead-avg, group=consumer-fetch-manager-metrics, description=The average lead of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:04:54:683 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Preparing to read 1578 bytes of data for partition orders-4 with offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:54:684 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating high watermark for partition orders-4 to 267
[12/16/19 14:04:54:684 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating log start offset for partition orders-4 to 0
[12/16/19 14:04:54:684 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating last stable offset for partition orders-4 to 267
[12/16/19 14:04:54:689 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name topic.orders.bytes-fetched
[12/16/19 14:04:54:692 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=fetch-size-avg, group=consumer-fetch-manager-metrics, description=The average number of bytes fetched per request for a topic, tags={client-id=consumer-1, topic=orders}]
[12/16/19 14:04:54:693 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=fetch-size-max, group=consumer-fetch-manager-metrics, description=The maximum number of bytes fetched per request for a topic, tags={client-id=consumer-1, topic=orders}]
[12/16/19 14:04:54:693 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=bytes-consumed-total, group=consumer-fetch-manager-metrics, description=The total number of bytes consumed for a topic, tags={client-id=consumer-1, topic=orders}]
[12/16/19 14:04:54:695 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=bytes-consumed-rate, group=consumer-fetch-manager-metrics, description=The average number of bytes consumed per second for a topic, tags={client-id=consumer-1, topic=orders}]
[12/16/19 14:04:54:695 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name topic.orders.records-fetched
[12/16/19 14:04:54:699 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-per-request-avg, group=consumer-fetch-manager-metrics, description=The average number of records in each request for a topic, tags={client-id=consumer-1, topic=orders}]
[12/16/19 14:04:54:701 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-consumed-total, group=consumer-fetch-manager-metrics, description=The total number of records consumed for a topic, tags={client-id=consumer-1, topic=orders}]
[12/16/19 14:04:54:703 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-consumed-rate, group=consumer-fetch-manager-metrics, description=The average number of records consumed per second for a topic, tags={client-id=consumer-1, topic=orders}]
[12/16/19 14:04:54:705 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 fetchRecords [Consumer clientId=consumer-1, groupId=baristas] Returning fetched records at offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} for assigned partition orders-4 and update position to FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:04:54:706 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name orders-4.records-lag
[12/16/19 14:04:54:708 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag, group=consumer-fetch-manager-metrics, description=The latest lag of the partition, tags={client-id=consumer-1, topic=orders, partition=4}]
[12/16/19 14:04:54:710 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The max lag of the partition, tags={client-id=consumer-1, topic=orders, partition=4}]
[12/16/19 14:04:54:716 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lag-avg, group=consumer-fetch-manager-metrics, description=The average lag of the partition, tags={client-id=consumer-1, topic=orders, partition=4}]
[12/16/19 14:04:54:716 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name orders-4.records-lead
[12/16/19 14:04:54:735 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead, group=consumer-fetch-manager-metrics, description=The latest lead of the partition, tags={client-id=consumer-1, topic=orders, partition=4}]
[12/16/19 14:04:54:763 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The min lead of the partition, tags={client-id=consumer-1, topic=orders, partition=4}]
[12/16/19 14:04:54:773 GMT] 00000046 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=records-lead-avg, group=consumer-fetch-manager-metrics, description=The average lead of the partition, tags={client-id=consumer-1, topic=orders, partition=4}]
[12/16/19 14:04:54:789 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:54:807 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:54:814 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:54:815 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:54:842 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:54:850 GMT] 00000046 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=1) for node 0. Added (), altered (orders-0, orders-1, orders-2, orders-3, orders-4), removed () out of (orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:54:863 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(orders-0, orders-1, orders-2, orders-3, orders-4), toForget=(), implied=()) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:54:864 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=1,topics=[{topic=orders,partitions=[{partition=0,current_leader_epoch=0,fetch_offset=268,log_start_offset=-1,partition_max_bytes=1048576},{partition=1,current_leader_epoch=0,fetch_offset=267,log_start_offset=-1,partition_max_bytes=1048576},{partition=2,current_leader_epoch=0,fetch_offset=267,log_start_offset=-1,partition_max_bytes=1048576},{partition=3,current_leader_epoch=0,fetch_offset=267,log_start_offset=-1,partition_max_bytes=1048576},{partition=4,current_leader_epoch=0,fetch_offset=267,log_start_offset=-1,partition_max_bytes=1048576}]}],forgotten_topics_data=[],rack_id=} with correlation id 11 to node 0
[12/16/19 14:04:55:366 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:04:55:500 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=115,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 12 to node 2147483647
[12/16/19 14:04:55:512 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 11, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:04:55:513 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:55:618 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 12, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:04:55:626 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:04:56:228 GMT] 00000046 id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order b2e07903-f955-417a-974a-188546fd5195
[12/16/19 14:04:56:236 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:237 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:237 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:241 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:241 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:242 GMT] 00000046 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=2) for node 0. Added (), altered (), removed () out of (orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:56:242 GMT] 00000046 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:242 GMT] 00000046 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=2,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 13 to node 0
[12/16/19 14:04:56:245 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:56:250 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:56:250 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:56:250 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:56:251 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:56:752 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 13, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:04:56:752 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:56:759 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:762 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:763 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:764 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:765 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:766 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=3) for node 0. Added (), altered (), removed () out of (orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:56:769 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:56:770 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=3,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 14 to node 0
[12/16/19 14:04:56:782 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:56:782 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:56:783 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:56:787 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:56:792 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:57:276 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 14, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:04:57:293 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:57:295 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:296 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:298 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:298 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:298 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:309 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=4) for node 0. Added (), altered (), removed () out of (orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:57:313 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:313 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=4,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 15 to node 0
[12/16/19 14:04:57:336 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order b2e07903-f955-417a-974a-188546fd5195 completed
[12/16/19 14:04:57:340 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:57:340 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:57:341 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:57:341 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:57:341 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:57:582 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 waitOnMetadata [Producer clientId=producer-1] Requesting metadata update for topic queue.
[12/16/19 14:04:57:585 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Producer clientId=producer-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) with no active connection
[12/16/19 14:04:57:588 GMT] 0000004a id=00000000 rg.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater 1 maybeUpdate [Producer clientId=producer-1] Initialize connection to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) for sending metadata request
[12/16/19 14:04:57:594 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       1 initiateConnect [Producer clientId=producer-1] Initiating connection to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) using address my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local/172.17.0.8
[12/16/19 14:04:57:596 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-0.bytes-sent
[12/16/19 14:04:57:597 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-total, group=producer-node-metrics, description=The total number of outgoing bytes, tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:597 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=outgoing-byte-rate, group=producer-node-metrics, description=The number of outgoing bytes per second, tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:603 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-total, group=producer-node-metrics, description=The total number of requests sent, tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:603 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-rate, group=producer-node-metrics, description=The number of requests sent per second, tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:604 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-avg, group=producer-node-metrics, description=The average size of requests sent., tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:604 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-size-max, group=producer-node-metrics, description=The maximum size of any request sent., tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:604 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-0.bytes-received
[12/16/19 14:04:57:609 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-total, group=producer-node-metrics, description=The total number of incoming bytes, tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:627 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=incoming-byte-rate, group=producer-node-metrics, description=The number of incoming bytes per second, tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:630 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-total, group=producer-node-metrics, description=The total number of responses received, tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:630 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=response-rate, group=producer-node-metrics, description=The number of responses received per second, tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:630 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name node-0.latency
[12/16/19 14:04:57:631 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-avg, group=producer-node-metrics, description=, tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:631 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=request-latency-max, group=producer-node-metrics, description=, tags={client-id=producer-1, node-id=node-0}]
[12/16/19 14:04:57:631 GMT] 0000004a id=00000000 org.apache.kafka.common.network.Selector                     1 pollSelectionKeys [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
[12/16/19 14:04:57:631 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleConnections [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
[12/16/19 14:04:57:632 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleInitiateApiVersionRequests [Producer clientId=producer-1] Initiating API versions fetch from node 0.
[12/16/19 14:04:57:643 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] No version information found when sending API_VERSIONS with correlation id 2 to node 0. Assuming version 2.
[12/16/19 14:04:57:643 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending API_VERSIONS {} with correlation id 2 to node 0
[12/16/19 14:04:57:644 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Producer clientId=producer-1] Found least loaded connecting node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:662 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Producer clientId=producer-1] Found least loaded connecting node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:665 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for API_VERSIONS with correlation id 2, received {error_code=0,api_versions=[{api_key=0,min_version=0,max_version=7},{api_key=1,min_version=0,max_version=11},{api_key=2,min_version=0,max_version=5},{api_key=3,min_version=0,max_version=8},{api_key=4,min_version=0,max_version=2},{api_key=5,min_version=0,max_version=1},{api_key=6,min_version=0,max_version=5},{api_key=7,min_version=0,max_version=2},{api_key=8,min_version=0,max_version=7},{api_key=9,min_version=0,max_version=5},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=5},{api_key=12,min_version=0,max_version=3},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=3},{api_key=15,min_version=0,max_version=3},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=3},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=3},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=2},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=1},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1},{api_key=43,min_version=0,max_version=0},{api_key=44,min_version=0,max_version=0}],throttle_time_ms=0}
[12/16/19 14:04:57:667 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       1 handleApiVersionsResponse [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 11 [usable: 11], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 8 [usable: 8], LeaderAndIsr(4): 0 to 2 [usable: 2], StopReplica(5): 0 to 1 [usable: 1], UpdateMetadata(6): 0 to 5 [usable: 5], ControlledShutdown(7): 0 to 2 [usable: 2], OffsetCommit(8): 0 to 7 [usable: 7], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 5 [usable: 5], Heartbeat(12): 0 to 3 [usable: 3], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 3 [usable: 3], DescribeGroups(15): 0 to 3 [usable: 3], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 to 1 [usable: 1], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): 0 [usable: 0], IncrementalAlterConfigs(44): 0 [usable: 0])
[12/16/19 14:04:57:667 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [Producer clientId=producer-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:04:57:667 GMT] 0000004a id=00000000 rg.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater 1 maybeUpdate [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='queue')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:667 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending METADATA {topics=[{name=queue}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 3 to node 0
[12/16/19 14:04:57:680 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for METADATA with correlation id 3, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[{error_code=0,name=queue,is_internal=false,partitions=[{error_code=0,partition_index=0,leader_id=0,leader_epoch=0,replica_nodes=[0],isr_nodes=[0],offline_replicas=[]}],topic_authorized_operations=0}],cluster_authorized_operations=0}
[12/16/19 14:04:57:684 GMT] 0000004a id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Producer clientId=producer-1] Determining if we should replace existing epoch null with new epoch 0
[12/16/19 14:04:57:684 GMT] 0000004a id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Producer clientId=producer-1] Updating last seen epoch from null to 0 for partition queue-0
[12/16/19 14:04:57:685 GMT] 0000004a id=00000000 org.apache.kafka.clients.Metadata                            1 update [Producer clientId=producer-1] Updated cluster metadata updateVersion 3 to MetadataCache{cluster=Cluster(id = 7-jItNsIRea8d5lAaxlkjw, nodes = [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )], partitions = [Partition(topic = queue, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])], controller = my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ))}
[12/16/19 14:04:57:689 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-3","orderId":"b2e07903-f955-417a-974a-188546fd5195","preparedBy":"Kyle"},"order":{"name":"Demo-3","orderId":"b2e07903-f955-417a-974a-188546fd5195","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@74a45bfb to topic queue partition 0
[12/16/19 14:04:57:695 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:04:57:817 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:04:57:834 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name topic.queue.records-per-batch
[12/16/19 14:04:57:834 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-send-total, group=producer-topic-metrics, description=The total number of records sent for a topic., tags={client-id=producer-1, topic=queue}]
[12/16/19 14:04:57:835 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-send-rate, group=producer-topic-metrics, description=The average number of records sent per second for a topic., tags={client-id=producer-1, topic=queue}]
[12/16/19 14:04:57:841 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 15, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:04:57:842 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:57:842 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:845 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:845 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:845 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:845 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:835 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name topic.queue.bytes
[12/16/19 14:04:57:847 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=byte-total, group=producer-topic-metrics, description=The total number of bytes sent for a topic., tags={client-id=producer-1, topic=queue}]
[12/16/19 14:04:57:847 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=byte-rate, group=producer-topic-metrics, description=The average number of bytes sent per second for a topic., tags={client-id=producer-1, topic=queue}]
[12/16/19 14:04:57:847 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name topic.queue.compression-rate
[12/16/19 14:04:57:846 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=5) for node 0. Added (), altered (), removed () out of (orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:57:849 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:57:849 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=5,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 16 to node 0
[12/16/19 14:04:57:850 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:57:851 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:57:861 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:57:861 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:57:861 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:57:848 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=compression-rate, group=producer-topic-metrics, description=The average compression rate of record batches for a topic., tags={client-id=producer-1, topic=queue}]
[12/16/19 14:04:57:862 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name topic.queue.record-retries
[12/16/19 14:04:57:862 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-retry-total, group=producer-topic-metrics, description=The total number of retried record sends for a topic, tags={client-id=producer-1, topic=queue}]
[12/16/19 14:04:57:863 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-retry-rate, group=producer-topic-metrics, description=The average per-second number of retried record sends for a topic, tags={client-id=producer-1, topic=queue}]
[12/16/19 14:04:57:863 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      1 sensor Added sensor with name topic.queue.record-errors
[12/16/19 14:04:57:863 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-error-total, group=producer-topic-metrics, description=The total number of record sends that resulted in errors for a topic, tags={client-id=producer-1, topic=queue}]
[12/16/19 14:04:57:864 GMT] 0000004a id=00000000 org.apache.kafka.common.metrics.Metrics                      3 registerMetric Registered metric named MetricName [name=record-error-rate, group=producer-topic-metrics, description=The average per-second number of record sends that resulted in errors for a topic, tags={client-id=producer-1, topic=queue}]
[12/16/19 14:04:57:864 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:04:57:890 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 4 to node 0
[12/16/19 14:04:57:891 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505097689, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:04:57:909 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 4, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3896,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:04:57:914 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order c8efe7b0-909f-40fb-ad04-e58ff7b77f39
[12/16/19 14:04:57:924 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 4
[12/16/19 14:04:57:933 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3896.
[12/16/19 14:04:58:392 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 16, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:04:58:393 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:58:394 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:04:58:399 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=115,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 17 to node 2147483647
[12/16/19 14:04:58:413 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:414 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:414 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:414 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:419 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:419 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=6) for node 0. Added (), altered (), removed () out of (orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:58:420 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:420 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=6,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 18 to node 0
[12/16/19 14:04:58:428 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 17, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:04:58:429 GMT] 00000028 id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:04:58:437 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:437 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:437 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:438 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:439 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:442 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:443 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:443 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:444 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:444 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:515 GMT] 0000004b id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:04:58:518 GMT] 00000028 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:04:58:522 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-0=OffsetAndMetadata{offset=259, leaderEpoch=0, metadata=''}}
[12/16/19 14:04:58:535 GMT] 00000028 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:04:58:535 GMT] 00000028 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:04:58:536 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-0=OffsetAndMetadata{offset=259, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:04:58:604 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=115,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=0,committed_offset=259,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 19 to node 2147483647
[12/16/19 14:04:58:675 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 19, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=0,error_code=0}]}]}
[12/16/19 14:04:58:676 GMT] 0000004d id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 259 for partition orders-0
[12/16/19 14:04:58:710 GMT] 00000028 id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-0=OffsetAndMetadata{offset=259, leaderEpoch=0, metadata=''}}
[12/16/19 14:04:58:733 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:734 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:742 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:744 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:744 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:746 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:746 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:746 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:746 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:746 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:935 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 18, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:04:58:943 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:58:973 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:973 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:976 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:977 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:977 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:983 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=7) for node 0. Added (), altered (), removed () out of (orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:58:983 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:58:984 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=7,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 20 to node 0
[12/16/19 14:04:58:997 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:998 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:998 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:998 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:58:998 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:59:498 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 20, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:04:59:498 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:59:503 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:59:503 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:59:504 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:59:509 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:59:509 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:59:509 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=8) for node 0. Added (), altered (), removed () out of (orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:04:59:509 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:59:514 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=8,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 21 to node 0
[12/16/19 14:04:59:525 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:59:525 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:59:529 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:59:529 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:59:529 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:04:59:894 GMT] 00000050 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505219894) with a timeout 120000 ms from now.
[12/16/19 14:04:59:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:59:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505219894)] at 1576505099896
[12/16/19 14:04:59:897 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:04:59:897 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:04:59:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505219894) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:59:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=5
[12/16/19 14:04:59:898 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 5 to node 0
[12/16/19 14:04:59:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119998)
[12/16/19 14:04:59:900 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:59:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505099901
[12/16/19 14:04:59:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119993)
[12/16/19 14:04:59:902 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 5, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:04:59:902 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:04:59:902 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505219894) with a timeout 119992 ms from now.
[12/16/19 14:04:59:902 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505219894) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:04:59:902 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505219894)] at 1576505099902
[12/16/19 14:04:59:902 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:04:59:902 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505219894) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:04:59:903 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=6
[12/16/19 14:04:59:909 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 6 to node 0
[12/16/19 14:04:59:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119992)
[12/16/19 14:04:59:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:04:59:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505099910
[12/16/19 14:04:59:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119984)
[12/16/19 14:04:59:911 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 6, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:04:59:921 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:04:59:921 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505219894) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:04:59:921 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505099921
[12/16/19 14:04:59:922 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=291822)
[12/16/19 14:05:00:020 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 21, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:05:00:023 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:05:00:029 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:029 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:029 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:029 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:030 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:030 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=9) for node 0. Added (), altered (), removed () out of (orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:05:00:030 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:030 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=9,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 22 to node 0
[12/16/19 14:05:00:041 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:00:041 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:00:041 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:00:042 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:00:053 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:00:534 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 22, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:05:00:535 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:05:00:537 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:538 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:538 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:538 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:539 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:539 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=10) for node 0. Added (), altered (), removed () out of (orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:05:00:539 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:00:540 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=10,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 23 to node 0
[12/16/19 14:05:00:542 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:00:543 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:00:545 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:00:545 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:00:545 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:048 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 23, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:05:01:048 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:05:01:060 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-0 at position FetchPosition{offset=268, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:061 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-1 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:061 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-2 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:061 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:061 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:061 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=11) for node 0. Added (), altered (), removed () out of (orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:05:01:062 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:064 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=11,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 24 to node 0
[12/16/19 14:05:01:079 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:085 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:085 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:085 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:085 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:405 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:01:407 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=115,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 25 to node 2147483647
[12/16/19 14:05:01:421 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-0 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:421 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-1 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:421 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-2 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:421 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:422 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:422 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 25, received {throttle_time_ms=0,error_code=27}
[12/16/19 14:05:01:426 GMT] 00000028 id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler I handle [Consumer clientId=consumer-1, groupId=baristas] Attempt to heartbeat failed since group is rebalancing
[12/16/19 14:05:01:427 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I onJoinPrepare [Consumer clientId=consumer-1, groupId=baristas] Revoking previously assigned partitions [orders-0, orders-1, orders-2, orders-3, orders-4]
[12/16/19 14:05:01:427 GMT] 00000028 id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.AckTracker  1 5 removed partitions 
                                                                                                               [orders-0, orders-1, orders-2, orders-3, orders-4]
[12/16/19 14:05:01:427 GMT] 00000028 id=00000000 ients.consumer.internals.AbstractCoordinator$HeartbeatThread 1 disable [Consumer clientId=consumer-1, groupId=baristas] Disabling heartbeat thread
[12/16/19 14:05:01:427 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator I sendJoinGroupRequest [Consumer clientId=consumer-1, groupId=baristas] (Re-)joining group
[12/16/19 14:05:01:431 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 metadata [Consumer clientId=consumer-1, groupId=baristas] Joining group with current subscription: [orders]
[12/16/19 14:05:01:431 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendJoinGroupRequest [Consumer clientId=consumer-1, groupId=baristas] Sending JoinGroup (JoinGroupRequestData(groupId='baristas', sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 0])])) to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:01:438 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending JOIN_GROUP {group_id=baristas,session_timeout_ms=10000,rebalance_timeout_ms=300000,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,protocol_type=consumer,protocols=[{name=range,metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]}]} with correlation id 26 to node 2147483647
[12/16/19 14:05:01:441 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for JOIN_GROUP with correlation id 26, received {throttle_time_ms=0,error_code=0,generation_id=116,protocol_name=range,leader=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,members=[{member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=91]},{member_id=consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9,group_instance_id=null,metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]}]}
[12/16/19 14:05:01:443 GMT] 00000028 id=00000000 sumer.internals.AbstractCoordinator$JoinGroupResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=116, protocolName='range', leader='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', members=[JoinGroupResponseMember(memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 0]), JoinGroupResponseMember(memberId='consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 0])])
[12/16/19 14:05:01:445 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 performAssignment [Consumer clientId=consumer-1, groupId=baristas] Performing assignment using strategy range with subscriptions {consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693=Subscription(topics=[orders]), consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9=Subscription(topics=[orders])}
[12/16/19 14:05:01:445 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 performAssignment [Consumer clientId=consumer-1, groupId=baristas] Finished assignment for group: {consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693=Assignment(partitions=[orders-3, orders-4]), consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9=Assignment(partitions=[orders-0, orders-1, orders-2])}
[12/16/19 14:05:01:450 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 onJoinLeader [Consumer clientId=consumer-1, groupId=baristas] Sending leader SyncGroup to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null): SyncGroupRequestData(groupId='baristas', generationId=116, memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', groupInstanceId='null', assignments=[SyncGroupRequestAssignment(memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', assignment=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 4, 0, 0, 0, 0]), SyncGroupRequestAssignment(memberId='consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9', assignment=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0])])
[12/16/19 14:05:01:452 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending SYNC_GROUP {group_id=baristas,generation_id=116,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,assignments=[{member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,assignment=java.nio.HeapByteBuffer[pos=0 lim=30 cap=30]},{member_id=consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9,assignment=java.nio.HeapByteBuffer[pos=0 lim=34 cap=34]}]} with correlation id 27 to node 2147483647
[12/16/19 14:05:01:457 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for SYNC_GROUP with correlation id 27, received {throttle_time_ms=0,error_code=0,assignment=java.nio.HeapByteBuffer[pos=0 lim=30 cap=30]}
[12/16/19 14:05:01:457 GMT] 00000028 id=00000000 pache.kafka.clients.consumer.internals.AbstractCoordinator$1 I onSuccess [Consumer clientId=consumer-1, groupId=baristas] Successfully joined group with generation 116
[12/16/19 14:05:01:458 GMT] 00000028 id=00000000 ients.consumer.internals.AbstractCoordinator$HeartbeatThread 1 enable [Consumer clientId=consumer-1, groupId=baristas] Enabling heartbeat thread
[12/16/19 14:05:01:464 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I onJoinComplete [Consumer clientId=consumer-1, groupId=baristas] Setting newly assigned partitions: orders-3, orders-4
[12/16/19 14:05:01:465 GMT] 00000028 id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.AckTracker  1 2 new partitions 
                                                                                                               [orders-3, orders-4]
[12/16/19 14:05:01:465 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 sendOffsetFetchRequest [Consumer clientId=consumer-1, groupId=baristas] Fetching committed offsets for partitions: [orders-3, orders-4]
[12/16/19 14:05:01:473 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_FETCH {group_id=baristas,topics=[{topic=orders,partitions=[{partition=3},{partition=4}]}]} with correlation id 28 to node 2147483647
[12/16/19 14:05:01:475 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_FETCH with correlation id 28, received {throttle_time_ms=0,responses=[{topic=orders,partition_responses=[{partition=3,offset=257,leader_epoch=0,metadata=,error_code=0},{partition=4,offset=257,leader_epoch=0,metadata=,error_code=0}]}],error_code=0}
[12/16/19 14:05:01:479 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I refreshCommittedOffsetsIfNeeded [Consumer clientId=consumer-1, groupId=baristas] Setting offset for partition orders-3 to the committed offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:05:01:480 GMT] 00000028 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:05:01:480 GMT] 00000028 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:05:01:480 GMT] 00000028 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I refreshCommittedOffsetsIfNeeded [Consumer clientId=consumer-1, groupId=baristas] Setting offset for partition orders-4 to the committed offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:05:01:480 GMT] 00000028 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:05:01:481 GMT] 00000028 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:05:01:481 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag, group=consumer-fetch-manager-metrics, description=The latest lag of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:05:01:490 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The max lag of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:05:01:496 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag-avg, group=consumer-fetch-manager-metrics, description=The average lag of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:05:01:498 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 removeSensor Removed sensor with name orders-0.records-lag
[12/16/19 14:05:01:506 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead, group=consumer-fetch-manager-metrics, description=The latest lead of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:05:01:506 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The min lead of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:05:01:507 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead-avg, group=consumer-fetch-manager-metrics, description=The average lead of the partition, tags={client-id=consumer-1, topic=orders, partition=0}]
[12/16/19 14:05:01:507 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 removeSensor Removed sensor with name orders-0.records-lead
[12/16/19 14:05:01:507 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag, group=consumer-fetch-manager-metrics, description=The latest lag of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:05:01:507 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The max lag of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:05:01:508 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag-avg, group=consumer-fetch-manager-metrics, description=The average lag of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:05:01:513 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 removeSensor Removed sensor with name orders-1.records-lag
[12/16/19 14:05:01:515 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead, group=consumer-fetch-manager-metrics, description=The latest lead of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:05:01:516 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The min lead of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:05:01:516 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead-avg, group=consumer-fetch-manager-metrics, description=The average lead of the partition, tags={client-id=consumer-1, topic=orders, partition=1}]
[12/16/19 14:05:01:516 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 removeSensor Removed sensor with name orders-1.records-lead
[12/16/19 14:05:01:516 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag, group=consumer-fetch-manager-metrics, description=The latest lag of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:05:01:516 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The max lag of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:05:01:517 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag-avg, group=consumer-fetch-manager-metrics, description=The average lag of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:05:01:517 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 removeSensor Removed sensor with name orders-2.records-lag
[12/16/19 14:05:01:517 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead, group=consumer-fetch-manager-metrics, description=The latest lead of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:05:01:517 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The min lead of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:05:01:518 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead-avg, group=consumer-fetch-manager-metrics, description=The average lead of the partition, tags={client-id=consumer-1, topic=orders, partition=2}]
[12/16/19 14:05:01:518 GMT] 00000028 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 removeSensor Removed sensor with name orders-2.records-lead
[12/16/19 14:05:01:521 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_FOR_LEADER_EPOCH {replica_id=-1,topics=[{topic=orders,partitions=[{partition=3,current_leader_epoch=0,leader_epoch=0},{partition=4,current_leader_epoch=0,leader_epoch=0}]}]} with correlation id 29 to node 0
[12/16/19 14:05:01:585 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 24, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:05:01:588 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for OFFSET_FOR_LEADER_EPOCH with correlation id 29, received {throttle_time_ms=0,topics=[{topic=orders,partitions=[{error_code=0,partition=3,leader_epoch=0,end_offset=267},{error_code=0,partition=4,leader_epoch=0,end_offset=267}]}]}
[12/16/19 14:05:01:589 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-0, orders-1, orders-2, orders-3, orders-4)
[12/16/19 14:05:01:589 GMT] 0000004d id=00000000 org.apache.kafka.clients.consumer.internals.AsyncClient$1    3 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Received OffsetsForLeaderEpochResponse (type=OffsetsForLeaderEpochResponse, , throttleTimeMs=0, epochEndOffsetsByPartition={orders-3=EpochEndOffset{error=NONE, leaderEpoch=0, endOffset=267}, orders-4=EpochEndOffset{error=NONE, leaderEpoch=0, endOffset=267}}) from broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:589 GMT] 0000004d id=00000000 kafka.clients.consumer.internals.OffsetsForLeaderEpochClient 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Handling OffsetsForLeaderEpoch response for orders-3. Got offset 267 for epoch 0
[12/16/19 14:05:01:589 GMT] 0000004d id=00000000 kafka.clients.consumer.internals.OffsetsForLeaderEpochClient 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Handling OffsetsForLeaderEpoch response for orders-4. Got offset 267 for epoch 0
[12/16/19 14:05:01:590 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:590 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:590 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=12) for node 0. Added (), altered (orders-3, orders-4), removed (orders-0, orders-1, orders-2) out of (orders-3, orders-4)
[12/16/19 14:05:01:591 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(orders-3, orders-4), toForget=(orders-0, orders-1, orders-2), implied=()) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:597 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=12,topics=[{topic=orders,partitions=[{partition=3,current_leader_epoch=0,fetch_offset=257,log_start_offset=-1,partition_max_bytes=1048576},{partition=4,current_leader_epoch=0,fetch_offset=257,log_start_offset=-1,partition_max_bytes=1048576}]}],forgotten_topics_data=[{topic=orders,partitions=[0,1,2]}],rack_id=} with correlation id 30 to node 0
[12/16/19 14:05:01:603 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:604 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:622 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 30, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[{topic=orders,partition_responses=[{partition_header={partition=3,error_code=0,high_watermark=267,last_stable_offset=267,log_start_offset=0,aborted_transactions=null,preferred_read_replica=-1},record_set=[(record=DefaultRecord(offset=257, timestamp=1576504966030, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=258, timestamp=1576504966090, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=259, timestamp=1576504966150, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=260, timestamp=1576504966227, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=261, timestamp=1576504966313, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=262, timestamp=1576504966676, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=263, timestamp=1576504967228, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=264, timestamp=1576504967474, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=265, timestamp=1576504967680, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=266, timestamp=1576504967862, key=0 bytes, value=88 bytes))]},{partition_header={partition=4,error_code=0,high_watermark=267,last_stable_offset=267,log_start_offset=0,aborted_transactions=null,preferred_read_replica=-1},record_set=[(record=DefaultRecord(offset=257, timestamp=1576504966056, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=258, timestamp=1576504966113, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=259, timestamp=1576504966156, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=260, timestamp=1576504966246, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=261, timestamp=1576504966327, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=262, timestamp=1576504966676, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=263, timestamp=1576504967242, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=264, timestamp=1576504967583, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=265, timestamp=1576504967725, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=266, timestamp=1576504967873, key=0 bytes, value=88 bytes))]}]}]}
[12/16/19 14:05:01:623 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(orders-3, orders-4)
[12/16/19 14:05:01:623 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher$1        1 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Fetch READ_UNCOMMITTED at offset 257 for partition orders-3 returned fetch data (error=NONE, highWaterMark=267, lastStableOffset = 267, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=1578)
[12/16/19 14:05:01:623 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher$1        1 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Fetch READ_UNCOMMITTED at offset 257 for partition orders-4 returned fetch data (error=NONE, highWaterMark=267, lastStableOffset = 267, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=1578)
[12/16/19 14:05:01:624 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Preparing to read 1578 bytes of data for partition orders-3 with offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:05:01:624 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating high watermark for partition orders-3 to 267
[12/16/19 14:05:01:624 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating log start offset for partition orders-3 to 0
[12/16/19 14:05:01:624 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating last stable offset for partition orders-3 to 267
[12/16/19 14:05:01:627 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 fetchRecords [Consumer clientId=consumer-1, groupId=baristas] Returning fetched records at offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} for assigned partition orders-3 and update position to FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:05:01:627 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Preparing to read 1578 bytes of data for partition orders-4 with offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:05:01:627 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating high watermark for partition orders-4 to 267
[12/16/19 14:05:01:627 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating log start offset for partition orders-4 to 0
[12/16/19 14:05:01:628 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating last stable offset for partition orders-4 to 267
[12/16/19 14:05:01:632 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 fetchRecords [Consumer clientId=consumer-1, groupId=baristas] Returning fetched records at offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} for assigned partition orders-4 and update position to FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:05:01:632 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:634 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:634 GMT] 00000028 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=13) for node 0. Added (), altered (orders-3, orders-4), removed () out of (orders-3, orders-4)
[12/16/19 14:05:01:634 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(orders-3, orders-4), toForget=(), implied=()) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:01:635 GMT] 00000028 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=13,topics=[{topic=orders,partitions=[{partition=3,current_leader_epoch=0,fetch_offset=267,log_start_offset=-1,partition_max_bytes=1048576},{partition=4,current_leader_epoch=0,fetch_offset=267,log_start_offset=-1,partition_max_bytes=1048576}]}],forgotten_topics_data=[],rack_id=} with correlation id 31 to node 0
[12/16/19 14:05:01:638 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:640 GMT] 00000028 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:641 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:642 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:01:749 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order c8efe7b0-909f-40fb-ad04-e58ff7b77f39 completed
[12/16/19 14:05:01:755 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-8","orderId":"c8efe7b0-909f-40fb-ad04-e58ff7b77f39","preparedBy":"Kyle"},"order":{"name":"Demo-8","orderId":"c8efe7b0-909f-40fb-ad04-e58ff7b77f39","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@f42383b9 to topic queue partition 0
[12/16/19 14:05:01:756 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:01:756 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:01:764 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:01:765 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 5 to node 0
[12/16/19 14:05:01:765 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505101755, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:05:01:768 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 5, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3897,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:01:768 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 5
[12/16/19 14:05:01:768 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3897.
[12/16/19 14:05:01:788 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 5b517918-e65a-4ccc-990b-2789436b407e
[12/16/19 14:05:02:137 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 31, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:05:02:139 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-3, orders-4)
[12/16/19 14:05:02:143 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:02:144 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:02:144 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=14) for node 0. Added (), altered (), removed () out of (orders-3, orders-4)
[12/16/19 14:05:02:144 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:02:145 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=14,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 32 to node 0
[12/16/19 14:05:02:149 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:02:149 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:02:649 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 32, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:05:02:649 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-3, orders-4)
[12/16/19 14:05:02:650 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:02:651 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:02:651 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=15) for node 0. Added (), altered (), removed () out of (orders-3, orders-4)
[12/16/19 14:05:02:651 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:02:651 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=15,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 33 to node 0
[12/16/19 14:05:02:656 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:02:656 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:03:153 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 33, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:05:03:153 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-3, orders-4)
[12/16/19 14:05:03:155 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:03:156 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:03:157 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=16) for node 0. Added (), altered (), removed () out of (orders-3, orders-4)
[12/16/19 14:05:03:157 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:03:158 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=16,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 34 to node 0
[12/16/19 14:05:03:161 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:03:162 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:03:670 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 34, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:05:03:678 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-3, orders-4)
[12/16/19 14:05:03:687 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:03:688 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:03:688 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=17) for node 0. Added (), altered (), removed () out of (orders-3, orders-4)
[12/16/19 14:05:03:692 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:03:693 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=17,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 35 to node 0
[12/16/19 14:05:03:705 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:03:705 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:03:772 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 5b517918-e65a-4ccc-990b-2789436b407e completed
[12/16/19 14:05:03:774 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-13","orderId":"5b517918-e65a-4ccc-990b-2789436b407e","preparedBy":"Kyle"},"order":{"name":"Demo-13","orderId":"5b517918-e65a-4ccc-990b-2789436b407e","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@84be06cd to topic queue partition 0
[12/16/19 14:05:03:774 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:03:775 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:03:779 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:03:783 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 6 to node 0
[12/16/19 14:05:03:786 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505103774, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:03:814 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 6, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3898,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:03:814 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 6
[12/16/19 14:05:03:814 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3898.
[12/16/19 14:05:03:828 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order b6fc2e49-834f-4894-8d8d-2ccd3a332306
[12/16/19 14:05:04:198 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 35, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:05:04:200 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-3, orders-4)
[12/16/19 14:05:04:201 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-3 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:04:201 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:04:201 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=18) for node 0. Added (), altered (), removed () out of (orders-3, orders-4)
[12/16/19 14:05:04:201 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-3, orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:04:201 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=18,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 36 to node 0
[12/16/19 14:05:04:206 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:04:206 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:04:464 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:04:470 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=116,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 37 to node 2147483647
[12/16/19 14:05:04:481 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-3 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:04:482 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:04:482 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 37, received {throttle_time_ms=0,error_code=27}
[12/16/19 14:05:04:483 GMT] 00000047 id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler I handle [Consumer clientId=consumer-1, groupId=baristas] Attempt to heartbeat failed since group is rebalancing
[12/16/19 14:05:04:483 GMT] 00000047 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I onJoinPrepare [Consumer clientId=consumer-1, groupId=baristas] Revoking previously assigned partitions [orders-3, orders-4]
[12/16/19 14:05:04:484 GMT] 00000047 id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.AckTracker  1 2 removed partitions 
                                                                                                               [orders-3, orders-4]
[12/16/19 14:05:04:484 GMT] 00000047 id=00000000 ients.consumer.internals.AbstractCoordinator$HeartbeatThread 1 disable [Consumer clientId=consumer-1, groupId=baristas] Disabling heartbeat thread
[12/16/19 14:05:04:484 GMT] 00000047 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator I sendJoinGroupRequest [Consumer clientId=consumer-1, groupId=baristas] (Re-)joining group
[12/16/19 14:05:04:485 GMT] 00000047 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 metadata [Consumer clientId=consumer-1, groupId=baristas] Joining group with current subscription: [orders]
[12/16/19 14:05:04:485 GMT] 00000047 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendJoinGroupRequest [Consumer clientId=consumer-1, groupId=baristas] Sending JoinGroup (JoinGroupRequestData(groupId='baristas', sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 0])])) to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:04:489 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending JOIN_GROUP {group_id=baristas,session_timeout_ms=10000,rebalance_timeout_ms=300000,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,protocol_type=consumer,protocols=[{name=range,metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]}]} with correlation id 38 to node 2147483647
[12/16/19 14:05:04:706 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 36, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:05:04:708 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-3, orders-4)
[12/16/19 14:05:06:148 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for JOIN_GROUP with correlation id 38, received {throttle_time_ms=0,error_code=0,generation_id=117,protocol_name=range,leader=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,members=[{member_id=consumer-1-1c1a9582-7ceb-4619-8950-2d60f387949e,group_instance_id=null,metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=164]},{member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=91]},{member_id=consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9,group_instance_id=null,metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]}]}
[12/16/19 14:05:06:149 GMT] 00000047 id=00000000 sumer.internals.AbstractCoordinator$JoinGroupResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=117, protocolName='range', leader='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', members=[JoinGroupResponseMember(memberId='consumer-1-1c1a9582-7ceb-4619-8950-2d60f387949e', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 0]), JoinGroupResponseMember(memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 0]), JoinGroupResponseMember(memberId='consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 0])])
[12/16/19 14:05:06:149 GMT] 00000047 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 performAssignment [Consumer clientId=consumer-1, groupId=baristas] Performing assignment using strategy range with subscriptions {consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693=Subscription(topics=[orders]), consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9=Subscription(topics=[orders]), consumer-1-1c1a9582-7ceb-4619-8950-2d60f387949e=Subscription(topics=[orders])}
[12/16/19 14:05:06:155 GMT] 00000047 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 performAssignment [Consumer clientId=consumer-1, groupId=baristas] Finished assignment for group: {consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693=Assignment(partitions=[orders-4]), consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9=Assignment(partitions=[orders-2, orders-3]), consumer-1-1c1a9582-7ceb-4619-8950-2d60f387949e=Assignment(partitions=[orders-0, orders-1])}
[12/16/19 14:05:06:156 GMT] 00000047 id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 onJoinLeader [Consumer clientId=consumer-1, groupId=baristas] Sending leader SyncGroup to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null): SyncGroupRequestData(groupId='baristas', generationId=117, memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', groupInstanceId='null', assignments=[SyncGroupRequestAssignment(memberId='consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693', assignment=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 1, 0, 0, 0, 4, 0, 0, 0, 0]), SyncGroupRequestAssignment(memberId='consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9', assignment=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0]), SyncGroupRequestAssignment(memberId='consumer-1-1c1a9582-7ceb-4619-8950-2d60f387949e', assignment=[0, 0, 0, 0, 0, 1, 0, 6, 111, 114, 100, 101, 114, 115, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])])
[12/16/19 14:05:06:156 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending SYNC_GROUP {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,assignments=[{member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,assignment=java.nio.HeapByteBuffer[pos=0 lim=26 cap=26]},{member_id=consumer-1-21b368e5-8c66-4abb-b666-74cdfa8404c9,assignment=java.nio.HeapByteBuffer[pos=0 lim=30 cap=30]},{member_id=consumer-1-1c1a9582-7ceb-4619-8950-2d60f387949e,assignment=java.nio.HeapByteBuffer[pos=0 lim=30 cap=30]}]} with correlation id 39 to node 2147483647
[12/16/19 14:05:06:161 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for SYNC_GROUP with correlation id 39, received {throttle_time_ms=0,error_code=0,assignment=java.nio.HeapByteBuffer[pos=0 lim=26 cap=26]}
[12/16/19 14:05:06:162 GMT] 00000047 id=00000000 pache.kafka.clients.consumer.internals.AbstractCoordinator$1 I onSuccess [Consumer clientId=consumer-1, groupId=baristas] Successfully joined group with generation 117
[12/16/19 14:05:06:162 GMT] 00000047 id=00000000 ients.consumer.internals.AbstractCoordinator$HeartbeatThread 1 enable [Consumer clientId=consumer-1, groupId=baristas] Enabling heartbeat thread
[12/16/19 14:05:06:162 GMT] 00000047 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I onJoinComplete [Consumer clientId=consumer-1, groupId=baristas] Setting newly assigned partitions: orders-4
[12/16/19 14:05:06:170 GMT] 00000047 id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.AckTracker  1 1 new partitions 
                                                                                                               [orders-4]
[12/16/19 14:05:06:170 GMT] 00000047 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 1 sendOffsetFetchRequest [Consumer clientId=consumer-1, groupId=baristas] Fetching committed offsets for partitions: [orders-4]
[12/16/19 14:05:06:179 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_FETCH {group_id=baristas,topics=[{topic=orders,partitions=[{partition=4}]}]} with correlation id 40 to node 2147483647
[12/16/19 14:05:06:180 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_FETCH with correlation id 40, received {throttle_time_ms=0,responses=[{topic=orders,partition_responses=[{partition=4,offset=257,leader_epoch=0,metadata=,error_code=0}]}],error_code=0}
[12/16/19 14:05:06:181 GMT] 00000047 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator I refreshCommittedOffsetsIfNeeded [Consumer clientId=consumer-1, groupId=baristas] Setting offset for partition orders-4 to the committed offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:05:06:181 GMT] 00000047 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:05:06:181 GMT] 00000047 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:05:06:194 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag, group=consumer-fetch-manager-metrics, description=The latest lag of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:05:06:195 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag-max, group=consumer-fetch-manager-metrics, description=The max lag of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:05:06:195 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lag-avg, group=consumer-fetch-manager-metrics, description=The average lag of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:05:06:195 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 removeSensor Removed sensor with name orders-3.records-lag
[12/16/19 14:05:06:195 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead, group=consumer-fetch-manager-metrics, description=The latest lead of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:05:06:196 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead-min, group=consumer-fetch-manager-metrics, description=The min lead of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:05:06:204 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      3 removeMetric Removed metric named MetricName [name=records-lead-avg, group=consumer-fetch-manager-metrics, description=The average lead of the partition, tags={client-id=consumer-1, topic=orders, partition=3}]
[12/16/19 14:05:06:205 GMT] 00000047 id=00000000 org.apache.kafka.common.metrics.Metrics                      1 removeSensor Removed sensor with name orders-3.records-lead
[12/16/19 14:05:06:210 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_FOR_LEADER_EPOCH {replica_id=-1,topics=[{topic=orders,partitions=[{partition=4,current_leader_epoch=0,leader_epoch=0}]}]} with correlation id 41 to node 0
[12/16/19 14:05:06:222 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for OFFSET_FOR_LEADER_EPOCH with correlation id 41, received {throttle_time_ms=0,topics=[{topic=orders,partitions=[{error_code=0,partition=4,leader_epoch=0,end_offset=267}]}]}
[12/16/19 14:05:06:231 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.AsyncClient$1    3 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Received OffsetsForLeaderEpochResponse (type=OffsetsForLeaderEpochResponse, , throttleTimeMs=0, epochEndOffsetsByPartition={orders-4=EpochEndOffset{error=NONE, leaderEpoch=0, endOffset=267}}) from broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:06:231 GMT] 00000047 id=00000000 kafka.clients.consumer.internals.OffsetsForLeaderEpochClient 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Handling OffsetsForLeaderEpoch response for orders-4. Got offset 267 for epoch 0
[12/16/19 14:05:06:236 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:06:237 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=19) for node 0. Added (), altered (orders-4), removed (orders-3) out of (orders-4)
[12/16/19 14:05:06:237 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(orders-4), toForget=(orders-3), implied=()) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:06:237 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=19,topics=[{topic=orders,partitions=[{partition=4,current_leader_epoch=0,fetch_offset=257,log_start_offset=-1,partition_max_bytes=1048576}]}],forgotten_topics_data=[{topic=orders,partitions=[3]}],rack_id=} with correlation id 42 to node 0
[12/16/19 14:05:06:252 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:05:06:270 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 42, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[{topic=orders,partition_responses=[{partition_header={partition=4,error_code=0,high_watermark=267,last_stable_offset=267,log_start_offset=0,aborted_transactions=null,preferred_read_replica=-1},record_set=[(record=DefaultRecord(offset=257, timestamp=1576504966056, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=258, timestamp=1576504966113, key=0 bytes, value=87 bytes)), (record=DefaultRecord(offset=259, timestamp=1576504966156, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=260, timestamp=1576504966246, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=261, timestamp=1576504966327, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=262, timestamp=1576504966676, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=263, timestamp=1576504967242, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=264, timestamp=1576504967583, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=265, timestamp=1576504967725, key=0 bytes, value=88 bytes)), (record=DefaultRecord(offset=266, timestamp=1576504967873, key=0 bytes, value=88 bytes))]}]}]}
[12/16/19 14:05:06:271 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(orders-4)
[12/16/19 14:05:06:271 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher$1        1 onSuccess [Consumer clientId=consumer-1, groupId=baristas] Fetch READ_UNCOMMITTED at offset 257 for partition orders-4 returned fetch data (error=NONE, highWaterMark=267, lastStableOffset = 267, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=1578)
[12/16/19 14:05:06:271 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Preparing to read 1578 bytes of data for partition orders-4 with offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:05:06:272 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating high watermark for partition orders-4 to 267
[12/16/19 14:05:06:285 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating log start offset for partition orders-4 to 0
[12/16/19 14:05:06:285 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 parseCompletedFetch [Consumer clientId=consumer-1, groupId=baristas] Updating last stable offset for partition orders-4 to 267
[12/16/19 14:05:06:292 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 fetchRecords [Consumer clientId=consumer-1, groupId=baristas] Returning fetched records at offset FetchPosition{offset=257, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} for assigned partition orders-4 and update position to FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}}
[12/16/19 14:05:06:293 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:06:293 GMT] 00000047 id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=20) for node 0. Added (), altered (orders-4), removed () out of (orders-4)
[12/16/19 14:05:06:293 GMT] 00000047 id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(orders-4), toForget=(), implied=()) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:06:293 GMT] 00000047 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=20,topics=[{topic=orders,partitions=[{partition=4,current_leader_epoch=0,fetch_offset=267,log_start_offset=-1,partition_max_bytes=1048576}]}],forgotten_topics_data=[],rack_id=} with correlation id 43 to node 0
[12/16/19 14:05:06:878 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 43, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:05:06:878 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:05:07:524 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order b6fc2e49-834f-4894-8d8d-2ccd3a332306 completed
[12/16/19 14:05:07:526 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-18","orderId":"b6fc2e49-834f-4894-8d8d-2ccd3a332306","preparedBy":"Kyle"},"order":{"name":"Demo-18","orderId":"b6fc2e49-834f-4894-8d8d-2ccd3a332306","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@66a948a9 to topic queue partition 0
[12/16/19 14:05:07:526 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:07:526 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:07:528 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:07:528 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 7 to node 0
[12/16/19 14:05:07:529 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505107526, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:07:531 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 7, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3899,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:07:531 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 7
[12/16/19 14:05:07:531 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3899.
[12/16/19 14:05:07:535 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 843a52fc-0375-4e50-ab7e-1ad4a872f0c0
[12/16/19 14:05:09:207 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:09:207 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 44 to node 2147483647
[12/16/19 14:05:09:311 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 44, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:09:312 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:09:905 GMT] 0000004b id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505229905) with a timeout 120000 ms from now.
[12/16/19 14:05:09:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:09:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505229905)] at 1576505109910
[12/16/19 14:05:09:910 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:09:910 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:05:09:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505229905) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:09:911 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=7
[12/16/19 14:05:09:911 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 7 to node 0
[12/16/19 14:05:09:912 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119995)
[12/16/19 14:05:09:913 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:09:913 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505109913
[12/16/19 14:05:09:914 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119992)
[12/16/19 14:05:09:915 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 7, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:09:916 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:09:916 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505229905) with a timeout 119989 ms from now.
[12/16/19 14:05:09:916 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505229905) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:09:918 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505229905)] at 1576505109916
[12/16/19 14:05:09:918 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:09:919 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505229905) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:09:919 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=8
[12/16/19 14:05:09:919 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 8 to node 0
[12/16/19 14:05:09:919 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119989)
[12/16/19 14:05:09:923 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:09:923 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505109923
[12/16/19 14:05:09:923 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119982)
[12/16/19 14:05:09:928 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 8, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:09:931 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:09:952 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505229905) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:09:952 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505109931
[12/16/19 14:05:09:952 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=281812)
[12/16/19 14:05:10:080 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 843a52fc-0375-4e50-ab7e-1ad4a872f0c0 completed
[12/16/19 14:05:10:083 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-23","orderId":"843a52fc-0375-4e50-ab7e-1ad4a872f0c0","preparedBy":"Kyle"},"order":{"name":"Demo-23","orderId":"843a52fc-0375-4e50-ab7e-1ad4a872f0c0","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@2854075f to topic queue partition 0
[12/16/19 14:05:10:086 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:10:086 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:10:087 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:10:098 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 8 to node 0
[12/16/19 14:05:10:100 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505110083, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:10:114 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 8, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3901,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:10:115 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 8
[12/16/19 14:05:10:115 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3901.
[12/16/19 14:05:10:124 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order f3613f72-e910-426d-98d2-ac7a8550d2cc
[12/16/19 14:05:12:262 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:12:263 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 45 to node 2147483647
[12/16/19 14:05:12:365 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 45, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:12:366 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:13:612 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order f3613f72-e910-426d-98d2-ac7a8550d2cc completed
[12/16/19 14:05:13:614 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-28","orderId":"f3613f72-e910-426d-98d2-ac7a8550d2cc","preparedBy":"Kyle"},"order":{"name":"Demo-28","orderId":"f3613f72-e910-426d-98d2-ac7a8550d2cc","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@af2972a0 to topic queue partition 0
[12/16/19 14:05:13:614 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:13:614 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:13:615 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:13:617 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 9 to node 0
[12/16/19 14:05:13:618 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505113613, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:13:622 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 9, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3904,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:13:623 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 9
[12/16/19 14:05:13:624 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 3da2f46f-c265-4637-9653-5f7e8401ef80
[12/16/19 14:05:13:624 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3904.
[12/16/19 14:05:15:316 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:15:316 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 46 to node 2147483647
[12/16/19 14:05:15:419 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 46, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:15:419 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:17:269 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 3da2f46f-c265-4637-9653-5f7e8401ef80 completed
[12/16/19 14:05:17:270 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-33","orderId":"3da2f46f-c265-4637-9653-5f7e8401ef80","preparedBy":"Kyle"},"order":{"name":"Demo-33","orderId":"3da2f46f-c265-4637-9653-5f7e8401ef80","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@82d4db6 to topic queue partition 0
[12/16/19 14:05:17:271 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:17:271 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:17:271 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:17:272 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 10 to node 0
[12/16/19 14:05:17:274 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 48038612-2cdd-477d-8264-f3791667b63a
[12/16/19 14:05:17:274 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505117270, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:17:276 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 10, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3907,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:17:277 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 10
[12/16/19 14:05:17:277 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3907.
[12/16/19 14:05:18:056 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 48038612-2cdd-477d-8264-f3791667b63a completed
[12/16/19 14:05:18:057 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-38","orderId":"48038612-2cdd-477d-8264-f3791667b63a","preparedBy":"Kyle"},"order":{"name":"Demo-38","orderId":"48038612-2cdd-477d-8264-f3791667b63a","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@70f07f21 to topic queue partition 0
[12/16/19 14:05:18:058 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:18:058 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:18:063 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 113c68e9-00e0-4ace-bb2c-93fffe158d9c
[12/16/19 14:05:18:065 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:18:079 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 11 to node 0
[12/16/19 14:05:18:080 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505118057, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:18:094 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 11, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3908,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:18:110 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 11
[12/16/19 14:05:18:115 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3908.
[12/16/19 14:05:18:355 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:18:358 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 47 to node 2147483647
[12/16/19 14:05:18:471 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 47, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:18:471 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:19:882 GMT] 00000053 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505239882) with a timeout 120000 ms from now.
[12/16/19 14:05:19:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:19:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505239882)] at 1576505119884
[12/16/19 14:05:19:884 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:19:884 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:05:19:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505239882) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:19:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=9
[12/16/19 14:05:19:885 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 9 to node 0
[12/16/19 14:05:19:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119998)
[12/16/19 14:05:19:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:19:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505119887
[12/16/19 14:05:19:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119995)
[12/16/19 14:05:19:888 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 9, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:19:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:19:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505239882) with a timeout 119994 ms from now.
[12/16/19 14:05:19:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505239882) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:19:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505239882)] at 1576505119888
[12/16/19 14:05:19:892 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:19:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505239882) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:19:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=10
[12/16/19 14:05:19:893 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 10 to node 0
[12/16/19 14:05:19:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119994)
[12/16/19 14:05:19:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:19:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505119897
[12/16/19 14:05:19:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119985)
[12/16/19 14:05:19:898 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 10, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:19:900 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:19:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505239882) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:19:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505119900
[12/16/19 14:05:19:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=271843)
[12/16/19 14:05:21:438 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:21:440 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 48 to node 2147483647
[12/16/19 14:05:21:552 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 48, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:21:552 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:22:466 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 113c68e9-00e0-4ace-bb2c-93fffe158d9c completed
[12/16/19 14:05:22:467 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-43","orderId":"113c68e9-00e0-4ace-bb2c-93fffe158d9c","preparedBy":"Kyle"},"order":{"name":"Demo-43","orderId":"113c68e9-00e0-4ace-bb2c-93fffe158d9c","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@e72dde0e to topic queue partition 0
[12/16/19 14:05:22:467 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:22:468 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:22:469 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:22:470 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 12 to node 0
[12/16/19 14:05:22:471 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505122467, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:22:472 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 12, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3913,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:22:473 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 12
[12/16/19 14:05:22:474 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3913.
[12/16/19 14:05:22:476 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order a3e38bfc-b803-4d9b-8a7b-02303276e11a
[12/16/19 14:05:24:525 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:24:526 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 49 to node 2147483647
[12/16/19 14:05:24:629 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 49, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:24:630 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:24:689 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order a3e38bfc-b803-4d9b-8a7b-02303276e11a completed
[12/16/19 14:05:24:690 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-48","orderId":"a3e38bfc-b803-4d9b-8a7b-02303276e11a","preparedBy":"Kyle"},"order":{"name":"Demo-48","orderId":"a3e38bfc-b803-4d9b-8a7b-02303276e11a","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@da02548d to topic queue partition 0
[12/16/19 14:05:24:691 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:24:692 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:24:693 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:24:695 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 13 to node 0
[12/16/19 14:05:24:696 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505124690, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:24:701 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 13, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3917,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:24:704 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 13
[12/16/19 14:05:24:705 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3917.
[12/16/19 14:05:24:713 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 8a941155-c161-4135-a534-7ff9b09292a3
[12/16/19 14:05:25:543 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 8a941155-c161-4135-a534-7ff9b09292a3 completed
[12/16/19 14:05:25:544 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-4","orderId":"8a941155-c161-4135-a534-7ff9b09292a3","preparedBy":"Kyle"},"order":{"name":"Demo-4","orderId":"8a941155-c161-4135-a534-7ff9b09292a3","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@f31267d8 to topic queue partition 0
[12/16/19 14:05:25:544 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:25:545 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:25:546 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:25:546 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 14 to node 0
[12/16/19 14:05:25:546 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505125544, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:05:25:548 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 14, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3918,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:25:548 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 14
[12/16/19 14:05:25:549 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3918.
[12/16/19 14:05:25:553 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 1fe739e2-b7e5-4da4-8465-0cb312be3336
[12/16/19 14:05:27:565 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:27:577 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 50 to node 2147483647
[12/16/19 14:05:27:679 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 50, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:27:679 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:28:544 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 1fe739e2-b7e5-4da4-8465-0cb312be3336 completed
[12/16/19 14:05:28:545 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-9","orderId":"1fe739e2-b7e5-4da4-8465-0cb312be3336","preparedBy":"Kyle"},"order":{"name":"Demo-9","orderId":"1fe739e2-b7e5-4da4-8465-0cb312be3336","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@98e107e5 to topic queue partition 0
[12/16/19 14:05:28:545 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:28:545 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:28:547 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order da9b15ab-36b8-4221-9692-788eaa1f43c9
[12/16/19 14:05:28:548 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:28:548 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 15 to node 0
[12/16/19 14:05:28:549 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505128545, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:05:28:551 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 15, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3922,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:28:551 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 15
[12/16/19 14:05:28:551 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3922.
[12/16/19 14:05:29:925 GMT] 00000057 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505249925) with a timeout 120000 ms from now.
[12/16/19 14:05:29:930 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:29:930 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505249925)] at 1576505129930
[12/16/19 14:05:29:930 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:29:931 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:05:29:931 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505249925) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:29:931 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=11
[12/16/19 14:05:29:931 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 11 to node 0
[12/16/19 14:05:29:932 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119995)
[12/16/19 14:05:29:933 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:29:933 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505129933
[12/16/19 14:05:29:933 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119992)
[12/16/19 14:05:29:934 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 11, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:29:934 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:29:934 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505249925) with a timeout 119991 ms from now.
[12/16/19 14:05:29:935 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505249925) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:29:936 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505249925)] at 1576505129934
[12/16/19 14:05:29:936 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:29:936 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505249925) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:29:936 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=12
[12/16/19 14:05:29:936 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 12 to node 0
[12/16/19 14:05:29:937 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119991)
[12/16/19 14:05:29:940 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:29:941 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505129941
[12/16/19 14:05:29:941 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119984)
[12/16/19 14:05:29:955 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 12, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:29:956 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:29:960 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505249925) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:29:960 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505129957
[12/16/19 14:05:29:960 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=261786)
[12/16/19 14:05:30:626 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:30:626 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 51 to node 2147483647
[12/16/19 14:05:30:730 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 51, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:30:730 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:32:437 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order da9b15ab-36b8-4221-9692-788eaa1f43c9 completed
[12/16/19 14:05:32:438 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-14","orderId":"da9b15ab-36b8-4221-9692-788eaa1f43c9","preparedBy":"Kyle"},"order":{"name":"Demo-14","orderId":"da9b15ab-36b8-4221-9692-788eaa1f43c9","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@f03fe346 to topic queue partition 0
[12/16/19 14:05:32:438 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:32:438 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:32:441 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:32:441 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 16 to node 0
[12/16/19 14:05:32:443 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505132438, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:32:445 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 16, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3926,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:32:445 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 16
[12/16/19 14:05:32:445 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3926.
[12/16/19 14:05:32:452 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order a5d41672-6540-48a7-a313-dabd773362a3
[12/16/19 14:05:33:721 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:33:763 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 52 to node 2147483647
[12/16/19 14:05:33:865 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 52, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:33:866 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:36:179 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order a5d41672-6540-48a7-a313-dabd773362a3 completed
[12/16/19 14:05:36:180 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-19","orderId":"a5d41672-6540-48a7-a313-dabd773362a3","preparedBy":"Kyle"},"order":{"name":"Demo-19","orderId":"a5d41672-6540-48a7-a313-dabd773362a3","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@f5c67abc to topic queue partition 0
[12/16/19 14:05:36:181 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:36:181 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:36:182 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:36:183 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 17 to node 0
[12/16/19 14:05:36:183 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505136180, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:36:185 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 17, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3931,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:36:192 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 17
[12/16/19 14:05:36:192 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3931.
[12/16/19 14:05:36:198 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 61a9123c-bade-46a1-b67d-e6e782f9a2c1
[12/16/19 14:05:36:803 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:36:803 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 53 to node 2147483647
[12/16/19 14:05:36:905 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 53, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:36:905 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:39:853 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:39:854 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 54 to node 2147483647
[12/16/19 14:05:39:883 GMT] 00000058 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505259883) with a timeout 120000 ms from now.
[12/16/19 14:05:39:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:39:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505259883)] at 1576505139886
[12/16/19 14:05:39:886 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:39:886 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:05:39:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505259883) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:39:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=13
[12/16/19 14:05:39:887 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 13 to node 0
[12/16/19 14:05:39:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119997)
[12/16/19 14:05:39:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:39:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505139888
[12/16/19 14:05:39:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119995)
[12/16/19 14:05:39:889 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 13, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:39:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:39:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505259883) with a timeout 119994 ms from now.
[12/16/19 14:05:39:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505259883) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:39:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505259883)] at 1576505139889
[12/16/19 14:05:39:889 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:39:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505259883) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:39:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=14
[12/16/19 14:05:39:889 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 14 to node 0
[12/16/19 14:05:39:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119994)
[12/16/19 14:05:39:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:39:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505139890
[12/16/19 14:05:39:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119993)
[12/16/19 14:05:39:891 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 14, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:39:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:39:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505259883) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:39:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505139891
[12/16/19 14:05:39:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=251852)
[12/16/19 14:05:39:955 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 54, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:39:955 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:40:325 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 61a9123c-bade-46a1-b67d-e6e782f9a2c1 completed
[12/16/19 14:05:40:326 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-24","orderId":"61a9123c-bade-46a1-b67d-e6e782f9a2c1","preparedBy":"Kyle"},"order":{"name":"Demo-24","orderId":"61a9123c-bade-46a1-b67d-e6e782f9a2c1","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@757e235c to topic queue partition 0
[12/16/19 14:05:40:327 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:40:327 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:40:330 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:40:331 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 18 to node 0
[12/16/19 14:05:40:332 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505140326, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:40:334 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 18, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3935,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:40:334 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 18
[12/16/19 14:05:40:334 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3935.
[12/16/19 14:05:40:350 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 38266dbb-c623-471a-8590-6880e55141ab
[12/16/19 14:05:40:831 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 38266dbb-c623-471a-8590-6880e55141ab completed
[12/16/19 14:05:40:844 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-29","orderId":"38266dbb-c623-471a-8590-6880e55141ab","preparedBy":"Kyle"},"order":{"name":"Demo-29","orderId":"38266dbb-c623-471a-8590-6880e55141ab","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@36dbf35c to topic queue partition 0
[12/16/19 14:05:40:844 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:40:845 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:40:847 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:40:847 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 19 to node 0
[12/16/19 14:05:40:848 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505140844, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:40:850 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 19, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3936,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:40:850 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 19
[12/16/19 14:05:40:851 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3936.
[12/16/19 14:05:40:860 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 3b6dedd8-0e3b-4df0-a282-a91183de48bd
[12/16/19 14:05:42:349 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 3b6dedd8-0e3b-4df0-a282-a91183de48bd completed
[12/16/19 14:05:42:350 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-34","orderId":"3b6dedd8-0e3b-4df0-a282-a91183de48bd","preparedBy":"Kyle"},"order":{"name":"Demo-34","orderId":"3b6dedd8-0e3b-4df0-a282-a91183de48bd","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@8a223fa9 to topic queue partition 0
[12/16/19 14:05:42:350 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:42:350 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:42:351 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:42:352 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 20 to node 0
[12/16/19 14:05:42:352 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505142350, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:42:354 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 20, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3937,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:42:354 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 20
[12/16/19 14:05:42:355 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3937.
[12/16/19 14:05:42:360 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 7a03f4b5-985e-41b9-8d35-ff50b0e87dd1
[12/16/19 14:05:42:874 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:42:875 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 55 to node 2147483647
[12/16/19 14:05:42:990 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 55, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:42:990 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:44:088 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 7a03f4b5-985e-41b9-8d35-ff50b0e87dd1 completed
[12/16/19 14:05:44:089 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-39","orderId":"7a03f4b5-985e-41b9-8d35-ff50b0e87dd1","preparedBy":"Kyle"},"order":{"name":"Demo-39","orderId":"7a03f4b5-985e-41b9-8d35-ff50b0e87dd1","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@b0a8cfe9 to topic queue partition 0
[12/16/19 14:05:44:089 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:44:093 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:44:100 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:44:101 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 21 to node 0
[12/16/19 14:05:44:102 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505144089, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:44:110 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 21, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3940,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:44:115 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 21
[12/16/19 14:05:44:115 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3940.
[12/16/19 14:05:44:120 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order ad65c8b4-cb3d-4f38-98ad-b703602d6bdc
[12/16/19 14:05:45:943 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:45:944 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 56 to node 2147483647
[12/16/19 14:05:46:046 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 56, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:46:046 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:46:311 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order ad65c8b4-cb3d-4f38-98ad-b703602d6bdc completed
[12/16/19 14:05:46:317 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-44","orderId":"ad65c8b4-cb3d-4f38-98ad-b703602d6bdc","preparedBy":"Kyle"},"order":{"name":"Demo-44","orderId":"ad65c8b4-cb3d-4f38-98ad-b703602d6bdc","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@7e980f1d to topic queue partition 0
[12/16/19 14:05:46:318 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:46:318 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:46:319 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:46:320 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 22 to node 0
[12/16/19 14:05:46:321 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505146317, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:46:324 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 22, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3943,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:46:324 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 22
[12/16/19 14:05:46:324 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3943.
[12/16/19 14:05:46:328 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order fc703905-a0f1-40ae-896e-a42859069518
[12/16/19 14:05:48:967 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:48:969 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 57 to node 2147483647
[12/16/19 14:05:49:072 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 57, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:49:073 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:49:902 GMT] 00000062 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505269902) with a timeout 120000 ms from now.
[12/16/19 14:05:49:904 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:49:905 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505269902)] at 1576505149905
[12/16/19 14:05:49:905 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:49:906 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:05:49:906 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505269902) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:49:906 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=15
[12/16/19 14:05:49:907 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 15 to node 0
[12/16/19 14:05:49:907 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119997)
[12/16/19 14:05:49:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:49:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505149909
[12/16/19 14:05:49:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119993)
[12/16/19 14:05:49:910 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 15, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:49:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:49:911 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505269902) with a timeout 119991 ms from now.
[12/16/19 14:05:49:911 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505269902) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:49:911 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505269902)] at 1576505149910
[12/16/19 14:05:49:911 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:49:912 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505269902) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:49:912 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=16
[12/16/19 14:05:49:912 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 16 to node 0
[12/16/19 14:05:49:913 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119992)
[12/16/19 14:05:49:914 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:49:914 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505149914
[12/16/19 14:05:49:914 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119988)
[12/16/19 14:05:49:915 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 16, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:49:915 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:49:922 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505269902) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:49:922 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505149915
[12/16/19 14:05:49:922 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=241828)
[12/16/19 14:05:50:050 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order fc703905-a0f1-40ae-896e-a42859069518 completed
[12/16/19 14:05:50:052 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-49","orderId":"fc703905-a0f1-40ae-896e-a42859069518","preparedBy":"Kyle"},"order":{"name":"Demo-49","orderId":"fc703905-a0f1-40ae-896e-a42859069518","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@61a09830 to topic queue partition 0
[12/16/19 14:05:50:052 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:50:058 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:50:061 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:50:064 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 23 to node 0
[12/16/19 14:05:50:066 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505150051, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:50:074 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 23, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3946,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:50:075 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 23
[12/16/19 14:05:50:075 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3946.
[12/16/19 14:05:50:118 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 1baaac47-4314-4629-8d3b-8cc982390019
[12/16/19 14:05:52:004 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 1baaac47-4314-4629-8d3b-8cc982390019 completed
[12/16/19 14:05:52:005 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-5","orderId":"1baaac47-4314-4629-8d3b-8cc982390019","preparedBy":"Kyle"},"order":{"name":"Demo-5","orderId":"1baaac47-4314-4629-8d3b-8cc982390019","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@b0f5c5ee to topic queue partition 0
[12/16/19 14:05:52:006 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:52:006 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:52:007 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:52:008 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 24 to node 0
[12/16/19 14:05:52:008 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505152005, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:05:52:013 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 53e4ee2b-8428-4539-bfb3-6db13669e009
[12/16/19 14:05:52:021 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:52:022 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 58 to node 2147483647
[12/16/19 14:05:52:028 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 24, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3949,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:52:028 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 24
[12/16/19 14:05:52:028 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3949.
[12/16/19 14:05:52:129 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 58, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:52:129 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:55:068 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:55:069 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 59 to node 2147483647
[12/16/19 14:05:55:171 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 59, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:55:171 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:57:010 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 53e4ee2b-8428-4539-bfb3-6db13669e009 completed
[12/16/19 14:05:57:011 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-10","orderId":"53e4ee2b-8428-4539-bfb3-6db13669e009","preparedBy":"Kyle"},"order":{"name":"Demo-10","orderId":"53e4ee2b-8428-4539-bfb3-6db13669e009","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@81b19a7c to topic queue partition 0
[12/16/19 14:05:57:011 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:57:012 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:57:012 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:57:013 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 25 to node 0
[12/16/19 14:05:57:014 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505157011, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:57:015 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 25, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3953,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:57:016 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 25
[12/16/19 14:05:57:016 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3953.
[12/16/19 14:05:57:024 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 6fd3a69b-9bae-47e9-938c-bb768a40207d
[12/16/19 14:05:58:101 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:05:58:101 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 60 to node 2147483647
[12/16/19 14:05:58:203 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 60, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:05:58:204 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:05:59:183 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 6fd3a69b-9bae-47e9-938c-bb768a40207d completed
[12/16/19 14:05:59:184 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-15","orderId":"6fd3a69b-9bae-47e9-938c-bb768a40207d","preparedBy":"Kyle"},"order":{"name":"Demo-15","orderId":"6fd3a69b-9bae-47e9-938c-bb768a40207d","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@e22749a8 to topic queue partition 0
[12/16/19 14:05:59:185 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:05:59:185 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:05:59:186 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:05:59:187 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 26 to node 0
[12/16/19 14:05:59:187 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505159184, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:05:59:189 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 26, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3955,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:05:59:189 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 26
[12/16/19 14:05:59:190 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3955.
[12/16/19 14:05:59:193 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 49ace5e5-5f0f-474b-a45c-7e0515624107
[12/16/19 14:05:59:883 GMT] 00000064 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505279883) with a timeout 120000 ms from now.
[12/16/19 14:05:59:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:59:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505279883)] at 1576505159885
[12/16/19 14:05:59:886 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:59:886 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:05:59:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505279883) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:59:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=17
[12/16/19 14:05:59:886 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 17 to node 0
[12/16/19 14:05:59:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119998)
[12/16/19 14:05:59:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:59:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505159887
[12/16/19 14:05:59:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119996)
[12/16/19 14:05:59:888 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 17, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:59:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:59:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505279883) with a timeout 119995 ms from now.
[12/16/19 14:05:59:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505279883) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:05:59:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505279883)] at 1576505159888
[12/16/19 14:05:59:889 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:05:59:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505279883) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:05:59:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=18
[12/16/19 14:05:59:889 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 18 to node 0
[12/16/19 14:05:59:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119995)
[12/16/19 14:05:59:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:05:59:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505159890
[12/16/19 14:05:59:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119993)
[12/16/19 14:05:59:890 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 18, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:59:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:05:59:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505279883) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:05:59:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505159891
[12/16/19 14:05:59:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=231852)
[12/16/19 14:06:01:132 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:01:133 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 61 to node 2147483647
[12/16/19 14:06:01:236 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 61, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:01:236 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:02:988 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 49ace5e5-5f0f-474b-a45c-7e0515624107 completed
[12/16/19 14:06:02:989 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-20","orderId":"49ace5e5-5f0f-474b-a45c-7e0515624107","preparedBy":"Kyle"},"order":{"name":"Demo-20","orderId":"49ace5e5-5f0f-474b-a45c-7e0515624107","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@e9ccec75 to topic queue partition 0
[12/16/19 14:06:02:989 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:02:989 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:02:990 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:02:991 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 27 to node 0
[12/16/19 14:06:02:993 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505162989, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:02:996 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 27, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3957,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:02:997 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 27
[12/16/19 14:06:02:997 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3957.
[12/16/19 14:06:03:003 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 9af3c14b-358a-41ad-8723-5fc2822b5e4e
[12/16/19 14:06:04:199 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:04:200 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 62 to node 2147483647
[12/16/19 14:06:04:304 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 62, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:04:304 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:06:932 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 9af3c14b-358a-41ad-8723-5fc2822b5e4e completed
[12/16/19 14:06:06:937 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-25","orderId":"9af3c14b-358a-41ad-8723-5fc2822b5e4e","preparedBy":"Kyle"},"order":{"name":"Demo-25","orderId":"9af3c14b-358a-41ad-8723-5fc2822b5e4e","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@df54a354 to topic queue partition 0
[12/16/19 14:06:06:937 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:06:938 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:06:941 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:06:941 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 28 to node 0
[12/16/19 14:06:06:943 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505166937, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:06:945 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 28, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3961,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:06:945 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 28
[12/16/19 14:06:06:946 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3961.
[12/16/19 14:06:06:964 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 9ecbf095-e997-46c8-9c0a-ed9763a85673
[12/16/19 14:06:07:187 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 9ecbf095-e997-46c8-9c0a-ed9763a85673 completed
[12/16/19 14:06:07:188 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-30","orderId":"9ecbf095-e997-46c8-9c0a-ed9763a85673","preparedBy":"Kyle"},"order":{"name":"Demo-30","orderId":"9ecbf095-e997-46c8-9c0a-ed9763a85673","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@b67cda42 to topic queue partition 0
[12/16/19 14:06:07:188 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:07:188 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:07:191 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:07:192 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 29 to node 0
[12/16/19 14:06:07:193 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505167188, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:07:197 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 29, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3962,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:07:197 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 29
[12/16/19 14:06:07:197 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3962.
[12/16/19 14:06:07:206 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order f4cac12c-aeae-4d99-8a2c-b6d9008d4b87
[12/16/19 14:06:07:217 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:07:218 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 63 to node 2147483647
[12/16/19 14:06:07:319 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 63, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:07:320 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:08:727 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order f4cac12c-aeae-4d99-8a2c-b6d9008d4b87 completed
[12/16/19 14:06:08:728 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-35","orderId":"f4cac12c-aeae-4d99-8a2c-b6d9008d4b87","preparedBy":"Kyle"},"order":{"name":"Demo-35","orderId":"f4cac12c-aeae-4d99-8a2c-b6d9008d4b87","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@a39bcee to topic queue partition 0
[12/16/19 14:06:08:729 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:08:729 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:08:730 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:08:733 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 30 to node 0
[12/16/19 14:06:08:733 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505168728, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:08:736 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 30, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3963,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:08:736 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 30
[12/16/19 14:06:08:736 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3963.
[12/16/19 14:06:08:749 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order c916d3cb-bd5e-41ad-b650-04714687c092
[12/16/19 14:06:09:884 GMT] 00000060 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505289884) with a timeout 120000 ms from now.
[12/16/19 14:06:09:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:09:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505289884)] at 1576505169886
[12/16/19 14:06:09:886 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:09:886 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:06:09:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505289884) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:09:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=19
[12/16/19 14:06:09:887 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 19 to node 0
[12/16/19 14:06:09:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119998)
[12/16/19 14:06:09:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:09:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505169891
[12/16/19 14:06:09:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119993)
[12/16/19 14:06:09:892 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 19, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:09:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:09:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505289884) with a timeout 119992 ms from now.
[12/16/19 14:06:09:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505289884) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:09:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505289884)] at 1576505169892
[12/16/19 14:06:09:893 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:09:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505289884) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:09:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=20
[12/16/19 14:06:09:894 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 20 to node 0
[12/16/19 14:06:09:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119992)
[12/16/19 14:06:09:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:09:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505169897
[12/16/19 14:06:09:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119987)
[12/16/19 14:06:09:898 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 20, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:09:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:09:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505289884) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:09:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505169898
[12/16/19 14:06:09:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=221845)
[12/16/19 14:06:10:254 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:10:254 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 64 to node 2147483647
[12/16/19 14:06:10:356 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 64, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:10:356 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:13:211 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order c916d3cb-bd5e-41ad-b650-04714687c092 completed
[12/16/19 14:06:13:212 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-40","orderId":"c916d3cb-bd5e-41ad-b650-04714687c092","preparedBy":"Kyle"},"order":{"name":"Demo-40","orderId":"c916d3cb-bd5e-41ad-b650-04714687c092","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@c96cf50a to topic queue partition 0
[12/16/19 14:06:13:212 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:13:212 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:13:216 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:13:217 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 31 to node 0
[12/16/19 14:06:13:218 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505173212, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:13:221 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 31, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3965,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:13:221 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 31
[12/16/19 14:06:13:221 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3965.
[12/16/19 14:06:13:234 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 925b5bff-7e57-4da0-a9c5-39ae8afd7554
[12/16/19 14:06:13:291 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:13:291 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 65 to node 2147483647
[12/16/19 14:06:13:393 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 65, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:13:397 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:16:313 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:16:314 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 66 to node 2147483647
[12/16/19 14:06:16:415 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 66, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:16:415 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:17:464 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 925b5bff-7e57-4da0-a9c5-39ae8afd7554 completed
[12/16/19 14:06:17:465 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-45","orderId":"925b5bff-7e57-4da0-a9c5-39ae8afd7554","preparedBy":"Kyle"},"order":{"name":"Demo-45","orderId":"925b5bff-7e57-4da0-a9c5-39ae8afd7554","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@904323e7 to topic queue partition 0
[12/16/19 14:06:17:465 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:17:468 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:17:473 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:17:474 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 32 to node 0
[12/16/19 14:06:17:475 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505177465, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:17:480 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 32, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3968,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:17:480 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 32
[12/16/19 14:06:17:480 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3968.
[12/16/19 14:06:17:503 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 99e35355-a239-431b-b3b8-10ce00b900c7
[12/16/19 14:06:19:372 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:19:372 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 67 to node 2147483647
[12/16/19 14:06:19:473 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 67, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:19:474 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:19:883 GMT] 00000064 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505299883) with a timeout 120000 ms from now.
[12/16/19 14:06:19:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:19:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505299883)] at 1576505179884
[12/16/19 14:06:19:884 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:19:885 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:06:19:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505299883) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:19:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=21
[12/16/19 14:06:19:885 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 21 to node 0
[12/16/19 14:06:19:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119999)
[12/16/19 14:06:19:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:19:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505179886
[12/16/19 14:06:19:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119997)
[12/16/19 14:06:19:887 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 21, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:19:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:19:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505299883) with a timeout 119996 ms from now.
[12/16/19 14:06:19:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505299883) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:19:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505299883)] at 1576505179887
[12/16/19 14:06:19:887 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:19:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505299883) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:19:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=22
[12/16/19 14:06:19:888 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 22 to node 0
[12/16/19 14:06:19:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119996)
[12/16/19 14:06:19:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:19:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505179889
[12/16/19 14:06:19:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119994)
[12/16/19 14:06:19:890 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 22, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:19:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:19:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505299883) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:19:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505179890
[12/16/19 14:06:19:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=211853)
[12/16/19 14:06:20:089 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 99e35355-a239-431b-b3b8-10ce00b900c7 completed
[12/16/19 14:06:20:090 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-50","orderId":"99e35355-a239-431b-b3b8-10ce00b900c7","preparedBy":"Kyle"},"order":{"name":"Demo-50","orderId":"99e35355-a239-431b-b3b8-10ce00b900c7","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@277e70c7 to topic queue partition 0
[12/16/19 14:06:20:090 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:20:090 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:20:091 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:20:092 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 33 to node 0
[12/16/19 14:06:20:093 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505180090, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:20:098 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 33, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3970,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:20:098 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 33
[12/16/19 14:06:20:098 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3970.
[12/16/19 14:06:20:111 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 654c1587-f7cb-47f2-b17d-ca292d765e70
[12/16/19 14:06:22:372 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 654c1587-f7cb-47f2-b17d-ca292d765e70 completed
[12/16/19 14:06:22:373 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-1","orderId":"654c1587-f7cb-47f2-b17d-ca292d765e70","preparedBy":"Kyle"},"order":{"name":"Demo-1","orderId":"654c1587-f7cb-47f2-b17d-ca292d765e70","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@e95f21b4 to topic queue partition 0
[12/16/19 14:06:22:373 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:22:373 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:22:374 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:22:375 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 34 to node 0
[12/16/19 14:06:22:375 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505182373, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:06:22:378 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 34, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3971,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:22:382 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 34
[12/16/19 14:06:22:382 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3971.
[12/16/19 14:06:22:387 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 4d016abb-4889-4323-a832-72425f6fba0a
[12/16/19 14:06:22:391 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:22:430 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 68 to node 2147483647
[12/16/19 14:06:22:540 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 68, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:22:540 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:23:520 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 4d016abb-4889-4323-a832-72425f6fba0a completed
[12/16/19 14:06:23:526 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-6","orderId":"4d016abb-4889-4323-a832-72425f6fba0a","preparedBy":"Kyle"},"order":{"name":"Demo-6","orderId":"4d016abb-4889-4323-a832-72425f6fba0a","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@24774a80 to topic queue partition 0
[12/16/19 14:06:23:527 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:23:527 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:23:533 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:23:533 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 35 to node 0
[12/16/19 14:06:23:534 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505183525, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:06:23:537 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 35, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3972,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:23:537 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 35
[12/16/19 14:06:23:538 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3972.
[12/16/19 14:06:23:543 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order d15673bc-a6e2-4b6b-9704-b6dafc315e1c
[12/16/19 14:06:25:400 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:25:401 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 69 to node 2147483647
[12/16/19 14:06:25:510 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 69, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:25:510 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:28:241 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order d15673bc-a6e2-4b6b-9704-b6dafc315e1c completed
[12/16/19 14:06:28:248 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-11","orderId":"d15673bc-a6e2-4b6b-9704-b6dafc315e1c","preparedBy":"Kyle"},"order":{"name":"Demo-11","orderId":"d15673bc-a6e2-4b6b-9704-b6dafc315e1c","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@4ad2050d to topic queue partition 0
[12/16/19 14:06:28:248 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:28:249 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:28:252 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:28:252 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 36 to node 0
[12/16/19 14:06:28:253 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505188248, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:28:267 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 36, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3974,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:28:269 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 36
[12/16/19 14:06:28:269 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3974.
[12/16/19 14:06:28:270 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order b6c84b83-ab74-4bbe-93c4-1cbaac7f1dbc
[12/16/19 14:06:28:434 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:28:435 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 70 to node 2147483647
[12/16/19 14:06:28:537 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 70, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:28:537 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:29:884 GMT] 0000006f id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505309884) with a timeout 120000 ms from now.
[12/16/19 14:06:29:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:29:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505309884)] at 1576505189886
[12/16/19 14:06:29:886 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:29:887 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:06:29:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505309884) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:29:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=23
[12/16/19 14:06:29:887 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 23 to node 0
[12/16/19 14:06:29:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119998)
[12/16/19 14:06:29:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:29:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505189890
[12/16/19 14:06:29:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119994)
[12/16/19 14:06:29:891 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 23, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:29:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:29:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505309884) with a timeout 119992 ms from now.
[12/16/19 14:06:29:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505309884) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:29:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505309884)] at 1576505189892
[12/16/19 14:06:29:892 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:29:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505309884) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:29:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=24
[12/16/19 14:06:29:894 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 24 to node 0
[12/16/19 14:06:29:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119992)
[12/16/19 14:06:29:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:29:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505189897
[12/16/19 14:06:29:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119987)
[12/16/19 14:06:29:900 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 24, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:29:903 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:29:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505309884) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:29:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505189903
[12/16/19 14:06:29:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=201840)
[12/16/19 14:06:31:466 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:31:469 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 71 to node 2147483647
[12/16/19 14:06:31:571 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 71, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:31:572 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:32:590 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order b6c84b83-ab74-4bbe-93c4-1cbaac7f1dbc completed
[12/16/19 14:06:32:591 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-16","orderId":"b6c84b83-ab74-4bbe-93c4-1cbaac7f1dbc","preparedBy":"Kyle"},"order":{"name":"Demo-16","orderId":"b6c84b83-ab74-4bbe-93c4-1cbaac7f1dbc","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@a2f8cd25 to topic queue partition 0
[12/16/19 14:06:32:592 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:32:592 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:32:593 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:32:594 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 37 to node 0
[12/16/19 14:06:32:594 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505192591, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:32:599 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 37, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3979,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:32:600 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 37
[12/16/19 14:06:32:600 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3979.
[12/16/19 14:06:32:608 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 0a834df1-8da5-4c73-b9b8-675b4b3d6319
[12/16/19 14:06:34:541 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:34:543 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 72 to node 2147483647
[12/16/19 14:06:34:648 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 72, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:34:650 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:36:228 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 0a834df1-8da5-4c73-b9b8-675b4b3d6319 completed
[12/16/19 14:06:36:230 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-21","orderId":"0a834df1-8da5-4c73-b9b8-675b4b3d6319","preparedBy":"Kyle"},"order":{"name":"Demo-21","orderId":"0a834df1-8da5-4c73-b9b8-675b4b3d6319","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@152e4654 to topic queue partition 0
[12/16/19 14:06:36:231 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:36:231 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:36:233 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:36:234 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 38 to node 0
[12/16/19 14:06:36:235 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505196229, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:36:241 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 38, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3981,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:36:241 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 38
[12/16/19 14:06:36:242 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3981.
[12/16/19 14:06:36:244 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 26bb92db-867d-4fb6-9038-c4ae4d2f753f
[12/16/19 14:06:37:563 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:37:563 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 73 to node 2147483647
[12/16/19 14:06:37:673 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 73, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:37:680 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:38:753 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 26bb92db-867d-4fb6-9038-c4ae4d2f753f completed
[12/16/19 14:06:38:754 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-26","orderId":"26bb92db-867d-4fb6-9038-c4ae4d2f753f","preparedBy":"Kyle"},"order":{"name":"Demo-26","orderId":"26bb92db-867d-4fb6-9038-c4ae4d2f753f","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@4af1e862 to topic queue partition 0
[12/16/19 14:06:38:754 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:38:754 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:38:760 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:38:763 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 39 to node 0
[12/16/19 14:06:38:764 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505198754, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:38:770 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 39, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3984,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:38:770 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 39
[12/16/19 14:06:38:770 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3984.
[12/16/19 14:06:38:779 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 40e84f81-2daf-44bb-b6b3-4289fc05323e
[12/16/19 14:06:39:745 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 40e84f81-2daf-44bb-b6b3-4289fc05323e completed
[12/16/19 14:06:39:745 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-31","orderId":"40e84f81-2daf-44bb-b6b3-4289fc05323e","preparedBy":"Kyle"},"order":{"name":"Demo-31","orderId":"40e84f81-2daf-44bb-b6b3-4289fc05323e","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@d9d99abe to topic queue partition 0
[12/16/19 14:06:39:746 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:39:746 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:39:750 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:39:750 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 40 to node 0
[12/16/19 14:06:39:751 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505199745, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:39:754 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 40, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3985,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:39:757 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 40
[12/16/19 14:06:39:757 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3985.
[12/16/19 14:06:39:761 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 968527a8-fe49-49b2-8898-9e0815fd653b
[12/16/19 14:06:39:885 GMT] 00000078 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505319885) with a timeout 120000 ms from now.
[12/16/19 14:06:39:930 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:39:930 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505319885)] at 1576505199930
[12/16/19 14:06:39:931 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:39:931 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:06:39:931 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505319885) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:39:931 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=25
[12/16/19 14:06:39:931 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 25 to node 0
[12/16/19 14:06:39:932 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119955)
[12/16/19 14:06:39:932 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:39:933 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505199932
[12/16/19 14:06:39:933 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119953)
[12/16/19 14:06:39:971 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 25, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:39:971 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:39:972 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505319885) with a timeout 119914 ms from now.
[12/16/19 14:06:39:972 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505319885) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:39:972 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505319885)] at 1576505199971
[12/16/19 14:06:39:972 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:39:972 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505319885) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:39:972 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=26
[12/16/19 14:06:39:973 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 26 to node 0
[12/16/19 14:06:39:973 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119914)
[12/16/19 14:06:39:973 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:39:973 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505199973
[12/16/19 14:06:39:973 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119912)
[12/16/19 14:06:39:977 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 26, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:39:977 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:39:978 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505319885) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:39:978 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505199977
[12/16/19 14:06:39:978 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=191766)
[12/16/19 14:06:40:632 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:40:632 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 74 to node 2147483647
[12/16/19 14:06:40:734 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 74, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:40:734 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:42:282 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 968527a8-fe49-49b2-8898-9e0815fd653b completed
[12/16/19 14:06:42:284 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-36","orderId":"968527a8-fe49-49b2-8898-9e0815fd653b","preparedBy":"Kyle"},"order":{"name":"Demo-36","orderId":"968527a8-fe49-49b2-8898-9e0815fd653b","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@37c7c131 to topic queue partition 0
[12/16/19 14:06:42:284 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:42:285 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:42:287 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:42:288 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 41 to node 0
[12/16/19 14:06:42:289 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505202283, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:42:294 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 41, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3987,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:42:305 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 41
[12/16/19 14:06:42:305 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3987.
[12/16/19 14:06:42:312 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order a3cb5b18-c094-4913-94ac-7fd56d6a76cf
[12/16/19 14:06:43:649 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:43:649 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 75 to node 2147483647
[12/16/19 14:06:43:756 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 75, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:43:756 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:44:316 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order a3cb5b18-c094-4913-94ac-7fd56d6a76cf completed
[12/16/19 14:06:44:319 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-41","orderId":"a3cb5b18-c094-4913-94ac-7fd56d6a76cf","preparedBy":"Kyle"},"order":{"name":"Demo-41","orderId":"a3cb5b18-c094-4913-94ac-7fd56d6a76cf","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@3578019 to topic queue partition 0
[12/16/19 14:06:44:320 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:44:321 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:44:330 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 2ef474e6-3209-4ff7-898b-f1d784719cf5
[12/16/19 14:06:44:350 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:44:352 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 42 to node 0
[12/16/19 14:06:44:352 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505204319, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:44:355 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 42, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3988,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:44:356 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 42
[12/16/19 14:06:44:356 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3988.
[12/16/19 14:06:46:364 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 2ef474e6-3209-4ff7-898b-f1d784719cf5 completed
[12/16/19 14:06:46:365 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-46","orderId":"2ef474e6-3209-4ff7-898b-f1d784719cf5","preparedBy":"Kyle"},"order":{"name":"Demo-46","orderId":"2ef474e6-3209-4ff7-898b-f1d784719cf5","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@ad15f061 to topic queue partition 0
[12/16/19 14:06:46:365 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:46:366 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:46:367 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:46:368 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 43 to node 0
[12/16/19 14:06:46:368 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505206365, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:46:370 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 43, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3990,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:46:370 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 43
[12/16/19 14:06:46:371 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3990.
[12/16/19 14:06:46:377 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 570d25f0-a074-4b5e-9798-add20690bf24
[12/16/19 14:06:46:735 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:46:735 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 76 to node 2147483647
[12/16/19 14:06:46:837 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 76, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:46:837 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:48:655 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 570d25f0-a074-4b5e-9798-add20690bf24 completed
[12/16/19 14:06:48:656 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-2","orderId":"570d25f0-a074-4b5e-9798-add20690bf24","preparedBy":"Kyle"},"order":{"name":"Demo-2","orderId":"570d25f0-a074-4b5e-9798-add20690bf24","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@2317347d to topic queue partition 0
[12/16/19 14:06:48:656 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:48:657 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:48:664 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:48:664 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 44 to node 0
[12/16/19 14:06:48:665 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505208656, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:06:48:667 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 44, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3993,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:48:667 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 44
[12/16/19 14:06:48:668 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3993.
[12/16/19 14:06:48:677 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order a452b008-00ed-4a9b-9a4d-0a2133673bbf
[12/16/19 14:06:49:168 GMT] 00000076 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:06:49:170 GMT] 00000076 id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=258, leaderEpoch=0, metadata=''}}
[12/16/19 14:06:49:170 GMT] 00000076 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:06:49:170 GMT] 00000076 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:06:49:170 GMT] 00000076 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=258, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:49:171 GMT] 00000076 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=258,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 77 to node 2147483647
[12/16/19 14:06:49:206 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 77, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:06:49:206 GMT] 0000004d id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 258 for partition orders-4
[12/16/19 14:06:49:809 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:49:810 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 78 to node 2147483647
[12/16/19 14:06:49:884 GMT] 00000079 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505329884) with a timeout 120000 ms from now.
[12/16/19 14:06:49:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:49:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505329884)] at 1576505209886
[12/16/19 14:06:49:886 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:49:886 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:06:49:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505329884) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:49:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=27
[12/16/19 14:06:49:887 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 27 to node 0
[12/16/19 14:06:49:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119998)
[12/16/19 14:06:49:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:49:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505209887
[12/16/19 14:06:49:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119997)
[12/16/19 14:06:49:888 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 27, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:49:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:49:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505329884) with a timeout 119996 ms from now.
[12/16/19 14:06:49:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505329884) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:49:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505329884)] at 1576505209888
[12/16/19 14:06:49:888 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:49:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505329884) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:49:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=28
[12/16/19 14:06:49:889 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 28 to node 0
[12/16/19 14:06:49:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119996)
[12/16/19 14:06:49:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:49:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505209890
[12/16/19 14:06:49:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119994)
[12/16/19 14:06:49:890 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 28, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:49:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:49:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505329884) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:49:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505209890
[12/16/19 14:06:49:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=181853)
[12/16/19 14:06:49:912 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 78, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:49:912 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:51:205 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order a452b008-00ed-4a9b-9a4d-0a2133673bbf completed
[12/16/19 14:06:51:206 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-7","orderId":"a452b008-00ed-4a9b-9a4d-0a2133673bbf","preparedBy":"Kyle"},"order":{"name":"Demo-7","orderId":"a452b008-00ed-4a9b-9a4d-0a2133673bbf","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@cf82b247 to topic queue partition 0
[12/16/19 14:06:51:207 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:51:207 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:51:210 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:51:211 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 45 to node 0
[12/16/19 14:06:51:212 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505211206, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:06:51:215 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 45, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3994,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:51:215 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 45
[12/16/19 14:06:51:215 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3994.
[12/16/19 14:06:51:222 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 013edae0-54bf-48cd-9b50-fae695658581
[12/16/19 14:06:51:362 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 013edae0-54bf-48cd-9b50-fae695658581 completed
[12/16/19 14:06:51:363 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-12","orderId":"013edae0-54bf-48cd-9b50-fae695658581","preparedBy":"Kyle"},"order":{"name":"Demo-12","orderId":"013edae0-54bf-48cd-9b50-fae695658581","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@c81616a2 to topic queue partition 0
[12/16/19 14:06:51:363 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:51:363 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:51:364 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:51:364 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 46 to node 0
[12/16/19 14:06:51:365 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505211363, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:51:366 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 46, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3995,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:51:367 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 46
[12/16/19 14:06:51:367 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3995.
[12/16/19 14:06:51:374 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order a0cfdfdb-41af-4ce6-91da-5b0d0313b34f
[12/16/19 14:06:51:716 GMT] 00000076 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:06:51:717 GMT] 00000076 id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=260, leaderEpoch=0, metadata=''}}
[12/16/19 14:06:51:717 GMT] 00000076 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:06:51:717 GMT] 00000076 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:06:51:717 GMT] 00000076 id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=258, leaderEpoch=0, metadata=''}}
[12/16/19 14:06:51:717 GMT] 00000076 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=260, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:51:717 GMT] 00000076 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=260,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 79 to node 2147483647
[12/16/19 14:06:51:722 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 79, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:06:51:723 GMT] 0000004d id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 260 for partition orders-4
[12/16/19 14:06:52:828 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:52:828 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 80 to node 2147483647
[12/16/19 14:06:52:930 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 80, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:52:930 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:54:732 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order a0cfdfdb-41af-4ce6-91da-5b0d0313b34f completed
[12/16/19 14:06:54:733 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-17","orderId":"a0cfdfdb-41af-4ce6-91da-5b0d0313b34f","preparedBy":"Kyle"},"order":{"name":"Demo-17","orderId":"a0cfdfdb-41af-4ce6-91da-5b0d0313b34f","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@484e0dc9 to topic queue partition 0
[12/16/19 14:06:54:734 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:54:734 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:54:738 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:54:739 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 47 to node 0
[12/16/19 14:06:54:742 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505214733, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:54:746 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 47, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3997,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:54:750 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 47
[12/16/19 14:06:54:751 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3997.
[12/16/19 14:06:54:760 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 42f0de7d-ec39-49c1-a680-8311a2edfc34
[12/16/19 14:06:55:274 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:06:55:277 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=261, leaderEpoch=0, metadata=''}}
[12/16/19 14:06:55:278 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:06:55:278 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:06:55:278 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=260, leaderEpoch=0, metadata=''}}
[12/16/19 14:06:55:281 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=261, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:55:281 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=261,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 81 to node 2147483647
[12/16/19 14:06:55:382 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 81, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:06:55:382 GMT] 0000004d id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 261 for partition orders-4
[12/16/19 14:06:55:888 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:55:889 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 82 to node 2147483647
[12/16/19 14:06:56:000 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 82, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:56:009 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:57:395 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 42f0de7d-ec39-49c1-a680-8311a2edfc34 completed
[12/16/19 14:06:57:404 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-22","orderId":"42f0de7d-ec39-49c1-a680-8311a2edfc34","preparedBy":"Kyle"},"order":{"name":"Demo-22","orderId":"42f0de7d-ec39-49c1-a680-8311a2edfc34","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@dcba61b7 to topic queue partition 0
[12/16/19 14:06:57:405 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:06:57:406 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:06:57:421 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:06:57:432 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 48 to node 0
[12/16/19 14:06:57:436 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505217404, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:06:57:438 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 48, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=3999,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:06:57:438 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 48
[12/16/19 14:06:57:438 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 3999.
[12/16/19 14:06:57:465 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order cdc30157-a3ac-4c8d-8918-a890e46e7a25
[12/16/19 14:06:57:939 GMT] 00000073 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:06:57:940 GMT] 00000073 id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=262, leaderEpoch=0, metadata=''}}
[12/16/19 14:06:57:940 GMT] 00000073 id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:06:57:940 GMT] 00000073 id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:06:57:940 GMT] 00000073 id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=261, leaderEpoch=0, metadata=''}}
[12/16/19 14:06:57:941 GMT] 00000073 id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=262, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:57:942 GMT] 00000073 id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=262,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 83 to node 2147483647
[12/16/19 14:06:58:023 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 83, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:06:58:024 GMT] 0000004d id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 262 for partition orders-4
[12/16/19 14:06:58:934 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:06:58:934 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 84 to node 2147483647
[12/16/19 14:06:59:035 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 84, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:06:59:035 GMT] 0000004d id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:06:59:886 GMT] 00000073 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505339886) with a timeout 120000 ms from now.
[12/16/19 14:06:59:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:59:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505339886)] at 1576505219889
[12/16/19 14:06:59:889 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:59:890 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:06:59:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505339886) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:59:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=29
[12/16/19 14:06:59:891 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 29 to node 0
[12/16/19 14:06:59:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119997)
[12/16/19 14:06:59:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:59:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505219892
[12/16/19 14:06:59:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119994)
[12/16/19 14:06:59:893 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 29, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:59:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:59:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505339886) with a timeout 119992 ms from now.
[12/16/19 14:06:59:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505339886) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:06:59:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505339886)] at 1576505219894
[12/16/19 14:06:59:895 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:06:59:895 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505339886) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:06:59:895 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=30
[12/16/19 14:06:59:895 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 30 to node 0
[12/16/19 14:06:59:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119992)
[12/16/19 14:06:59:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:06:59:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505219896
[12/16/19 14:06:59:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119990)
[12/16/19 14:06:59:898 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 30, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:59:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:06:59:903 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505339886) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:06:59:903 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505219898
[12/16/19 14:06:59:903 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=171845)
[12/16/19 14:07:00:883 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order cdc30157-a3ac-4c8d-8918-a890e46e7a25 completed
[12/16/19 14:07:00:884 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-27","orderId":"cdc30157-a3ac-4c8d-8918-a890e46e7a25","preparedBy":"Kyle"},"order":{"name":"Demo-27","orderId":"cdc30157-a3ac-4c8d-8918-a890e46e7a25","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@2aca3090 to topic queue partition 0
[12/16/19 14:07:00:885 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:00:885 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:00:892 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 233c210c-ccc9-4571-aeea-8a6df93523ee
[12/16/19 14:07:00:893 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:00:894 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 49 to node 0
[12/16/19 14:07:00:894 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505220884, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:00:896 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 49, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4000,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:00:896 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 49
[12/16/19 14:07:00:896 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4000.
[12/16/19 14:07:01:306 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 233c210c-ccc9-4571-aeea-8a6df93523ee completed
[12/16/19 14:07:01:307 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-32","orderId":"233c210c-ccc9-4571-aeea-8a6df93523ee","preparedBy":"Kyle"},"order":{"name":"Demo-32","orderId":"233c210c-ccc9-4571-aeea-8a6df93523ee","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@ea2db1a5 to topic queue partition 0
[12/16/19 14:07:01:307 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:01:307 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:01:311 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:01:312 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 50 to node 0
[12/16/19 14:07:01:312 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505221307, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:01:313 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 50, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4001,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:01:313 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 50
[12/16/19 14:07:01:313 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4001.
[12/16/19 14:07:01:318 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order f8a47ed7-6c16-49b5-99c8-2530e02dbdbe
[12/16/19 14:07:01:397 GMT] 0000007c id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:01:398 GMT] 0000007c id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=264, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:01:398 GMT] 0000007c id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:01:399 GMT] 0000007c id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:01:399 GMT] 0000007c id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=262, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:01:399 GMT] 0000007c id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=264, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:01:400 GMT] 0000007c id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=264,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 85 to node 2147483647
[12/16/19 14:07:01:417 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 85, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:01:417 GMT] 0000004d id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 264 for partition orders-4
[12/16/19 14:07:01:514 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order f8a47ed7-6c16-49b5-99c8-2530e02dbdbe completed
[12/16/19 14:07:01:514 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-37","orderId":"f8a47ed7-6c16-49b5-99c8-2530e02dbdbe","preparedBy":"Kyle"},"order":{"name":"Demo-37","orderId":"f8a47ed7-6c16-49b5-99c8-2530e02dbdbe","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@8641db6e to topic queue partition 0
[12/16/19 14:07:01:514 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:01:515 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:01:516 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:01:517 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 51 to node 0
[12/16/19 14:07:01:518 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505221514, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:01:520 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 51, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4003,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:01:520 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 51
[12/16/19 14:07:01:520 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4003.
[12/16/19 14:07:01:533 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order bb4568cb-dbb5-48d3-af7c-e38bbf86b011
[12/16/19 14:07:01:541 GMT] 0000004f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:01:541 GMT] 0000004f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=264, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:01:542 GMT] 0000004f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:01:552 GMT] 0000004f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=21) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:01:553 GMT] 0000004f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:01:555 GMT] 0000004f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=21,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 86 to node 0
[12/16/19 14:07:01:559 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:01:937 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:01:937 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 87 to node 2147483647
[12/16/19 14:07:01:940 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:01:940 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 87, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:01:940 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:01:941 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:01:941 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:02:028 GMT] 00000082 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:02:030 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:02:030 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=265, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:02:030 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:02:030 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:02:030 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=265, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:02:031 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=265,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 88 to node 2147483647
[12/16/19 14:07:02:033 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:02:033 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 88, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:02:034 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 265 for partition orders-4
[12/16/19 14:07:02:034 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=265, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:02:034 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:02:040 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:02:057 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 86, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:02:057 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:02:058 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:02:058 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=22) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:02:058 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:02:058 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=22,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 89 to node 0
[12/16/19 14:07:02:060 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:02:561 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 89, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:02:562 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:02:564 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:02:565 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=23) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:02:566 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:02:566 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=23,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 90 to node 0
[12/16/19 14:07:02:575 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:03:069 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 90, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:03:069 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:03:070 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:03:071 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=24) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:03:071 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:03:071 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=24,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 91 to node 0
[12/16/19 14:07:03:072 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:03:573 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 91, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:03:573 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:03:574 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:03:574 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=25) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:03:574 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:03:576 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=25,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 92 to node 0
[12/16/19 14:07:03:581 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:04:081 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 92, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:04:083 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:04:085 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:04:086 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=26) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:04:086 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:04:087 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=26,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 93 to node 0
[12/16/19 14:07:04:092 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:04:296 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order bb4568cb-dbb5-48d3-af7c-e38bbf86b011 completed
[12/16/19 14:07:04:297 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-42","orderId":"bb4568cb-dbb5-48d3-af7c-e38bbf86b011","preparedBy":"Kyle"},"order":{"name":"Demo-42","orderId":"bb4568cb-dbb5-48d3-af7c-e38bbf86b011","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@3f646c5c to topic queue partition 0
[12/16/19 14:07:04:298 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:04:298 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:04:299 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:04:300 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 52 to node 0
[12/16/19 14:07:04:301 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505224297, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:04:308 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 52, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4005,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:04:308 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 52
[12/16/19 14:07:04:308 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4005.
[12/16/19 14:07:04:313 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order ed633a6c-f5b8-476a-95c7-c3df2ba878f5
[12/16/19 14:07:04:588 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 93, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:04:589 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:04:592 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:04:592 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=27) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:04:592 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:04:594 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=27,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 94 to node 0
[12/16/19 14:07:04:597 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:04:809 GMT] 00000073 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:04:810 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:04:810 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=266, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:04:811 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:04:811 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:04:812 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=266, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:04:812 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=266,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 95 to node 2147483647
[12/16/19 14:07:04:814 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:04:815 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 95, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:04:815 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 266 for partition orders-4
[12/16/19 14:07:04:816 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=266, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:04:816 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:04:817 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:04:939 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:04:939 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 96 to node 2147483647
[12/16/19 14:07:04:940 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:04:941 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 96, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:04:941 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:04:942 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:04:942 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:05:117 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 94, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:05:118 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:05:119 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:05:119 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=28) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:05:119 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:05:120 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=28,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 97 to node 0
[12/16/19 14:07:05:137 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:05:640 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 97, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:05:642 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:05:655 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:05:655 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=29) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:05:658 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:05:659 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=29,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 98 to node 0
[12/16/19 14:07:05:662 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:06:162 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 98, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:06:164 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:06:166 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:06:169 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=30) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:06:178 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:06:178 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=30,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 99 to node 0
[12/16/19 14:07:06:179 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:06:376 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order ed633a6c-f5b8-476a-95c7-c3df2ba878f5 completed
[12/16/19 14:07:06:377 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-47","orderId":"ed633a6c-f5b8-476a-95c7-c3df2ba878f5","preparedBy":"Kyle"},"order":{"name":"Demo-47","orderId":"ed633a6c-f5b8-476a-95c7-c3df2ba878f5","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@a1fad3a7 to topic queue partition 0
[12/16/19 14:07:06:378 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:06:378 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:06:379 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:06:380 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 53 to node 0
[12/16/19 14:07:06:380 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505226377, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:06:386 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 53, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4007,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:06:386 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 53
[12/16/19 14:07:06:386 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4007.
[12/16/19 14:07:06:388 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 654c1587-f7cb-47f2-b17d-ca292d765e70
[12/16/19 14:07:06:680 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 99, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:06:681 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:06:682 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:06:682 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=31) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:06:683 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:06:683 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=31,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 100 to node 0
[12/16/19 14:07:06:685 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:06:786 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 654c1587-f7cb-47f2-b17d-ca292d765e70 completed
[12/16/19 14:07:06:786 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-1","orderId":"654c1587-f7cb-47f2-b17d-ca292d765e70","preparedBy":"Kyle"},"order":{"name":"Demo-1","orderId":"654c1587-f7cb-47f2-b17d-ca292d765e70","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@b12a050a to topic queue partition 0
[12/16/19 14:07:06:787 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:06:792 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:06:798 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:06:798 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 4d016abb-4889-4323-a832-72425f6fba0a
[12/16/19 14:07:06:798 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 54 to node 0
[12/16/19 14:07:06:799 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505226786, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:07:06:802 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 54, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4009,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:06:802 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 54
[12/16/19 14:07:06:803 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4009.
[12/16/19 14:07:06:887 GMT] 0000007c id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:06:909 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:06:912 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=267, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:06:912 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:06:912 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:06:912 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=267, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:06:915 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=267,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 101 to node 2147483647
[12/16/19 14:07:06:922 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:06:927 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 101, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:06:928 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 267 for partition orders-4
[12/16/19 14:07:06:931 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=267, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:06:935 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:06:936 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:07:185 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 100, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:07:186 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:07:186 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:07:187 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=32) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:07:187 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:07:187 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=32,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 102 to node 0
[12/16/19 14:07:07:188 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:07:688 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 102, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:07:689 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:07:689 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:07:690 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=33) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:07:690 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:07:690 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=33,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 103 to node 0
[12/16/19 14:07:07:691 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:07:941 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:07:945 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 104 to node 2147483647
[12/16/19 14:07:07:946 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:07:947 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 104, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:07:947 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:07:947 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:07:947 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:08:192 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 103, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:08:192 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:08:193 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:08:194 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=34) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:08:194 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:08:194 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=34,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 105 to node 0
[12/16/19 14:07:08:195 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:08:696 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 105, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:08:696 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:08:697 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:08:697 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=35) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:08:697 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:08:698 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=35,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 106 to node 0
[12/16/19 14:07:08:699 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:09:200 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 106, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:09:201 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:09:202 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:09:202 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=36) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:09:203 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:09:204 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=36,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 107 to node 0
[12/16/19 14:07:09:205 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:09:704 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 107, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:09:704 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:09:705 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:09:705 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=37) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:09:706 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:09:706 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=37,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 108 to node 0
[12/16/19 14:07:09:707 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:09:884 GMT] 0000007c id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505349884) with a timeout 120000 ms from now.
[12/16/19 14:07:09:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:09:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505349884)] at 1576505229893
[12/16/19 14:07:09:893 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:09:893 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:07:09:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505349884) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:09:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=31
[12/16/19 14:07:09:893 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 31 to node 0
[12/16/19 14:07:09:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119991)
[12/16/19 14:07:09:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:09:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505229894
[12/16/19 14:07:09:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119990)
[12/16/19 14:07:09:895 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 31, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:09:895 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:09:895 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505349884) with a timeout 119989 ms from now.
[12/16/19 14:07:09:895 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505349884) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:09:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505349884)] at 1576505229895
[12/16/19 14:07:09:896 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:09:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505349884) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:09:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=32
[12/16/19 14:07:09:896 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 32 to node 0
[12/16/19 14:07:09:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119989)
[12/16/19 14:07:09:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:09:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505229897
[12/16/19 14:07:09:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119987)
[12/16/19 14:07:09:897 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 32, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:09:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:09:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505349884) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:09:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505229898
[12/16/19 14:07:09:898 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=161845)
[12/16/19 14:07:10:215 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 108, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:10:216 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:10:227 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:10:227 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=38) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:10:227 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:10:228 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=38,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 109 to node 0
[12/16/19 14:07:10:230 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:10:740 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 109, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:10:740 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:10:747 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:10:747 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=39) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:10:748 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:10:748 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=39,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 110 to node 0
[12/16/19 14:07:10:754 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:10:944 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:10:944 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 111 to node 2147483647
[12/16/19 14:07:10:952 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:10:952 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 111, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:10:953 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:10:954 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:10:955 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:11:005 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 4d016abb-4889-4323-a832-72425f6fba0a completed
[12/16/19 14:07:11:006 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-6","orderId":"4d016abb-4889-4323-a832-72425f6fba0a","preparedBy":"Kyle"},"order":{"name":"Demo-6","orderId":"4d016abb-4889-4323-a832-72425f6fba0a","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@8da47f12 to topic queue partition 0
[12/16/19 14:07:11:006 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:11:007 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:11:008 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:11:009 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 55 to node 0
[12/16/19 14:07:11:010 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505231006, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:07:11:012 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 55, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4011,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:11:012 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 55
[12/16/19 14:07:11:012 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4011.
[12/16/19 14:07:11:012 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order d15673bc-a6e2-4b6b-9704-b6dafc315e1c
[12/16/19 14:07:11:257 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 110, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:11:258 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:11:270 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:11:270 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=40) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:11:271 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:11:271 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=40,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 112 to node 0
[12/16/19 14:07:11:274 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:11:780 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 112, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:11:780 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:11:783 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:11:783 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=41) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:11:784 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:11:785 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=41,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 113 to node 0
[12/16/19 14:07:11:787 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:12:287 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 113, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:12:290 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:12:298 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:12:312 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=42) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:12:312 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:12:313 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=42,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 114 to node 0
[12/16/19 14:07:12:318 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:12:814 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 114, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:12:815 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:12:816 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:12:816 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=43) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:12:816 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:12:818 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=43,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 115 to node 0
[12/16/19 14:07:12:820 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:13:334 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 115, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:13:335 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:13:338 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:13:339 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=44) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:13:339 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:13:339 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=44,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 116 to node 0
[12/16/19 14:07:13:377 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:13:841 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 116, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:13:841 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:13:845 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:13:845 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=45) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:13:845 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:13:847 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=45,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 117 to node 0
[12/16/19 14:07:13:849 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:13:945 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:13:946 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 118 to node 2147483647
[12/16/19 14:07:13:946 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:13:947 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 118, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:13:947 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:13:948 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:13:948 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:14:341 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order d15673bc-a6e2-4b6b-9704-b6dafc315e1c completed
[12/16/19 14:07:14:343 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-11","orderId":"d15673bc-a6e2-4b6b-9704-b6dafc315e1c","preparedBy":"Kyle"},"order":{"name":"Demo-11","orderId":"d15673bc-a6e2-4b6b-9704-b6dafc315e1c","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@b5cac7a6 to topic queue partition 0
[12/16/19 14:07:14:344 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:14:345 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:14:348 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:14:350 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 56 to node 0
[12/16/19 14:07:14:351 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 117, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:14:355 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:14:357 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:14:357 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=46) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:14:358 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:14:356 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505234343, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:14:359 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=46,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 119 to node 0
[12/16/19 14:07:14:364 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 56, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4014,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:14:368 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 56
[12/16/19 14:07:14:368 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4014.
[12/16/19 14:07:14:376 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:14:368 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order b6c84b83-ab74-4bbe-93c4-1cbaac7f1dbc
[12/16/19 14:07:14:864 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 119, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:14:865 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:14:865 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:14:865 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=47) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:14:865 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:14:866 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=47,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 120 to node 0
[12/16/19 14:07:14:866 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:15:366 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 120, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:15:367 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:15:367 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:15:368 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=48) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:15:368 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:15:368 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=48,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 121 to node 0
[12/16/19 14:07:15:369 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:15:865 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order b6c84b83-ab74-4bbe-93c4-1cbaac7f1dbc completed
[12/16/19 14:07:15:865 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-16","orderId":"b6c84b83-ab74-4bbe-93c4-1cbaac7f1dbc","preparedBy":"Kyle"},"order":{"name":"Demo-16","orderId":"b6c84b83-ab74-4bbe-93c4-1cbaac7f1dbc","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@6e955b11 to topic queue partition 0
[12/16/19 14:07:15:865 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:15:866 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:15:866 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:15:867 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 57 to node 0
[12/16/19 14:07:15:867 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505235865, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:15:871 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 0a834df1-8da5-4c73-b9b8-675b4b3d6319
[12/16/19 14:07:15:875 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 57, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4015,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:15:875 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 57
[12/16/19 14:07:15:875 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4015.
[12/16/19 14:07:15:880 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 121, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:15:880 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:15:881 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:15:881 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=49) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:15:881 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:15:881 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=49,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 122 to node 0
[12/16/19 14:07:15:883 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:16:384 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 122, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:16:384 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:16:386 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:16:386 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=50) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:16:386 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:16:387 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=50,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 123 to node 0
[12/16/19 14:07:16:388 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:16:890 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 123, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:16:916 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:16:930 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:16:930 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=51) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:16:931 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:16:931 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=51,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 124 to node 0
[12/16/19 14:07:16:932 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:16:947 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:16:947 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 125 to node 2147483647
[12/16/19 14:07:16:948 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:16:948 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 125, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:16:948 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:16:949 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:16:949 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:17:434 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 124, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:17:445 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:17:447 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:17:448 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=52) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:17:448 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:17:448 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=52,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 126 to node 0
[12/16/19 14:07:17:452 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:17:953 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 126, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:17:954 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:17:954 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:17:954 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=53) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:17:954 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:17:955 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=53,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 127 to node 0
[12/16/19 14:07:17:955 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:18:457 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 127, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:18:459 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:18:462 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:18:462 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=54) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:18:463 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:18:463 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=54,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 128 to node 0
[12/16/19 14:07:18:468 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:18:966 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 128, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:18:967 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:18:968 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:18:968 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=55) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:18:968 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:18:968 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=55,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 129 to node 0
[12/16/19 14:07:18:969 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:19:470 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 129, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:19:471 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:19:471 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:19:472 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=56) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:19:472 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:19:472 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=56,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 130 to node 0
[12/16/19 14:07:19:473 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:19:884 GMT] 00000083 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505359884) with a timeout 120000 ms from now.
[12/16/19 14:07:19:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:19:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505359884)] at 1576505239886
[12/16/19 14:07:19:886 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:19:886 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:07:19:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505359884) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:19:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=33
[12/16/19 14:07:19:886 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 33 to node 0
[12/16/19 14:07:19:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119998)
[12/16/19 14:07:19:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:19:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505239887
[12/16/19 14:07:19:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119997)
[12/16/19 14:07:19:888 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 33, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:19:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:19:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505359884) with a timeout 119994 ms from now.
[12/16/19 14:07:19:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505359884) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:19:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505359884)] at 1576505239890
[12/16/19 14:07:19:891 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:19:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505359884) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:19:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=34
[12/16/19 14:07:19:891 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 34 to node 0
[12/16/19 14:07:19:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119994)
[12/16/19 14:07:19:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:19:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505239892
[12/16/19 14:07:19:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119992)
[12/16/19 14:07:19:896 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 34, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:19:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:19:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505359884) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:19:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505239896
[12/16/19 14:07:19:897 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=151847)
[12/16/19 14:07:19:949 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:19:949 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 131 to node 2147483647
[12/16/19 14:07:19:950 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:19:952 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 131, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:19:952 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:19:953 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:19:954 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:19:974 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 130, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:19:974 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:19:975 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:19:976 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=57) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:19:976 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:19:977 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=57,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 132 to node 0
[12/16/19 14:07:19:980 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:20:311 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 0a834df1-8da5-4c73-b9b8-675b4b3d6319 completed
[12/16/19 14:07:20:312 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-21","orderId":"0a834df1-8da5-4c73-b9b8-675b4b3d6319","preparedBy":"Kyle"},"order":{"name":"Demo-21","orderId":"0a834df1-8da5-4c73-b9b8-675b4b3d6319","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@2214e532 to topic queue partition 0
[12/16/19 14:07:20:312 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:20:312 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:20:313 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:20:314 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 58 to node 0
[12/16/19 14:07:20:316 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 26bb92db-867d-4fb6-9038-c4ae4d2f753f
[12/16/19 14:07:20:316 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505240312, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:20:321 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 58, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4017,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:20:321 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 58
[12/16/19 14:07:20:322 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4017.
[12/16/19 14:07:20:481 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 132, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:20:481 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:20:482 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:20:482 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=58) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:20:482 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:20:483 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=58,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 133 to node 0
[12/16/19 14:07:20:484 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:20:531 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 26bb92db-867d-4fb6-9038-c4ae4d2f753f completed
[12/16/19 14:07:20:531 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-26","orderId":"26bb92db-867d-4fb6-9038-c4ae4d2f753f","preparedBy":"Kyle"},"order":{"name":"Demo-26","orderId":"26bb92db-867d-4fb6-9038-c4ae4d2f753f","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@5b85afaf to topic queue partition 0
[12/16/19 14:07:20:531 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:20:531 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:20:532 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:20:532 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 59 to node 0
[12/16/19 14:07:20:533 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505240531, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:20:536 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 59, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4018,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:20:536 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 59
[12/16/19 14:07:20:536 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4018.
[12/16/19 14:07:20:536 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 40e84f81-2daf-44bb-b6b3-4289fc05323e
[12/16/19 14:07:20:985 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 133, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:20:985 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:20:985 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:20:985 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=59) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:20:986 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:20:986 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=59,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 134 to node 0
[12/16/19 14:07:20:986 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:21:489 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 134, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:21:490 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:21:491 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:21:491 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=60) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:21:491 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:21:491 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=60,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 135 to node 0
[12/16/19 14:07:21:492 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:21:993 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 135, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:21:993 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:21:994 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:21:994 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=61) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:21:994 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:21:994 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=61,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 136 to node 0
[12/16/19 14:07:21:995 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:22:497 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 136, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:22:499 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:22:503 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:22:504 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=62) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:22:504 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:22:505 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=62,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 137 to node 0
[12/16/19 14:07:22:507 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:22:951 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:22:951 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 138 to node 2147483647
[12/16/19 14:07:22:953 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:22:953 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 138, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:22:953 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:22:954 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:22:954 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:23:010 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 137, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:23:011 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:23:012 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:23:013 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=63) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:23:013 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:23:014 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=63,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 139 to node 0
[12/16/19 14:07:23:015 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:23:518 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 139, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:23:518 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:23:522 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:23:522 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=64) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:23:523 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:23:524 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=64,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 140 to node 0
[12/16/19 14:07:23:529 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:24:027 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 140, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:24:028 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:24:029 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:24:030 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=65) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:24:030 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:24:031 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=65,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 141 to node 0
[12/16/19 14:07:24:032 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:24:231 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 40e84f81-2daf-44bb-b6b3-4289fc05323e completed
[12/16/19 14:07:24:232 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-31","orderId":"40e84f81-2daf-44bb-b6b3-4289fc05323e","preparedBy":"Kyle"},"order":{"name":"Demo-31","orderId":"40e84f81-2daf-44bb-b6b3-4289fc05323e","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@6ff3557e to topic queue partition 0
[12/16/19 14:07:24:233 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:24:233 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:24:234 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:24:234 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 60 to node 0
[12/16/19 14:07:24:235 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505244232, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:24:238 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 60, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4020,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:24:238 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 60
[12/16/19 14:07:24:238 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4020.
[12/16/19 14:07:24:239 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 968527a8-fe49-49b2-8898-9e0815fd653b
[12/16/19 14:07:24:536 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 141, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:24:536 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:24:537 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:24:537 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=66) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:24:537 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:24:538 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=66,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 142 to node 0
[12/16/19 14:07:24:541 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:25:039 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 142, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:25:041 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:25:042 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:25:043 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=67) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:25:043 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:25:043 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=67,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 143 to node 0
[12/16/19 14:07:25:045 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:25:545 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 143, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:25:547 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:25:548 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:25:548 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=68) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:25:548 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:25:549 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=68,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 144 to node 0
[12/16/19 14:07:25:550 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:25:970 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:25:972 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 145 to node 2147483647
[12/16/19 14:07:25:972 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:25:973 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 145, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:25:973 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:25:973 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:25:974 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:26:051 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 144, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:26:054 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:26:054 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:26:054 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=69) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:26:055 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:26:066 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=69,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 146 to node 0
[12/16/19 14:07:26:068 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:26:568 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 146, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:26:568 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:26:569 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:26:569 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=70) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:26:569 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:26:569 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=70,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 147 to node 0
[12/16/19 14:07:26:569 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:27:072 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 147, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:27:072 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:27:073 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:27:073 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=71) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:27:073 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:27:073 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=71,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 148 to node 0
[12/16/19 14:07:27:074 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:27:576 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 148, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:27:577 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:27:581 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:27:581 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=72) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:27:582 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:27:582 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=72,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 149 to node 0
[12/16/19 14:07:27:590 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:28:088 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 149, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:28:090 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:28:092 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:28:092 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=73) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:28:092 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:28:093 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=73,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 150 to node 0
[12/16/19 14:07:28:096 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:28:117 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 968527a8-fe49-49b2-8898-9e0815fd653b completed
[12/16/19 14:07:28:118 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-36","orderId":"968527a8-fe49-49b2-8898-9e0815fd653b","preparedBy":"Kyle"},"order":{"name":"Demo-36","orderId":"968527a8-fe49-49b2-8898-9e0815fd653b","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@583bf98e to topic queue partition 0
[12/16/19 14:07:28:119 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:28:119 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:28:120 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:28:121 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 61 to node 0
[12/16/19 14:07:28:122 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505248118, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:28:123 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order a3cb5b18-c094-4913-94ac-7fd56d6a76cf
[12/16/19 14:07:28:125 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 61, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4021,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:28:125 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 61
[12/16/19 14:07:28:125 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4021.
[12/16/19 14:07:28:594 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 150, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:28:596 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:28:596 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:28:597 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=74) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:28:597 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:28:597 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=74,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 151 to node 0
[12/16/19 14:07:28:599 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:28:982 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:28:982 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 152 to node 2147483647
[12/16/19 14:07:28:983 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:28:983 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 152, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:28:984 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:28:984 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:28:984 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:29:102 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 151, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:29:117 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:29:120 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:29:121 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=75) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:29:122 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:29:122 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=75,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 153 to node 0
[12/16/19 14:07:29:127 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:29:639 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 153, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:29:640 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:29:642 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:29:643 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=76) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:29:643 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:29:643 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=76,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 154 to node 0
[12/16/19 14:07:29:649 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:29:887 GMT] 0000008a id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505369887) with a timeout 120000 ms from now.
[12/16/19 14:07:29:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:29:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505369887)] at 1576505249890
[12/16/19 14:07:29:890 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:29:890 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:07:29:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505369887) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:29:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=35
[12/16/19 14:07:29:890 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 35 to node 0
[12/16/19 14:07:29:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119997)
[12/16/19 14:07:29:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505249891
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119996)
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 35, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505369887) with a timeout 119996 ms from now.
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505369887) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505369887)] at 1576505249891
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505369887) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=36
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 36 to node 0
[12/16/19 14:07:29:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119996)
[12/16/19 14:07:29:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:29:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505249892
[12/16/19 14:07:29:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119995)
[12/16/19 14:07:29:892 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 36, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:29:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:29:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505369887) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:29:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505249892
[12/16/19 14:07:29:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=141851)
[12/16/19 14:07:30:144 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 154, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:30:145 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:30:150 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:30:150 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=77) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:30:150 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:30:150 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=77,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 155 to node 0
[12/16/19 14:07:30:151 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:30:651 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 155, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:30:652 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:30:652 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:30:653 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=78) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:30:653 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:30:653 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=78,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 156 to node 0
[12/16/19 14:07:30:654 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:31:155 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 156, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:31:157 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:31:158 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:31:158 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=79) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:31:158 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:31:158 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=79,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 157 to node 0
[12/16/19 14:07:31:159 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:31:659 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 157, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:31:661 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:31:662 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:31:662 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=80) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:31:662 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:31:663 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=80,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 158 to node 0
[12/16/19 14:07:31:664 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:31:983 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:31:983 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 159 to node 2147483647
[12/16/19 14:07:31:986 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:31:988 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 159, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:31:989 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:31:989 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:31:990 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:32:164 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 158, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:32:169 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:32:171 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:32:171 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=81) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:32:171 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:32:171 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=81,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 160 to node 0
[12/16/19 14:07:32:178 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:32:674 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 160, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:32:675 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:32:679 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:32:681 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=82) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:32:681 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:32:682 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=82,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 161 to node 0
[12/16/19 14:07:32:705 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:32:737 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order a3cb5b18-c094-4913-94ac-7fd56d6a76cf completed
[12/16/19 14:07:32:738 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-41","orderId":"a3cb5b18-c094-4913-94ac-7fd56d6a76cf","preparedBy":"Kyle"},"order":{"name":"Demo-41","orderId":"a3cb5b18-c094-4913-94ac-7fd56d6a76cf","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@310545ed to topic queue partition 0
[12/16/19 14:07:32:738 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:32:738 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:32:740 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:32:740 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 62 to node 0
[12/16/19 14:07:32:741 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505252738, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:32:742 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 2ef474e6-3209-4ff7-898b-f1d784719cf5
[12/16/19 14:07:32:743 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 62, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4022,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:32:743 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 62
[12/16/19 14:07:32:744 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4022.
[12/16/19 14:07:33:205 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 161, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:33:205 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:33:206 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:33:206 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=83) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:33:206 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:33:207 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=83,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 162 to node 0
[12/16/19 14:07:33:208 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:33:708 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 162, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:33:709 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:33:713 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:33:714 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=84) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:33:714 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:33:714 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=84,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 163 to node 0
[12/16/19 14:07:33:715 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:34:215 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 163, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:34:216 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:34:217 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:34:217 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=85) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:34:218 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:34:218 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=85,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 164 to node 0
[12/16/19 14:07:34:228 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:34:719 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 164, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:34:719 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:34:720 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:34:720 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=86) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:34:720 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:34:721 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=86,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 165 to node 0
[12/16/19 14:07:34:723 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:34:987 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:34:988 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 166 to node 2147483647
[12/16/19 14:07:34:991 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:34:994 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 166, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:34:998 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:35:000 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:35:001 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:35:241 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 165, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:35:244 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:35:259 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:35:259 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=87) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:35:259 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:35:259 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=87,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 167 to node 0
[12/16/19 14:07:35:261 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:35:765 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 167, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:35:767 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:35:769 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:35:769 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=88) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:35:769 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:35:769 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=88,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 168 to node 0
[12/16/19 14:07:35:770 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:36:273 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 168, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:36:284 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:36:286 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:36:304 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=89) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:36:304 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:36:305 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=89,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 169 to node 0
[12/16/19 14:07:36:306 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:36:813 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 169, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:36:813 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:36:814 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:36:815 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=90) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:36:821 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:36:825 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=90,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 170 to node 0
[12/16/19 14:07:36:828 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:36:981 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 2ef474e6-3209-4ff7-898b-f1d784719cf5 completed
[12/16/19 14:07:36:982 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-46","orderId":"2ef474e6-3209-4ff7-898b-f1d784719cf5","preparedBy":"Kyle"},"order":{"name":"Demo-46","orderId":"2ef474e6-3209-4ff7-898b-f1d784719cf5","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@ee50f336 to topic queue partition 0
[12/16/19 14:07:36:982 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:36:983 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:36:983 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:36:984 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 63 to node 0
[12/16/19 14:07:36:984 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505256982, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:36:989 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 570d25f0-a074-4b5e-9798-add20690bf24
[12/16/19 14:07:36:989 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 63, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4023,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:36:990 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 63
[12/16/19 14:07:36:990 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4023.
[12/16/19 14:07:37:329 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 170, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:37:331 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:37:331 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:37:332 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=91) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:37:332 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:37:332 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=91,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 171 to node 0
[12/16/19 14:07:37:334 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:37:835 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 171, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:37:836 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:37:840 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:37:841 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=92) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:37:842 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:37:843 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=92,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 172 to node 0
[12/16/19 14:07:37:846 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:37:991 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:37:991 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 173 to node 2147483647
[12/16/19 14:07:37:992 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:37:993 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 173, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:37:993 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:37:993 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:37:994 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:38:345 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 172, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:38:346 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:38:347 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:38:347 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=93) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:38:347 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:38:347 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=93,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 174 to node 0
[12/16/19 14:07:38:348 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:38:852 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 174, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:38:854 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:38:858 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:38:858 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=94) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:38:858 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:38:859 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=94,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 175 to node 0
[12/16/19 14:07:38:862 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:38:950 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 570d25f0-a074-4b5e-9798-add20690bf24 completed
[12/16/19 14:07:38:950 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-2","orderId":"570d25f0-a074-4b5e-9798-add20690bf24","preparedBy":"Kyle"},"order":{"name":"Demo-2","orderId":"570d25f0-a074-4b5e-9798-add20690bf24","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@5b1ab0cb to topic queue partition 0
[12/16/19 14:07:38:950 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:38:951 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:38:951 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:38:952 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 64 to node 0
[12/16/19 14:07:38:952 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505258950, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:07:38:954 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 64, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4024,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:38:955 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 64
[12/16/19 14:07:38:955 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order a452b008-00ed-4a9b-9a4d-0a2133673bbf
[12/16/19 14:07:38:955 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4024.
[12/16/19 14:07:39:152 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order a452b008-00ed-4a9b-9a4d-0a2133673bbf completed
[12/16/19 14:07:39:154 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-7","orderId":"a452b008-00ed-4a9b-9a4d-0a2133673bbf","preparedBy":"Kyle"},"order":{"name":"Demo-7","orderId":"a452b008-00ed-4a9b-9a4d-0a2133673bbf","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@cea66a61 to topic queue partition 0
[12/16/19 14:07:39:155 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:39:156 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:39:158 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:39:161 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 65 to node 0
[12/16/19 14:07:39:169 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505259154, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:07:39:171 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 013edae0-54bf-48cd-9b50-fae695658581
[12/16/19 14:07:39:175 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 65, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4025,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:39:176 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 65
[12/16/19 14:07:39:193 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4025.
[12/16/19 14:07:39:361 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 175, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:39:364 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:39:365 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:39:366 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=95) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:39:366 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:39:366 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=95,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 176 to node 0
[12/16/19 14:07:39:368 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:39:455 GMT] 0000008a id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:39:456 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:39:457 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=259, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:39:457 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:39:457 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:39:457 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=259, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:39:457 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=259,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 177 to node 2147483647
[12/16/19 14:07:39:460 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:39:460 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 177, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:39:462 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 259 for partition orders-4
[12/16/19 14:07:39:464 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=259, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:39:466 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:39:867 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 176, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:39:868 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:39:869 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:39:870 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=96) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:39:870 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:39:871 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=96,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 178 to node 0
[12/16/19 14:07:39:874 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:39:883 GMT] 0000008a id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505379883) with a timeout 120000 ms from now.
[12/16/19 14:07:39:883 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:39:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505379883)] at 1576505259884
[12/16/19 14:07:39:884 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:39:884 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:07:39:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505379883) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:39:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=37
[12/16/19 14:07:39:884 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 37 to node 0
[12/16/19 14:07:39:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119999)
[12/16/19 14:07:39:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:39:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505259885
[12/16/19 14:07:39:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119998)
[12/16/19 14:07:39:886 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 37, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:39:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:39:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505379883) with a timeout 119997 ms from now.
[12/16/19 14:07:39:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505379883) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:39:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505379883)] at 1576505259886
[12/16/19 14:07:39:886 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:39:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505379883) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:39:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=38
[12/16/19 14:07:39:887 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 38 to node 0
[12/16/19 14:07:39:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119997)
[12/16/19 14:07:39:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:39:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505259887
[12/16/19 14:07:39:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119996)
[12/16/19 14:07:39:888 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 38, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:39:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:39:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505379883) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:39:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505259888
[12/16/19 14:07:39:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=131855)
[12/16/19 14:07:40:384 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 178, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:40:386 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:40:394 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:40:395 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=97) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:40:395 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:40:398 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=97,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 179 to node 0
[12/16/19 14:07:40:400 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:40:430 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 013edae0-54bf-48cd-9b50-fae695658581 completed
[12/16/19 14:07:40:431 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-12","orderId":"013edae0-54bf-48cd-9b50-fae695658581","preparedBy":"Kyle"},"order":{"name":"Demo-12","orderId":"013edae0-54bf-48cd-9b50-fae695658581","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@592db9a3 to topic queue partition 0
[12/16/19 14:07:40:431 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:40:432 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:40:433 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:40:433 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 66 to node 0
[12/16/19 14:07:40:434 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505260431, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:40:437 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 66, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4026,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:40:437 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 66
[12/16/19 14:07:40:438 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4026.
[12/16/19 14:07:40:441 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order a0cfdfdb-41af-4ce6-91da-5b0d0313b34f
[12/16/19 14:07:40:901 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 179, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:40:901 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:40:901 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:40:901 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=98) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:40:901 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:40:902 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=98,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 180 to node 0
[12/16/19 14:07:40:902 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:40:949 GMT] 00000083 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:40:950 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:40:950 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=260, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:40:950 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:40:950 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:40:950 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=260, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:40:950 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=260,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 181 to node 2147483647
[12/16/19 14:07:40:951 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:40:952 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 181, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:40:952 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 260 for partition orders-4
[12/16/19 14:07:40:952 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=260, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:40:953 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:40:953 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:40:991 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:40:992 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:40:992 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:40:992 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:40:993 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 182 to node 2147483647
[12/16/19 14:07:41:000 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:41:000 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 182, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:41:001 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:41:001 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:41:002 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:41:403 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 180, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:41:403 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:41:404 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:41:404 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=99) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:41:404 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:41:404 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=99,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 183 to node 0
[12/16/19 14:07:41:405 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:41:832 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order a0cfdfdb-41af-4ce6-91da-5b0d0313b34f completed
[12/16/19 14:07:41:833 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-17","orderId":"a0cfdfdb-41af-4ce6-91da-5b0d0313b34f","preparedBy":"Kyle"},"order":{"name":"Demo-17","orderId":"a0cfdfdb-41af-4ce6-91da-5b0d0313b34f","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@159c052f to topic queue partition 0
[12/16/19 14:07:41:833 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:41:833 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:41:833 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:41:834 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 67 to node 0
[12/16/19 14:07:41:834 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505261833, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:41:835 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 67, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4027,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:41:836 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 67
[12/16/19 14:07:41:836 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4027.
[12/16/19 14:07:41:837 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 42f0de7d-ec39-49c1-a680-8311a2edfc34
[12/16/19 14:07:41:906 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 183, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:41:906 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:41:906 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:41:906 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=100) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:41:907 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:41:907 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=100,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 184 to node 0
[12/16/19 14:07:41:908 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:42:337 GMT] 00000083 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:42:337 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:42:338 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=261, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:42:338 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:42:338 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:42:339 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=261, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:42:339 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=261,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 185 to node 2147483647
[12/16/19 14:07:42:340 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:42:341 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 185, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:42:341 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 261 for partition orders-4
[12/16/19 14:07:42:341 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=261, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:42:342 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:42:342 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:42:408 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 184, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:42:408 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:42:409 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:42:409 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=101) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:42:409 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:42:409 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=101,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 186 to node 0
[12/16/19 14:07:42:410 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:42:911 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 186, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:42:911 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:42:912 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:42:912 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=102) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:42:912 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:42:912 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=102,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 187 to node 0
[12/16/19 14:07:42:913 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:43:414 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 187, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:43:415 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:43:415 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:43:415 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=103) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:43:416 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:43:416 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=103,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 188 to node 0
[12/16/19 14:07:43:417 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:43:918 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 188, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:43:919 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:43:919 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:43:920 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=104) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:43:920 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:43:920 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=104,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 189 to node 0
[12/16/19 14:07:43:921 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:43:993 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:43:993 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 190 to node 2147483647
[12/16/19 14:07:43:994 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:43:995 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 190, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:43:995 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:43:996 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:43:996 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:44:423 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 189, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:44:424 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:44:425 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:44:425 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=105) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:44:425 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:44:425 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=105,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 191 to node 0
[12/16/19 14:07:44:428 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:44:531 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 42f0de7d-ec39-49c1-a680-8311a2edfc34 completed
[12/16/19 14:07:44:532 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-22","orderId":"42f0de7d-ec39-49c1-a680-8311a2edfc34","preparedBy":"Kyle"},"order":{"name":"Demo-22","orderId":"42f0de7d-ec39-49c1-a680-8311a2edfc34","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@9b8c9546 to topic queue partition 0
[12/16/19 14:07:44:532 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:44:533 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:44:535 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:44:535 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 68 to node 0
[12/16/19 14:07:44:536 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505264532, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:44:539 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 68, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4028,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:44:539 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 68
[12/16/19 14:07:44:539 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4028.
[12/16/19 14:07:44:549 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order cdc30157-a3ac-4c8d-8918-a890e46e7a25
[12/16/19 14:07:44:926 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 191, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:44:927 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:44:928 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:44:928 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=106) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:44:928 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:44:928 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=106,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 192 to node 0
[12/16/19 14:07:44:931 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:45:082 GMT] 00000084 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:45:145 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:45:154 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order cdc30157-a3ac-4c8d-8918-a890e46e7a25 completed
[12/16/19 14:07:45:155 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-27","orderId":"cdc30157-a3ac-4c8d-8918-a890e46e7a25","preparedBy":"Kyle"},"order":{"name":"Demo-27","orderId":"cdc30157-a3ac-4c8d-8918-a890e46e7a25","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@2fa49a41 to topic queue partition 0
[12/16/19 14:07:45:163 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:45:163 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:45:168 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:45:168 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 69 to node 0
[12/16/19 14:07:45:169 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505265155, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:45:171 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 69, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4029,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:45:171 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 69
[12/16/19 14:07:45:171 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4029.
[12/16/19 14:07:45:176 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=262, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:45:176 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:45:176 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:45:176 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=262, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:45:177 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=262,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 193 to node 2147483647
[12/16/19 14:07:45:178 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:45:182 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 233c210c-ccc9-4571-aeea-8a6df93523ee
[12/16/19 14:07:45:179 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 193, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:45:183 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 262 for partition orders-4
[12/16/19 14:07:45:184 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=262, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:45:185 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:45:185 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:45:439 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 192, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:45:440 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:45:448 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:45:465 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=107) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:45:465 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:45:465 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=107,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 194 to node 0
[12/16/19 14:07:45:475 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:45:675 GMT] 00000084 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:45:680 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:45:681 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=263, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:45:681 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:45:681 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:45:681 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=263, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:45:682 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=263,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 195 to node 2147483647
[12/16/19 14:07:45:683 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:45:684 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 195, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:45:684 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 263 for partition orders-4
[12/16/19 14:07:45:684 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=263, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:45:685 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:45:700 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:45:969 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 194, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:45:969 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:45:970 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:45:971 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=108) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:45:971 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:45:971 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=108,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 196 to node 0
[12/16/19 14:07:45:973 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:46:473 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 196, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:46:473 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:46:478 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:46:478 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=109) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:46:478 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:46:479 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=109,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 197 to node 0
[12/16/19 14:07:46:480 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:46:981 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 197, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:46:981 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:46:982 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:46:982 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=110) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:46:982 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:46:982 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=110,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 198 to node 0
[12/16/19 14:07:46:983 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:46:994 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:46:994 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 199 to node 2147483647
[12/16/19 14:07:46:995 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:46:995 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 199, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:46:995 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:46:996 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:46:996 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:47:486 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 198, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:47:486 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:47:487 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:47:487 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=111) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:47:487 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:47:488 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=111,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 200 to node 0
[12/16/19 14:07:47:497 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:47:997 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 200, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:47:997 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:47:998 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:47:999 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=112) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:47:999 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:47:999 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=112,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 201 to node 0
[12/16/19 14:07:48:000 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:48:402 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 233c210c-ccc9-4571-aeea-8a6df93523ee completed
[12/16/19 14:07:48:406 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-32","orderId":"233c210c-ccc9-4571-aeea-8a6df93523ee","preparedBy":"Kyle"},"order":{"name":"Demo-32","orderId":"233c210c-ccc9-4571-aeea-8a6df93523ee","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@9002f2d1 to topic queue partition 0
[12/16/19 14:07:48:407 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:48:408 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:48:411 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:48:414 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 70 to node 0
[12/16/19 14:07:48:415 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505268405, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:48:431 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 70, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4030,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:48:432 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 70
[12/16/19 14:07:48:432 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4030.
[12/16/19 14:07:48:461 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order f8a47ed7-6c16-49b5-99c8-2530e02dbdbe
[12/16/19 14:07:48:501 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 201, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:48:501 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:48:502 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:48:502 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=113) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:48:502 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:48:502 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=113,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 202 to node 0
[12/16/19 14:07:48:503 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:48:549 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order f8a47ed7-6c16-49b5-99c8-2530e02dbdbe completed
[12/16/19 14:07:48:549 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-37","orderId":"f8a47ed7-6c16-49b5-99c8-2530e02dbdbe","preparedBy":"Kyle"},"order":{"name":"Demo-37","orderId":"f8a47ed7-6c16-49b5-99c8-2530e02dbdbe","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@b2d5166b to topic queue partition 0
[12/16/19 14:07:48:550 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:48:550 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:48:553 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:48:553 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 71 to node 0
[12/16/19 14:07:48:554 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505268549, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:48:558 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 71, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4031,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:48:558 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 71
[12/16/19 14:07:48:558 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4031.
[12/16/19 14:07:48:560 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order bb4568cb-dbb5-48d3-af7c-e38bbf86b011
[12/16/19 14:07:48:933 GMT] 00000083 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:48:934 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:48:934 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=265, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:48:934 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:48:934 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:48:935 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=265, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:48:935 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=265,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 203 to node 2147483647
[12/16/19 14:07:48:937 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:48:938 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 203, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:48:938 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 265 for partition orders-4
[12/16/19 14:07:48:938 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=265, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:48:941 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:48:942 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:49:013 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 202, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:49:013 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:49:017 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:49:017 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=114) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:49:017 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:49:017 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=114,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 204 to node 0
[12/16/19 14:07:49:022 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:49:519 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 204, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:49:520 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:49:521 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:49:521 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=115) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:49:521 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:49:522 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=115,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 205 to node 0
[12/16/19 14:07:49:523 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:49:887 GMT] 0000008a id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505389887) with a timeout 120000 ms from now.
[12/16/19 14:07:49:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:49:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505389887)] at 1576505269889
[12/16/19 14:07:49:889 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:49:889 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:07:49:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505389887) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:49:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=39
[12/16/19 14:07:49:889 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 39 to node 0
[12/16/19 14:07:49:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119998)
[12/16/19 14:07:49:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:49:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505269890
[12/16/19 14:07:49:890 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119997)
[12/16/19 14:07:49:890 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 39, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:49:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:49:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505389887) with a timeout 119996 ms from now.
[12/16/19 14:07:49:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505389887) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:49:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505389887)] at 1576505269891
[12/16/19 14:07:49:891 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:49:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505389887) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:49:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=40
[12/16/19 14:07:49:891 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 40 to node 0
[12/16/19 14:07:49:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119996)
[12/16/19 14:07:49:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:49:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505269892
[12/16/19 14:07:49:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=119995)
[12/16/19 14:07:49:892 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 40, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:49:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:49:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505389887) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:49:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505269892
[12/16/19 14:07:49:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=121851)
[12/16/19 14:07:50:000 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:50:000 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 206 to node 2147483647
[12/16/19 14:07:50:004 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:50:004 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 206, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:50:005 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:50:005 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:50:005 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:50:031 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 205, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:50:031 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:50:045 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:50:046 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=116) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:50:046 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:50:047 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=116,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 207 to node 0
[12/16/19 14:07:50:048 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:50:550 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 207, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:50:550 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:50:552 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:50:552 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=117) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:50:552 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:50:553 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=117,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 208 to node 0
[12/16/19 14:07:50:557 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:50:957 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order bb4568cb-dbb5-48d3-af7c-e38bbf86b011 completed
[12/16/19 14:07:50:958 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-42","orderId":"bb4568cb-dbb5-48d3-af7c-e38bbf86b011","preparedBy":"Kyle"},"order":{"name":"Demo-42","orderId":"bb4568cb-dbb5-48d3-af7c-e38bbf86b011","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@f0258583 to topic queue partition 0
[12/16/19 14:07:50:958 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:50:958 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:50:960 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:50:960 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 72 to node 0
[12/16/19 14:07:50:961 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505270958, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:50:964 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 72, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4032,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:50:964 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 72
[12/16/19 14:07:50:964 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4032.
[12/16/19 14:07:50:990 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order ed633a6c-f5b8-476a-95c7-c3df2ba878f5
[12/16/19 14:07:51:126 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 208, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:51:134 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:51:144 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:51:146 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=118) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:51:146 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:51:146 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=118,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 209 to node 0
[12/16/19 14:07:51:147 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:51:469 GMT] 0000008e id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:51:471 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:51:473 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=266, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:51:474 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:51:474 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:51:484 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=266, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:51:484 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=266,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 210 to node 2147483647
[12/16/19 14:07:51:489 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:51:513 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 210, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:51:514 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 266 for partition orders-4
[12/16/19 14:07:51:514 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=266, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:51:515 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:51:515 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:51:648 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 209, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:51:648 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:51:648 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:51:649 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=119) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:51:649 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:51:649 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=119,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 211 to node 0
[12/16/19 14:07:51:649 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:52:150 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 211, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:52:150 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:52:151 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:52:151 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=120) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:52:151 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:52:151 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=120,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 212 to node 0
[12/16/19 14:07:52:152 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:52:653 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 212, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:52:654 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:52:655 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:52:658 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=121) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:52:658 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:52:659 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=121,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 213 to node 0
[12/16/19 14:07:52:663 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:53:001 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:53:002 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 214 to node 2147483647
[12/16/19 14:07:53:003 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:53:003 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 214, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:53:003 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:53:004 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:53:004 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:53:162 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 213, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:53:163 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:53:163 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:53:163 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=122) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:53:163 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:53:164 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=122,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 215 to node 0
[12/16/19 14:07:53:167 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:53:666 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 215, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:53:667 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:53:672 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:53:672 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=123) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:53:675 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:53:676 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=123,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 216 to node 0
[12/16/19 14:07:53:679 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:54:180 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 216, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:54:180 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:54:181 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:54:181 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=124) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:54:181 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:54:181 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=124,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 217 to node 0
[12/16/19 14:07:54:183 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:54:307 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order ed633a6c-f5b8-476a-95c7-c3df2ba878f5 completed
[12/16/19 14:07:54:307 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-47","orderId":"ed633a6c-f5b8-476a-95c7-c3df2ba878f5","preparedBy":"Kyle"},"order":{"name":"Demo-47","orderId":"ed633a6c-f5b8-476a-95c7-c3df2ba878f5","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@b7829785 to topic queue partition 0
[12/16/19 14:07:54:308 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:54:308 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:54:309 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:54:310 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 73 to node 0
[12/16/19 14:07:54:311 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505274307, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:07:54:312 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 570d25f0-a074-4b5e-9798-add20690bf24
[12/16/19 14:07:54:317 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 73, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4033,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:54:318 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 73
[12/16/19 14:07:54:318 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4033.
[12/16/19 14:07:54:689 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 217, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:54:689 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:54:695 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:54:695 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=125) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:54:695 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:54:695 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=125,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 218 to node 0
[12/16/19 14:07:54:697 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:54:819 GMT] 00000090 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:54:823 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:54:826 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=267, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:54:826 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:54:826 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:54:826 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=267, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:54:826 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=267,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 219 to node 2147483647
[12/16/19 14:07:54:833 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:54:833 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 219, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:54:833 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 267 for partition orders-4
[12/16/19 14:07:54:833 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=267, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:54:843 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:54:843 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:55:197 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 218, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:55:198 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:55:201 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:55:202 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=126) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:55:202 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:55:203 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=126,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 220 to node 0
[12/16/19 14:07:55:204 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:55:704 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 220, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:55:704 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:55:706 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:55:706 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=127) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:55:706 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:55:706 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=127,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 221 to node 0
[12/16/19 14:07:55:707 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:56:004 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:56:004 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 222 to node 2147483647
[12/16/19 14:07:56:006 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:56:008 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 222, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:56:009 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:56:010 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:56:010 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:56:209 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 221, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:56:210 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:56:211 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:56:211 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=128) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:56:211 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:56:212 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=128,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 223 to node 0
[12/16/19 14:07:56:214 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:56:714 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 223, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:56:714 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:56:715 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:56:715 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=129) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:56:715 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:56:715 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=129,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 224 to node 0
[12/16/19 14:07:56:716 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:57:216 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 224, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:57:217 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:57:217 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:57:217 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=130) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:57:218 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:57:218 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=130,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 225 to node 0
[12/16/19 14:07:57:218 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:57:718 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 225, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:57:719 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:57:719 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:57:719 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=131) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:57:719 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:57:720 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=131,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 226 to node 0
[12/16/19 14:07:57:720 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:58:115 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 570d25f0-a074-4b5e-9798-add20690bf24 completed
[12/16/19 14:07:58:115 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-2","orderId":"570d25f0-a074-4b5e-9798-add20690bf24","preparedBy":"Kyle"},"order":{"name":"Demo-2","orderId":"570d25f0-a074-4b5e-9798-add20690bf24","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@32719cdf to topic queue partition 0
[12/16/19 14:07:58:115 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:07:58:115 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:07:58:117 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:07:58:117 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 74 to node 0
[12/16/19 14:07:58:118 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505278115, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:07:58:119 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order a452b008-00ed-4a9b-9a4d-0a2133673bbf
[12/16/19 14:07:58:119 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 74, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4034,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:07:58:119 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 74
[12/16/19 14:07:58:119 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4034.
[12/16/19 14:07:58:221 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 226, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:58:221 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:58:222 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:58:222 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=132) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:58:223 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:58:223 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=132,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 227 to node 0
[12/16/19 14:07:58:224 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:58:727 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 227, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:58:727 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:58:734 GMT] 0000008a id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:07:58:741 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:07:58:741 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=258, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:58:741 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:07:58:741 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:07:58:741 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=258, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:58:747 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=258,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 228 to node 2147483647
[12/16/19 14:07:58:749 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:58:749 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=133) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:58:749 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:58:749 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=133,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 229 to node 0
[12/16/19 14:07:58:752 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 228, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:07:58:752 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 258 for partition orders-4
[12/16/19 14:07:58:752 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=258, leaderEpoch=0, metadata=''}}
[12/16/19 14:07:58:753 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:58:753 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:59:005 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:07:59:005 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 230 to node 2147483647
[12/16/19 14:07:59:009 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:59:009 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 230, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:07:59:010 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:07:59:010 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:59:010 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:59:250 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 229, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:59:251 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:59:251 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:59:251 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=134) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:59:252 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:59:252 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=134,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 231 to node 0
[12/16/19 14:07:59:252 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:59:753 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 231, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:07:59:754 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:07:59:754 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:59:754 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=135) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:07:59:754 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:59:754 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=135,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 232 to node 0
[12/16/19 14:07:59:755 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:07:59:884 GMT] 0000008f id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505399883) with a timeout 120000 ms from now.
[12/16/19 14:07:59:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:59:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505399883)] at 1576505279885
[12/16/19 14:07:59:885 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:59:885 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:07:59:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505399883) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:59:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=41
[12/16/19 14:07:59:885 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 41 to node 0
[12/16/19 14:07:59:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=111858)
[12/16/19 14:07:59:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:59:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505279886
[12/16/19 14:07:59:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=111857)
[12/16/19 14:07:59:886 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 41, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:59:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:59:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505399883) with a timeout 119997 ms from now.
[12/16/19 14:07:59:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505399883) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:07:59:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505399883)] at 1576505279886
[12/16/19 14:07:59:886 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:07:59:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505399883) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:07:59:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=42
[12/16/19 14:07:59:887 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 42 to node 0
[12/16/19 14:07:59:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=111857)
[12/16/19 14:07:59:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:07:59:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505279887
[12/16/19 14:07:59:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=111856)
[12/16/19 14:07:59:888 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 42, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:59:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:07:59:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505399883) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:07:59:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505279888
[12/16/19 14:07:59:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=111855)
[12/16/19 14:08:00:267 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 232, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:00:271 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:00:272 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:00:272 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=136) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:00:272 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:00:272 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=136,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 233 to node 0
[12/16/19 14:08:00:276 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:00:698 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order a452b008-00ed-4a9b-9a4d-0a2133673bbf completed
[12/16/19 14:08:00:700 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-7","orderId":"a452b008-00ed-4a9b-9a4d-0a2133673bbf","preparedBy":"Kyle"},"order":{"name":"Demo-7","orderId":"a452b008-00ed-4a9b-9a4d-0a2133673bbf","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@e550c103 to topic queue partition 0
[12/16/19 14:08:00:700 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:08:00:700 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:08:00:702 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:08:00:704 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=307]} with correlation id 75 to node 0
[12/16/19 14:08:00:705 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505280700, key=0 bytes, value=237 bytes))]}), transactionalId=''
[12/16/19 14:08:00:707 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 75, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4035,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:08:00:708 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 75
[12/16/19 14:08:00:708 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4035.
[12/16/19 14:08:00:840 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 233, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:00:841 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:00:841 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 013edae0-54bf-48cd-9b50-fae695658581
[12/16/19 14:08:00:865 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:00:869 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=137) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:00:872 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:00:874 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=137,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 234 to node 0
[12/16/19 14:08:00:879 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:01:225 GMT] 00000091 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:08:01:229 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:08:01:230 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=259, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:01:230 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:08:01:230 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:08:01:231 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=259, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:01:232 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=259,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 235 to node 2147483647
[12/16/19 14:08:01:234 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:01:235 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 235, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:08:01:235 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 259 for partition orders-4
[12/16/19 14:08:01:235 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=259, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:01:236 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:01:236 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:01:385 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 234, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:01:386 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:01:410 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:01:412 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=138) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:01:412 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:01:412 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=138,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 236 to node 0
[12/16/19 14:08:01:417 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:01:577 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 013edae0-54bf-48cd-9b50-fae695658581 completed
[12/16/19 14:08:01:578 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-12","orderId":"013edae0-54bf-48cd-9b50-fae695658581","preparedBy":"Kyle"},"order":{"name":"Demo-12","orderId":"013edae0-54bf-48cd-9b50-fae695658581","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@f89519 to topic queue partition 0
[12/16/19 14:08:01:578 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:08:01:578 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:08:01:579 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:08:01:580 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 76 to node 0
[12/16/19 14:08:01:580 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505281578, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:08:01:582 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 76, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4036,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:08:01:582 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 76
[12/16/19 14:08:01:582 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4036.
[12/16/19 14:08:01:586 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order a0cfdfdb-41af-4ce6-91da-5b0d0313b34f
[12/16/19 14:08:01:916 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 236, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:01:916 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:01:917 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:01:917 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=139) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:01:917 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:01:918 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=139,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 237 to node 0
[12/16/19 14:08:01:919 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:02:007 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:02:007 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 238 to node 2147483647
[12/16/19 14:08:02:008 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:02:008 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 238, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:02:008 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:02:009 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:02:009 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:02:084 GMT] 00000091 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:08:02:085 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:08:02:086 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=260, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:02:086 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:08:02:086 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:08:02:086 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=260, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:02:086 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=260,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 239 to node 2147483647
[12/16/19 14:08:02:088 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:02:088 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 239, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:08:02:088 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 260 for partition orders-4
[12/16/19 14:08:02:088 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=260, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:02:089 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:02:091 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:02:421 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 237, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:02:422 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:02:424 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:02:424 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=140) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:02:424 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:02:425 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=140,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 240 to node 0
[12/16/19 14:08:02:427 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:02:928 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 240, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:02:928 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:02:929 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:02:929 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=141) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:02:929 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:02:929 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=141,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 241 to node 0
[12/16/19 14:08:02:930 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:03:431 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 241, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:03:434 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:03:446 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:03:446 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=142) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:03:446 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:03:446 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=142,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 242 to node 0
[12/16/19 14:08:03:473 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:03:979 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 242, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:03:980 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:03:981 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:03:981 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=143) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:03:982 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:03:984 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=143,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 243 to node 0
[12/16/19 14:08:03:987 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:04:492 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 243, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:04:494 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:04:495 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:04:495 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=144) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:04:495 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:04:495 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=144,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 244 to node 0
[12/16/19 14:08:04:496 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:04:996 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 244, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:04:997 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:04:997 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:04:998 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=145) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:04:998 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:04:998 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=145,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 245 to node 0
[12/16/19 14:08:04:999 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:05:008 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:05:008 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 246 to node 2147483647
[12/16/19 14:08:05:009 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:05:010 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 246, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:05:010 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:05:011 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:05:013 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:05:498 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order a0cfdfdb-41af-4ce6-91da-5b0d0313b34f completed
[12/16/19 14:08:05:499 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-17","orderId":"a0cfdfdb-41af-4ce6-91da-5b0d0313b34f","preparedBy":"Kyle"},"order":{"name":"Demo-17","orderId":"a0cfdfdb-41af-4ce6-91da-5b0d0313b34f","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@59f98e95 to topic queue partition 0
[12/16/19 14:08:05:499 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:08:05:499 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:08:05:500 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 245, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:05:500 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:08:05:501 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 77 to node 0
[12/16/19 14:08:05:501 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505285499, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:08:05:505 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:05:505 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:05:505 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=146) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:05:506 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:05:506 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=146,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 247 to node 0
[12/16/19 14:08:05:507 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 77, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4037,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:08:05:507 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 77
[12/16/19 14:08:05:507 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:05:507 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4037.
[12/16/19 14:08:05:513 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 42f0de7d-ec39-49c1-a680-8311a2edfc34
[12/16/19 14:08:05:680 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 42f0de7d-ec39-49c1-a680-8311a2edfc34 completed
[12/16/19 14:08:05:680 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-22","orderId":"42f0de7d-ec39-49c1-a680-8311a2edfc34","preparedBy":"Kyle"},"order":{"name":"Demo-22","orderId":"42f0de7d-ec39-49c1-a680-8311a2edfc34","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@7cfa90b to topic queue partition 0
[12/16/19 14:08:05:683 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:08:05:684 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:08:05:686 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:08:05:688 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 78 to node 0
[12/16/19 14:08:05:689 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505285680, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:08:05:691 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 78, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4038,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:08:05:692 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 78
[12/16/19 14:08:05:693 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4038.
[12/16/19 14:08:05:697 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order cdc30157-a3ac-4c8d-8918-a890e46e7a25
[12/16/19 14:08:05:892 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order cdc30157-a3ac-4c8d-8918-a890e46e7a25 completed
[12/16/19 14:08:05:892 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-27","orderId":"cdc30157-a3ac-4c8d-8918-a890e46e7a25","preparedBy":"Kyle"},"order":{"name":"Demo-27","orderId":"cdc30157-a3ac-4c8d-8918-a890e46e7a25","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@c452231e to topic queue partition 0
[12/16/19 14:08:05:892 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:08:05:917 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:08:05:918 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:08:05:918 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 79 to node 0
[12/16/19 14:08:05:919 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505285892, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:08:05:921 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order 233c210c-ccc9-4571-aeea-8a6df93523ee
[12/16/19 14:08:05:922 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 79, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4039,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:08:05:922 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 79
[12/16/19 14:08:05:923 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4039.
[12/16/19 14:08:06:008 GMT] 00000094 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:08:06:015 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 247, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:06:028 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:08:06:043 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:06:044 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=263, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:06:044 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:08:06:044 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:08:06:044 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=263, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:06:045 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=263,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 248 to node 2147483647
[12/16/19 14:08:06:047 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:06:048 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=147) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:06:048 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:06:048 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=147,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 249 to node 0
[12/16/19 14:08:06:050 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 248, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:08:06:051 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 263 for partition orders-4
[12/16/19 14:08:06:051 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=263, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:06:052 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:06:053 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:06:130 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order 233c210c-ccc9-4571-aeea-8a6df93523ee completed
[12/16/19 14:08:06:132 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-32","orderId":"233c210c-ccc9-4571-aeea-8a6df93523ee","preparedBy":"Kyle"},"order":{"name":"Demo-32","orderId":"233c210c-ccc9-4571-aeea-8a6df93523ee","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@afa96a10 to topic queue partition 0
[12/16/19 14:08:06:133 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:08:06:134 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:08:06:137 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:08:06:138 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 80 to node 0
[12/16/19 14:08:06:139 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505286131, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:08:06:141 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 80, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4040,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:08:06:141 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 80
[12/16/19 14:08:06:141 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4040.
[12/16/19 14:08:06:144 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order f8a47ed7-6c16-49b5-99c8-2530e02dbdbe
[12/16/19 14:08:06:550 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 249, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:06:550 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:06:551 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:06:551 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=148) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:06:551 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:06:552 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=148,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 250 to node 0
[12/16/19 14:08:06:553 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:06:651 GMT] 00000095 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:08:06:652 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:08:06:656 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=264, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:06:657 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:08:06:666 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:08:06:679 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=264, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:06:682 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=264,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 251 to node 2147483647
[12/16/19 14:08:06:689 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:06:692 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 251, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:08:06:693 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 264 for partition orders-4
[12/16/19 14:08:06:693 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=264, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:06:694 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:06:695 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:07:052 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 250, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:07:052 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:07:053 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:07:054 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=149) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:07:054 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:07:054 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=149,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 252 to node 0
[12/16/19 14:08:07:055 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:07:556 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 252, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:07:556 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:07:558 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:07:558 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=150) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:07:558 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:07:559 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=150,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 253 to node 0
[12/16/19 14:08:07:560 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:08:009 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:08:010 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 254 to node 2147483647
[12/16/19 14:08:08:010 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:08:011 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 254, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:08:011 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:08:011 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:08:012 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:08:060 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 253, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:08:060 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:08:061 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:08:061 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=151) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:08:061 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:08:061 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=151,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 255 to node 0
[12/16/19 14:08:08:062 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:08:562 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 255, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:08:563 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:08:563 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:08:563 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=152) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:08:564 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:08:565 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=152,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 256 to node 0
[12/16/19 14:08:08:566 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:09:066 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 256, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:09:067 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:09:068 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:09:068 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=153) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:09:068 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:09:069 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=153,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 257 to node 0
[12/16/19 14:08:09:069 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:09:581 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 257, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:09:582 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:09:582 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:09:583 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=154) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:09:583 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:09:583 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=154,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 258 to node 0
[12/16/19 14:08:09:584 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:09:882 GMT] 00000095 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505409882) with a timeout 120000 ms from now.
[12/16/19 14:08:09:883 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:09:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505409882)] at 1576505289883
[12/16/19 14:08:09:884 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:09:884 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:08:09:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505409882) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:09:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=43
[12/16/19 14:08:09:884 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 43 to node 0
[12/16/19 14:08:09:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=101860)
[12/16/19 14:08:09:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:09:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505289885
[12/16/19 14:08:09:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=101858)
[12/16/19 14:08:09:886 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 43, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:09:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:09:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505409882) with a timeout 119996 ms from now.
[12/16/19 14:08:09:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505409882) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:09:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505409882)] at 1576505289886
[12/16/19 14:08:09:887 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:09:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505409882) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:09:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=44
[12/16/19 14:08:09:887 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 44 to node 0
[12/16/19 14:08:09:887 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=101857)
[12/16/19 14:08:09:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:09:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505289890
[12/16/19 14:08:09:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=101853)
[12/16/19 14:08:09:892 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 44, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:09:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:09:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505409882) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:09:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505289893
[12/16/19 14:08:09:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=101850)
[12/16/19 14:08:10:084 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 258, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:10:085 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:10:086 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:10:086 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=155) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:10:087 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:10:088 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=155,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 259 to node 0
[12/16/19 14:08:10:090 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:10:593 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 259, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:10:594 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:10:603 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:10:609 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=156) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:10:610 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:10:610 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=156,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 260 to node 0
[12/16/19 14:08:10:618 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:10:706 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order f8a47ed7-6c16-49b5-99c8-2530e02dbdbe completed
[12/16/19 14:08:10:707 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-37","orderId":"f8a47ed7-6c16-49b5-99c8-2530e02dbdbe","preparedBy":"Kyle"},"order":{"name":"Demo-37","orderId":"f8a47ed7-6c16-49b5-99c8-2530e02dbdbe","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@e6fcdd56 to topic queue partition 0
[12/16/19 14:08:10:708 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:08:10:708 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:08:10:711 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:08:10:712 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 81 to node 0
[12/16/19 14:08:10:713 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505290707, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:08:10:715 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 81, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4041,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:08:10:715 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 81
[12/16/19 14:08:10:715 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4041.
[12/16/19 14:08:10:723 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order bb4568cb-dbb5-48d3-af7c-e38bbf86b011
[12/16/19 14:08:11:014 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:11:015 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 261 to node 2147483647
[12/16/19 14:08:11:015 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:11:016 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 261, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:11:016 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:11:016 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:11:017 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:11:041 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order bb4568cb-dbb5-48d3-af7c-e38bbf86b011 completed
[12/16/19 14:08:11:041 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-42","orderId":"bb4568cb-dbb5-48d3-af7c-e38bbf86b011","preparedBy":"Kyle"},"order":{"name":"Demo-42","orderId":"bb4568cb-dbb5-48d3-af7c-e38bbf86b011","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@34102592 to topic queue partition 0
[12/16/19 14:08:11:042 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:08:11:042 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:08:11:042 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:08:11:043 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 82 to node 0
[12/16/19 14:08:11:043 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505291041, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:08:11:046 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 prepare Barista Kyle has received order ed633a6c-f5b8-476a-95c7-c3df2ba878f5
[12/16/19 14:08:11:048 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 82, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4042,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:08:11:048 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 82
[12/16/19 14:08:11:048 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4042.
[12/16/19 14:08:11:120 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 260, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:11:120 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:11:123 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:11:123 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=157) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:11:123 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:11:123 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=157,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 262 to node 0
[12/16/19 14:08:11:125 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:11:220 GMT] 00000095 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:08:11:231 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:08:11:236 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=266, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:11:237 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:08:11:237 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:08:11:238 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=266, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:11:238 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=266,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 263 to node 2147483647
[12/16/19 14:08:11:240 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:11:241 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 263, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:08:11:241 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 266 for partition orders-4
[12/16/19 14:08:11:242 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=266, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:11:243 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:11:243 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:11:625 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 262, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:11:626 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:11:629 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:11:629 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=158) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:11:630 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:11:630 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=158,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 264 to node 0
[12/16/19 14:08:11:631 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:12:132 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 264, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:12:134 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:12:134 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:12:135 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=159) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:12:135 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:12:135 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=159,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 265 to node 0
[12/16/19 14:08:12:136 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:12:638 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 265, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:12:642 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:12:644 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:12:644 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=160) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:12:644 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:12:646 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=160,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 266 to node 0
[12/16/19 14:08:12:648 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:13:149 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 266, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:13:150 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:13:150 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:13:150 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=161) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:13:151 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:13:151 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=161,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 267 to node 0
[12/16/19 14:08:13:152 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:13:674 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 267, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:13:677 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:13:677 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:13:678 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=162) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:13:678 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:13:679 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=162,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 268 to node 0
[12/16/19 14:08:13:681 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:14:017 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:14:018 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 269 to node 2147483647
[12/16/19 14:08:14:019 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:14:019 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 269, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:14:020 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:14:020 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:14:020 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:14:021 GMT] 0000004f id=00000000 me.escoffier.quarkus.coffeeshop.KafkaBarista                 1 lambda$makeIt$1 Order ed633a6c-f5b8-476a-95c7-c3df2ba878f5 completed
[12/16/19 14:08:14:021 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Sending record ProducerRecord(topic=queue, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value={"beverage":{"beverage":"espresso","customer":"Demo-47","orderId":"ed633a6c-f5b8-476a-95c7-c3df2ba878f5","preparedBy":"Kyle"},"order":{"name":"Demo-47","orderId":"ed633a6c-f5b8-476a-95c7-c3df2ba878f5","product":"espresso"},"state":"READY"}, timestamp=null) with callback com.ibm.ws.microprofile.reactive.messaging.kafka.adapter.impl.KafkaProducerImpl$$Lambda$462/0000000000000000@814b1e33 to topic queue partition 0
[12/16/19 14:08:14:022 GMT] 0000004f id=00000000 rg.apache.kafka.clients.producer.internals.RecordAccumulator 3 append [Producer clientId=producer-1] Allocating a new 16384 byte message buffer for topic queue partition 0
[12/16/19 14:08:14:022 GMT] 0000004f id=00000000 org.apache.kafka.clients.producer.KafkaProducer              3 doSend [Producer clientId=producer-1] Waking up the sender since topic queue partition 0 is either full or getting a new batch
[12/16/19 14:08:14:022 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProducerData [Producer clientId=producer-1] Nodes with data ready to send: [my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )]
[12/16/19 14:08:14:023 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Producer clientId=producer-1] Sending PRODUCE {acks=1,timeout=30000,partitionSizes=[queue-0=309]} with correlation id 83 to node 0
[12/16/19 14:08:14:023 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 sendProduceRequest [Producer clientId=producer-1] Sent produce request to 0: (type=ProduceRequest, acks=1, timeout=30000, partitionRecords=({queue-0=[(record=DefaultRecord(offset=0, timestamp=1576505294021, key=0 bytes, value=239 bytes))]}), transactionalId=''
[12/16/19 14:08:14:024 GMT] 0000004a id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Producer clientId=producer-1] Completed receive from node 0 for PRODUCE with correlation id 83, received {responses=[{topic=queue,partition_responses=[{partition=0,error_code=0,base_offset=4043,log_append_time=-1,log_start_offset=0}]}],throttle_time_ms=0}
[12/16/19 14:08:14:025 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.Sender           3 handleProduceResponse [Producer clientId=producer-1] Received produce response from node 0 with correlation id 83
[12/16/19 14:08:14:025 GMT] 0000004a id=00000000 org.apache.kafka.clients.producer.internals.ProducerBatch    3 done Successfully produced messages to queue-0 with base offset 4043.
[12/16/19 14:08:14:190 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 268, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:14:191 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:14:191 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:14:191 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=163) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:14:192 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:14:192 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=163,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 270 to node 0
[12/16/19 14:08:14:199 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:14:526 GMT] 00000095 id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 wakeup [Consumer clientId=consumer-1, groupId=baristas] Received user wakeup
[12/16/19 14:08:14:530 GMT] 0000007f id=00000000 pache.kafka.clients.consumer.internals.ConsumerNetworkClient 1 maybeTriggerWakeup [Consumer clientId=consumer-1, groupId=baristas] Raising WakeupException in response to user wakeup
[12/16/19 14:08:14:536 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.KafkaConsumer              1 commitAsync [Consumer clientId=consumer-1, groupId=baristas] Committing offsets: {orders-4=OffsetAndMetadata{offset=267, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:14:536 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            3 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Determining if we should replace existing epoch 0 with new epoch 0
[12/16/19 14:08:14:537 GMT] 0000007f id=00000000 org.apache.kafka.clients.Metadata                            1 updateLastSeenEpoch [Consumer clientId=consumer-1, groupId=baristas] Not replacing existing epoch 0 with new epoch 0
[12/16/19 14:08:14:538 GMT] 0000007f id=00000000 .apache.kafka.clients.consumer.internals.ConsumerCoordinator 3 sendOffsetCommitRequest [Consumer clientId=consumer-1, groupId=baristas] Sending OffsetCommit request with {orders-4=OffsetAndMetadata{offset=267, leaderEpoch=0, metadata=''}} to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:14:538 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending OFFSET_COMMIT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null,topics=[{name=orders,partitions=[{partition_index=4,committed_offset=267,committed_leader_epoch=0,committed_metadata=}]}]} with correlation id 271 to node 2147483647
[12/16/19 14:08:14:540 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:14:541 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for OFFSET_COMMIT with correlation id 271, received {throttle_time_ms=0,topics=[{name=orders,partitions=[{partition_index=4,error_code=0}]}]}
[12/16/19 14:08:14:542 GMT] 0000007f id=00000000 er.internals.ConsumerCoordinator$OffsetCommitResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Committed offset 267 for partition orders-4
[12/16/19 14:08:14:542 GMT] 0000007f id=00000000 com.ibm.ws.microprofile.reactive.messaging.kafka.KafkaInput  3 Committed offsets successfully 
                                                                                                               {orders-4=OffsetAndMetadata{offset=267, leaderEpoch=0, metadata=''}}
[12/16/19 14:08:14:543 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:14:544 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:14:697 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 270, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:14:699 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:14:699 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:14:699 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=164) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:14:699 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:14:700 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=164,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 272 to node 0
[12/16/19 14:08:14:701 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:15:202 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 272, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:15:204 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:15:204 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:15:204 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=165) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:15:204 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:15:205 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=165,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 273 to node 0
[12/16/19 14:08:15:205 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:15:707 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 273, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:15:708 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:15:711 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:15:712 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=166) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:15:712 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:15:713 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=166,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 274 to node 0
[12/16/19 14:08:15:716 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:16:218 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 274, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:16:223 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:16:231 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:16:231 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=167) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:16:231 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:16:231 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=167,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 275 to node 0
[12/16/19 14:08:16:233 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:16:734 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 275, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:16:736 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:16:737 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:16:738 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=168) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:16:738 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:16:738 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=168,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 276 to node 0
[12/16/19 14:08:16:739 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:17:019 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:17:019 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 277 to node 2147483647
[12/16/19 14:08:17:020 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:17:021 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 277, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:17:021 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:17:021 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:17:022 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:17:240 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 276, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:17:241 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:17:242 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:17:243 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=169) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:17:243 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:17:243 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=169,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 278 to node 0
[12/16/19 14:08:17:247 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:17:749 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 278, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:17:751 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:17:753 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:17:753 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=170) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:17:753 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:17:755 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=170,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 279 to node 0
[12/16/19 14:08:17:757 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:18:257 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 279, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:18:259 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:18:260 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:18:260 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=171) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:18:260 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:18:261 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=171,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 280 to node 0
[12/16/19 14:08:18:262 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:18:763 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 280, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:18:764 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:18:764 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:18:764 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=172) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:18:764 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:18:765 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=172,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 281 to node 0
[12/16/19 14:08:18:766 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:19:267 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 281, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:19:279 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:19:280 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:19:280 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=173) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:19:280 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:19:280 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=173,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 282 to node 0
[12/16/19 14:08:19:287 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:19:782 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 282, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:19:783 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:19:784 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:19:784 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=174) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:19:784 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:19:784 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=174,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 283 to node 0
[12/16/19 14:08:19:787 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:19:886 GMT] 00000095 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505419886) with a timeout 120000 ms from now.
[12/16/19 14:08:19:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:19:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505419886)] at 1576505299888
[12/16/19 14:08:19:888 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:19:888 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:08:19:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505419886) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:19:888 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=45
[12/16/19 14:08:19:889 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 45 to node 0
[12/16/19 14:08:19:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=91855)
[12/16/19 14:08:19:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:19:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505299889
[12/16/19 14:08:19:889 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=91854)
[12/16/19 14:08:19:892 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 45, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:19:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:19:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505419886) with a timeout 119994 ms from now.
[12/16/19 14:08:19:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505419886) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:19:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505419886)] at 1576505299892
[12/16/19 14:08:19:893 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:19:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505419886) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:19:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=46
[12/16/19 14:08:19:893 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 46 to node 0
[12/16/19 14:08:19:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=91851)
[12/16/19 14:08:19:895 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:19:895 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505299895
[12/16/19 14:08:19:895 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=91848)
[12/16/19 14:08:19:896 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 46, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:19:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:19:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505419886) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:19:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505299896
[12/16/19 14:08:19:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=91847)
[12/16/19 14:08:20:023 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:20:023 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 284 to node 2147483647
[12/16/19 14:08:20:025 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:20:025 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 284, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:20:025 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:20:026 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:20:026 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:20:286 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 283, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:20:286 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:20:293 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:20:294 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=175) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:20:294 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:20:294 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=175,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 285 to node 0
[12/16/19 14:08:20:298 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:20:799 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 285, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:20:813 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:20:814 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:20:814 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=176) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:20:815 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:20:815 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=176,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 286 to node 0
[12/16/19 14:08:20:816 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:21:329 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 286, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:21:332 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:21:333 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:21:333 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=177) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:21:333 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:21:333 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=177,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 287 to node 0
[12/16/19 14:08:21:334 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:21:835 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 287, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:21:836 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:21:836 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:21:836 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=178) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:21:837 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:21:837 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=178,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 288 to node 0
[12/16/19 14:08:21:838 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:22:340 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 288, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:22:352 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:22:355 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:22:356 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=179) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:22:357 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:22:358 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=179,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 289 to node 0
[12/16/19 14:08:22:359 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:22:860 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 289, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:22:872 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:22:873 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:22:874 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=180) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:22:874 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:22:875 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=180,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 290 to node 0
[12/16/19 14:08:22:883 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:23:027 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:23:028 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 291 to node 2147483647
[12/16/19 14:08:23:030 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:23:030 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 291, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:23:030 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:23:031 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:23:031 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:23:378 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 290, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:23:381 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:23:382 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:23:382 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=181) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:23:383 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:23:383 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=181,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 292 to node 0
[12/16/19 14:08:23:387 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:23:885 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 292, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:23:886 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:23:887 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:23:887 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=182) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:23:887 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:23:887 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=182,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 293 to node 0
[12/16/19 14:08:23:890 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:24:388 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 293, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:24:389 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:24:390 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:24:390 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=183) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:24:390 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:24:391 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=183,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 294 to node 0
[12/16/19 14:08:24:393 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:24:892 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 294, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:24:893 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:24:894 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:24:894 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=184) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:24:894 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:24:894 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=184,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 295 to node 0
[12/16/19 14:08:24:895 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:25:396 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 295, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:25:403 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:25:404 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:25:404 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=185) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:25:405 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:25:406 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=185,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 296 to node 0
[12/16/19 14:08:25:408 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:25:942 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 296, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:25:944 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:25:951 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:25:952 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=186) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:25:952 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:25:953 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=186,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 297 to node 0
[12/16/19 14:08:25:954 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:26:047 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:26:047 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 298 to node 2147483647
[12/16/19 14:08:26:053 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:26:062 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 298, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:26:062 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:26:066 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:26:066 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:26:453 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 297, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:26:454 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:26:454 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:26:454 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=187) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:26:454 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:26:454 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=187,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 299 to node 0
[12/16/19 14:08:26:455 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:26:956 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 299, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:26:956 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:26:956 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:26:957 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=188) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:26:957 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:26:957 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=188,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 300 to node 0
[12/16/19 14:08:26:957 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:27:459 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 300, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:27:464 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:27:466 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:27:466 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=189) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:27:467 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:27:468 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=189,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 301 to node 0
[12/16/19 14:08:27:470 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:27:970 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 301, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:27:972 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:27:977 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:27:978 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=190) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:27:978 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:27:979 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=190,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 302 to node 0
[12/16/19 14:08:27:981 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:28:480 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 302, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:28:480 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:28:481 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:28:481 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=191) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:28:481 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:28:481 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=191,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 303 to node 0
[12/16/19 14:08:28:482 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:28:983 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 303, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:28:983 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:28:984 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:28:984 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=192) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:28:984 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:28:984 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=192,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 304 to node 0
[12/16/19 14:08:28:985 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:29:048 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:29:048 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 305 to node 2147483647
[12/16/19 14:08:29:049 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:29:049 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 305, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:29:049 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:29:050 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:29:050 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:29:485 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 304, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:29:487 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:29:487 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:29:488 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=193) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:29:488 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:29:488 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=193,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 306 to node 0
[12/16/19 14:08:29:490 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:29:881 GMT] 0000009c id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505429881) with a timeout 120000 ms from now.
[12/16/19 14:08:29:882 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:29:882 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505429881)] at 1576505309882
[12/16/19 14:08:29:882 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:29:882 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:08:29:882 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505429881) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:29:882 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=47
[12/16/19 14:08:29:882 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 47 to node 0
[12/16/19 14:08:29:883 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=81861)
[12/16/19 14:08:29:883 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:29:883 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505309883
[12/16/19 14:08:29:883 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=81860)
[12/16/19 14:08:29:884 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 47, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:29:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:29:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505429881) with a timeout 119997 ms from now.
[12/16/19 14:08:29:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505429881) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:29:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505429881)] at 1576505309884
[12/16/19 14:08:29:884 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:29:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505429881) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:29:884 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=48
[12/16/19 14:08:29:884 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 48 to node 0
[12/16/19 14:08:29:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=81859)
[12/16/19 14:08:29:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:29:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505309885
[12/16/19 14:08:29:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=81858)
[12/16/19 14:08:29:885 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 48, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:29:885 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:29:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505429881) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:29:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505309885
[12/16/19 14:08:29:886 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=81858)
[12/16/19 14:08:29:991 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 306, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:29:991 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:29:992 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:29:992 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=194) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:29:992 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:29:993 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=194,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 307 to node 0
[12/16/19 14:08:29:994 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:30:515 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 307, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:30:518 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:30:519 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:30:520 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=195) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:30:520 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:30:520 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=195,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 308 to node 0
[12/16/19 14:08:30:521 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:31:032 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 308, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:31:033 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:31:036 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:31:036 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=196) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:31:036 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:31:036 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=196,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 309 to node 0
[12/16/19 14:08:31:037 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:31:539 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 309, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:31:540 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:31:540 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:31:540 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=197) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:31:541 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:31:541 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=197,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 310 to node 0
[12/16/19 14:08:31:541 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:32:042 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 310, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:32:042 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:32:043 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:32:043 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=198) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:32:043 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:32:043 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=198,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 311 to node 0
[12/16/19 14:08:32:044 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:32:048 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:32:049 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 312 to node 2147483647
[12/16/19 14:08:32:055 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:32:055 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 312, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:32:055 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:32:055 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:32:056 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:32:546 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 311, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:32:546 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:32:547 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:32:548 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=199) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:32:548 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:32:548 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=199,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 313 to node 0
[12/16/19 14:08:32:551 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:33:053 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 313, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:33:055 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:33:056 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:33:056 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=200) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:33:057 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:33:062 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=200,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 314 to node 0
[12/16/19 14:08:33:064 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:33:565 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 314, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:33:565 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:33:568 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:33:568 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=201) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:33:569 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:33:569 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=201,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 315 to node 0
[12/16/19 14:08:33:572 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:34:071 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 315, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:34:072 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:34:073 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:34:073 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=202) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:34:074 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:34:074 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=202,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 316 to node 0
[12/16/19 14:08:34:075 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:34:576 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 316, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:34:577 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:34:577 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:34:577 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=203) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:34:577 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:34:579 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=203,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 317 to node 0
[12/16/19 14:08:34:581 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:35:050 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:35:051 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 318 to node 2147483647
[12/16/19 14:08:35:054 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:35:055 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 318, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:35:055 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:35:056 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:35:057 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:35:082 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 317, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:35:083 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:35:083 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:35:084 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=204) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:35:084 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:35:084 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=204,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 319 to node 0
[12/16/19 14:08:35:085 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:35:590 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 319, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:35:592 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:35:600 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:35:604 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=205) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:35:604 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:35:606 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=205,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 320 to node 0
[12/16/19 14:08:35:607 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:36:109 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 320, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:36:109 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:36:110 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:36:110 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=206) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:36:111 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:36:121 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=206,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 321 to node 0
[12/16/19 14:08:36:124 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:36:624 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 321, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:36:626 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:36:626 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:36:626 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=207) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:36:626 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:36:627 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=207,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 322 to node 0
[12/16/19 14:08:36:628 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:37:129 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 322, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:37:132 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:37:134 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:37:134 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=208) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:37:135 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:37:135 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=208,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 323 to node 0
[12/16/19 14:08:37:140 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:37:640 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 323, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:37:646 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:37:647 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:37:647 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=209) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:37:648 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:37:654 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=209,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 324 to node 0
[12/16/19 14:08:37:660 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:38:058 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:38:060 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 325 to node 2147483647
[12/16/19 14:08:38:063 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:38:065 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 325, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:38:066 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:38:067 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:38:068 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:38:159 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 324, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:38:160 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:38:168 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:38:168 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=210) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:38:168 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:38:170 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=210,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 326 to node 0
[12/16/19 14:08:38:174 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:38:673 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 326, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:38:673 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:38:674 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:38:674 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=211) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:38:674 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:38:674 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=211,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 327 to node 0
[12/16/19 14:08:38:675 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:39:175 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 327, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:39:178 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:39:179 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:39:179 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=212) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:39:179 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:39:179 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=212,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 328 to node 0
[12/16/19 14:08:39:182 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:39:686 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 328, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:39:690 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:39:696 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:39:697 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=213) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:39:697 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:39:698 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=213,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 329 to node 0
[12/16/19 14:08:39:699 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:39:890 GMT] 0000009c id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505439890) with a timeout 120000 ms from now.
[12/16/19 14:08:39:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:39:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505439890)] at 1576505319891
[12/16/19 14:08:39:891 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:39:891 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:08:39:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505439890) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:39:891 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=49
[12/16/19 14:08:39:891 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 49 to node 0
[12/16/19 14:08:39:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=71852)
[12/16/19 14:08:39:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:39:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505319892
[12/16/19 14:08:39:892 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=71851)
[12/16/19 14:08:39:893 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 49, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:39:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:39:893 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505439890) with a timeout 119997 ms from now.
[12/16/19 14:08:39:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505439890) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:39:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505439890)] at 1576505319893
[12/16/19 14:08:39:894 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:39:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505439890) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:39:894 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=50
[12/16/19 14:08:39:894 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 50 to node 0
[12/16/19 14:08:39:895 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=71850)
[12/16/19 14:08:39:895 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:39:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505319895
[12/16/19 14:08:39:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=71848)
[12/16/19 14:08:39:896 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 50, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:39:896 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:39:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505439890) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:39:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505319896
[12/16/19 14:08:39:901 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=71847)
[12/16/19 14:08:40:216 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 329, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:40:221 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:40:238 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:40:252 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=214) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:40:255 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:40:256 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=214,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 330 to node 0
[12/16/19 14:08:40:258 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:40:760 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 330, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:40:761 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:40:761 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:40:761 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=215) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:40:761 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:40:762 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=215,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 331 to node 0
[12/16/19 14:08:40:762 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:41:058 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:41:058 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 332 to node 2147483647
[12/16/19 14:08:41:060 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:41:061 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 332, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:41:061 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:41:062 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:41:062 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:41:265 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 331, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:41:265 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:41:266 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:41:266 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=216) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:41:266 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:41:266 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=216,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 333 to node 0
[12/16/19 14:08:41:268 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:41:769 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 333, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:41:770 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:41:772 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:41:772 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=217) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:41:773 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:41:775 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=217,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 334 to node 0
[12/16/19 14:08:41:777 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:42:278 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 334, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:42:279 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:42:280 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:42:280 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=218) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:42:280 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:42:281 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=218,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 335 to node 0
[12/16/19 14:08:42:282 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:42:782 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 335, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:42:783 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:42:783 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:42:783 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=219) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:42:783 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:42:783 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=219,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 336 to node 0
[12/16/19 14:08:42:784 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:43:285 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 336, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:43:286 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:43:288 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:43:289 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=220) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:43:289 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:43:289 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=220,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 337 to node 0
[12/16/19 14:08:43:292 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:43:791 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 337, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:43:794 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:43:794 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:43:794 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=221) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:43:794 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:43:795 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=221,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 338 to node 0
[12/16/19 14:08:43:795 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:44:059 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:44:059 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 339 to node 2147483647
[12/16/19 14:08:44:061 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:44:062 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 339, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:44:062 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:44:062 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:44:063 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:44:296 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 338, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:44:297 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:44:298 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:44:298 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=222) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:44:298 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:44:299 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=222,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 340 to node 0
[12/16/19 14:08:44:301 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:44:801 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 340, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:44:801 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:44:801 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:44:802 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=223) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:44:802 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:44:802 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=223,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 341 to node 0
[12/16/19 14:08:44:804 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:45:304 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 341, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:45:305 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:45:307 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:45:308 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=224) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:45:308 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:45:309 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=224,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 342 to node 0
[12/16/19 14:08:45:313 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:45:812 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 342, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:45:813 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:45:815 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:45:815 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=225) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:45:815 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:45:816 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=225,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 343 to node 0
[12/16/19 14:08:45:818 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:46:318 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 343, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:46:318 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:46:354 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:46:354 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=226) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:46:354 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:46:354 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=226,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 344 to node 0
[12/16/19 14:08:46:360 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:46:862 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 344, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:46:871 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:46:872 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:46:872 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=227) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:46:872 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:46:872 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=227,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 345 to node 0
[12/16/19 14:08:46:873 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:47:062 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:47:063 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 346 to node 2147483647
[12/16/19 14:08:47:065 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:47:066 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 346, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:47:066 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:47:066 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:47:068 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:47:373 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 345, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:47:374 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:47:374 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:47:374 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=228) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:47:374 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:47:375 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=228,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 347 to node 0
[12/16/19 14:08:47:376 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:47:881 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 347, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:47:896 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:47:899 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:47:900 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=229) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:47:900 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:47:901 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=229,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 348 to node 0
[12/16/19 14:08:47:911 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:48:403 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 348, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:48:406 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:48:415 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:48:416 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=230) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:48:416 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:48:419 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=230,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 349 to node 0
[12/16/19 14:08:48:420 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:48:922 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 349, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:48:922 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:48:924 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:48:924 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=231) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:48:924 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:48:925 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=231,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 350 to node 0
[12/16/19 14:08:48:925 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:49:425 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 350, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:49:426 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:49:427 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:49:427 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=232) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:49:427 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:49:427 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=232,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 351 to node 0
[12/16/19 14:08:49:433 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:49:895 GMT] 0000009e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505449895) with a timeout 120000 ms from now.
[12/16/19 14:08:49:904 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:49:905 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505449895)] at 1576505329905
[12/16/19 14:08:49:905 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:49:905 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:08:49:906 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505449895) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:49:906 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=51
[12/16/19 14:08:49:907 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 51 to node 0
[12/16/19 14:08:49:907 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=61838)
[12/16/19 14:08:49:908 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:49:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505329909
[12/16/19 14:08:49:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=61834)
[12/16/19 14:08:49:909 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 51, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:49:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:49:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505449895) with a timeout 119986 ms from now.
[12/16/19 14:08:49:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505449895) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:49:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505449895)] at 1576505329909
[12/16/19 14:08:49:910 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:49:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505449895) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:49:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=52
[12/16/19 14:08:49:910 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 52 to node 0
[12/16/19 14:08:49:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=61834)
[12/16/19 14:08:49:911 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:49:911 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505329911
[12/16/19 14:08:49:911 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=61832)
[12/16/19 14:08:49:912 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 52, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:49:912 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:49:912 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505449895) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:49:912 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505329912
[12/16/19 14:08:49:912 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=61831)
[12/16/19 14:08:49:934 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 351, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:49:934 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:49:936 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:49:937 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=233) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:49:937 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:49:937 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=233,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 352 to node 0
[12/16/19 14:08:49:938 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:50:063 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:50:063 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 353 to node 2147483647
[12/16/19 14:08:50:064 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:50:065 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 353, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:50:065 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:50:065 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:50:065 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:50:438 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 352, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:50:439 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:50:441 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:50:441 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=234) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:50:442 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:50:443 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=234,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 354 to node 0
[12/16/19 14:08:50:449 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:50:945 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 354, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:50:946 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:50:947 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:50:960 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=235) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:50:961 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:50:962 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=235,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 355 to node 0
[12/16/19 14:08:50:966 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:51:465 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 355, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:51:465 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:51:466 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:51:466 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=236) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:51:467 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:51:467 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=236,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 356 to node 0
[12/16/19 14:08:51:467 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:51:968 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 356, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:51:970 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:51:972 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:51:974 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=237) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:51:975 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:51:975 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=237,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 357 to node 0
[12/16/19 14:08:51:979 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:52:478 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 357, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:52:481 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:52:484 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:52:484 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=238) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:52:485 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:52:492 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=238,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 358 to node 0
[12/16/19 14:08:52:498 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:52:995 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 358, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:52:996 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:52:999 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:52:999 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=239) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:52:999 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:53:000 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=239,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 359 to node 0
[12/16/19 14:08:53:015 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:53:065 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:53:065 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 360 to node 2147483647
[12/16/19 14:08:53:066 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:53:066 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 360, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:53:067 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:53:067 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:53:067 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:53:519 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 359, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:53:521 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:53:522 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:53:522 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=240) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:53:522 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:53:522 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=240,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 361 to node 0
[12/16/19 14:08:53:523 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:54:028 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 361, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:54:034 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:54:036 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:54:036 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=241) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:54:036 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:54:037 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=241,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 362 to node 0
[12/16/19 14:08:54:039 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:54:541 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 362, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:54:547 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:54:547 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:54:547 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=242) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:54:547 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:54:547 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=242,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 363 to node 0
[12/16/19 14:08:54:548 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:55:049 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 363, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:55:050 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:55:055 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:55:056 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=243) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:55:057 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:55:058 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=243,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 364 to node 0
[12/16/19 14:08:55:072 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:55:574 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 364, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:55:584 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:55:587 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:55:587 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=244) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:55:587 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:55:588 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=244,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 365 to node 0
[12/16/19 14:08:55:592 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:56:067 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:56:067 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 366 to node 2147483647
[12/16/19 14:08:56:068 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:56:069 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 366, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:56:069 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:56:069 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:56:070 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:56:092 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 365, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:56:092 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:56:096 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:56:097 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=245) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:56:097 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:56:104 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=245,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 367 to node 0
[12/16/19 14:08:56:107 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:56:609 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 367, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:56:612 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:56:613 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:56:613 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=246) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:56:613 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:56:613 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=246,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 368 to node 0
[12/16/19 14:08:56:616 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:57:115 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 368, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:57:118 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:57:119 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:57:119 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=247) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:57:119 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:57:119 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=247,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 369 to node 0
[12/16/19 14:08:57:119 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:57:622 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 369, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:57:631 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:57:634 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:57:635 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=248) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:57:637 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:57:638 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=248,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 370 to node 0
[12/16/19 14:08:57:639 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:58:142 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 370, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:58:146 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:58:146 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:58:146 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=249) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:58:146 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:58:147 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=249,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 371 to node 0
[12/16/19 14:08:58:147 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:58:690 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 371, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:58:692 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:58:694 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:58:694 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=250) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:58:695 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:58:696 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=250,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 372 to node 0
[12/16/19 14:08:58:697 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:59:069 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:08:59:069 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 373 to node 2147483647
[12/16/19 14:08:59:070 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:59:071 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 373, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:08:59:071 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:08:59:071 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:59:071 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:59:199 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 372, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:59:200 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:59:201 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:59:201 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=251) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:59:201 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:59:201 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=251,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 374 to node 0
[12/16/19 14:08:59:202 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:59:702 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 374, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:08:59:704 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:08:59:705 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:59:705 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=252) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:08:59:705 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:59:705 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=252,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 375 to node 0
[12/16/19 14:08:59:706 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:08:59:900 GMT] 000000a8 id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=findAllBrokers, deadlineMs=1576505459900) with a timeout 120000 ms from now.
[12/16/19 14:08:59:905 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:59:905 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=findAllBrokers, deadlineMs=1576505459900)] at 1576505339905
[12/16/19 14:08:59:905 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:59:906 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 leastLoadedNode [AdminClient clientId=adminclient-1] Found least loaded node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) connected with no in-flight requests
[12/16/19 14:08:59:906 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=findAllBrokers, deadlineMs=1576505459900) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:59:906 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=53
[12/16/19 14:08:59:906 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending METADATA {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false} with correlation id 53 to node 0
[12/16/19 14:08:59:907 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=51838)
[12/16/19 14:08:59:907 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:59:908 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505339907
[12/16/19 14:08:59:908 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=51836)
[12/16/19 14:08:59:908 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for METADATA with correlation id 53, received {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:59:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:59:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 1 enqueue [AdminClient clientId=adminclient-1] Queueing Call(callName=listConsumerGroups, deadlineMs=1576505459900) with a timeout 119991 ms from now.
[12/16/19 14:08:59:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=findAllBrokers, deadlineMs=1576505459900) got response {throttle_time_ms=0,brokers=[{node_id=0,host=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local,port=9092,rack=}],cluster_id=7-jItNsIRea8d5lAaxlkjw,controller_id=0,topics=[],cluster_authorized_operations=0}
[12/16/19 14:08:59:909 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [Call(callName=listConsumerGroups, deadlineMs=1576505459900)] at 1576505339909
[12/16/19 14:08:59:909 GMT] 0000004e id=00000000 rg.apache.kafka.clients.admin.internals.AdminMetadataManager 3 isReady [AdminClient clientId=adminclient-1] Metadata is ready to use.
[12/16/19 14:08:59:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCall [AdminClient clientId=adminclient-1] Assigned Call(callName=listConsumerGroups, deadlineMs=1576505459900) to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:08:59:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 sendEligibleCalls [AdminClient clientId=adminclient-1] Sending (type=ListGroupsRequest) to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ). correlationId=54
[12/16/19 14:08:59:910 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [AdminClient clientId=adminclient-1] Sending LIST_GROUPS {} with correlation id 54 to node 0
[12/16/19 14:08:59:910 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=51834)
[12/16/19 14:08:59:914 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 0 response(s)
[12/16/19 14:08:59:914 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505339914
[12/16/19 14:08:59:914 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=51829)
[12/16/19 14:08:59:914 GMT] 0000004e id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [AdminClient clientId=adminclient-1] Completed receive from node 0 for LIST_GROUPS with correlation id 54, received {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:59:914 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] KafkaClient#poll retrieved 1 response(s)
[12/16/19 14:08:59:914 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 handleResponses [AdminClient clientId=adminclient-1] Call(callName=listConsumerGroups, deadlineMs=1576505459900) got response {throttle_time_ms=0,error_code=0,groups=[{group_id=coffeeshop,protocol_type=consumer},{group_id=a7ea90a8-05da-4f5f-914e-fba4d3fe4cc2,protocol_type=consumer},{group_id=baristas,protocol_type=consumer},{group_id=62b76de8-ac52-48d8-91bc-19343dde3266,protocol_type=consumer}]}
[12/16/19 14:08:59:915 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 maybeDrainPendingCalls [AdminClient clientId=adminclient-1] Trying to choose nodes for [] at 1576505339914
[12/16/19 14:08:59:915 GMT] 0000004e id=00000000 che.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable 3 run [AdminClient clientId=adminclient-1] Entering KafkaClient#poll(timeout=51829)
[12/16/19 14:09:00:206 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 375, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:00:207 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:00:207 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:00:208 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=253) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:00:208 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:00:208 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=253,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 376 to node 0
[12/16/19 14:09:00:209 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:00:723 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 376, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:00:723 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:00:733 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:00:733 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=254) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:00:733 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:00:733 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=254,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 377 to node 0
[12/16/19 14:09:00:736 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:01:264 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 377, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:01:264 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:01:265 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:01:266 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=255) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:01:266 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:01:267 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=255,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 378 to node 0
[12/16/19 14:09:01:268 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:01:770 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 378, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:01:777 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:01:779 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:01:779 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=256) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:01:780 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:01:780 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=256,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 379 to node 0
[12/16/19 14:09:01:782 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:02:073 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:09:02:073 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 380 to node 2147483647
[12/16/19 14:09:02:076 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:02:076 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 380, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:09:02:077 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:09:02:078 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:02:079 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:02:281 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 379, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:02:282 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:02:283 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:02:283 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=257) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:02:283 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:02:284 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=257,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 381 to node 0
[12/16/19 14:09:02:285 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:02:785 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 381, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:02:786 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:02:786 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:02:787 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=258) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:02:787 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:02:787 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=258,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 382 to node 0
[12/16/19 14:09:02:787 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:03:287 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 382, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:03:288 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:03:289 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:03:289 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=259) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:03:289 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:03:289 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=259,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 383 to node 0
[12/16/19 14:09:03:290 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:03:790 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 383, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:03:791 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:03:792 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:03:792 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=260) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:03:792 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:03:792 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=260,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 384 to node 0
[12/16/19 14:09:03:793 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:04:296 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 384, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:04:303 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:04:304 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:04:305 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=261) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:04:305 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:04:305 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=261,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 385 to node 0
[12/16/19 14:09:04:316 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:04:814 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 385, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:04:818 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:04:819 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:04:819 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=262) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:04:819 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:04:819 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=262,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 386 to node 0
[12/16/19 14:09:04:820 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:05:074 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:09:05:074 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 387 to node 2147483647
[12/16/19 14:09:05:076 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:05:076 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 387, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:09:05:077 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:09:05:077 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:05:077 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:05:320 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 386, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:05:333 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:05:334 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:05:334 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=263) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:05:334 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:05:334 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=263,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 388 to node 0
[12/16/19 14:09:05:335 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:05:843 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 388, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:05:845 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:05:847 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:05:847 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=264) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:05:847 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:05:847 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=264,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 389 to node 0
[12/16/19 14:09:05:849 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:06:350 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 389, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:06:352 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:06:353 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:06:353 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=265) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:06:353 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:06:353 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=265,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 390 to node 0
[12/16/19 14:09:06:353 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:06:855 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 390, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:06:864 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:06:865 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:06:866 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=266) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:06:866 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:06:867 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=266,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 391 to node 0
[12/16/19 14:09:06:867 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:07:369 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 391, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:07:372 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:07:372 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:07:373 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=267) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:07:373 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:07:374 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=267,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 392 to node 0
[12/16/19 14:09:07:375 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:07:876 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 392, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:07:879 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:07:880 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:07:880 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=268) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:07:881 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:07:882 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=268,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 393 to node 0
[12/16/19 14:09:07:883 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:08:076 GMT] 0000004d id=00000000 .apache.kafka.clients.consumer.internals.AbstractCoordinator 1 sendHeartbeatRequest [Consumer clientId=consumer-1, groupId=baristas] Sending Heartbeat request to coordinator my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 2147483647 rack: null)
[12/16/19 14:09:08:076 GMT] 0000004d id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending HEARTBEAT {group_id=baristas,generation_id=117,member_id=consumer-1-f368bf97-a433-4cfe-9a2d-441f7300a693,group_instance_id=null} with correlation id 394 to node 2147483647
[12/16/19 14:09:08:078 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:08:078 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 2147483647 for HEARTBEAT with correlation id 394, received {throttle_time_ms=0,error_code=0}
[12/16/19 14:09:08:079 GMT] 0000007f id=00000000 sumer.internals.AbstractCoordinator$HeartbeatResponseHandler 1 handle [Consumer clientId=consumer-1, groupId=baristas] Received successful Heartbeat response
[12/16/19 14:09:08:079 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:08:080 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:08:384 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 393, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:08:385 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:08:385 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:08:385 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=269) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:08:385 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:08:385 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=269,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 395 to node 0
[12/16/19 14:09:08:386 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:08:886 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 395, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:08:886 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:08:887 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:08:887 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=270) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:08:887 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:08:887 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=270,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 396 to node 0
[12/16/19 14:09:08:887 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
[12/16/19 14:09:09:389 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 handleCompletedReceives [Consumer clientId=consumer-1, groupId=baristas] Completed receive from node 0 for FETCH with correlation id 396, received {throttle_time_ms=0,error_code=0,session_id=425357323,responses=[]}
[12/16/19 14:09:09:390 GMT] 0000004d id=00000000 org.apache.kafka.clients.FetchSessionHandler                 1 handleResponse [Consumer clientId=consumer-1, groupId=baristas] Node 0 sent an incremental fetch response for session 425357323 with response=(), implied=(orders-4)
[12/16/19 14:09:09:390 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Added READ_UNCOMMITTED fetch request for partition orders-4 at position FetchPosition{offset=267, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ), epoch=0}} to node my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:09:390 GMT] 0000007f id=00000000 org.apache.kafka.clients.FetchSessionHandler$Builder         1 build [Consumer clientId=consumer-1, groupId=baristas] Built incremental fetch (sessionId=425357323, epoch=271) for node 0. Added (), altered (), removed () out of (orders-4)
[12/16/19 14:09:09:390 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          1 sendFetches [Consumer clientId=consumer-1, groupId=baristas] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(orders-4)) to broker my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: )
[12/16/19 14:09:09:391 GMT] 0000007f id=00000000 org.apache.kafka.clients.NetworkClient                       3 doSend [Consumer clientId=consumer-1, groupId=baristas] Sending FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=425357323,session_epoch=271,topics=[],forgotten_topics_data=[],rack_id=} with correlation id 397 to node 0
[12/16/19 14:09:09:391 GMT] 0000007f id=00000000 org.apache.kafka.clients.consumer.internals.Fetcher          3 prepareFetchRequests [Consumer clientId=consumer-1, groupId=baristas] Skipping fetch for partition orders-4 because previous request to my-cluster-kafka-0.my-cluster-kafka-brokers.kafka.svc.cluster.local:9092 (id: 0 rack: ) has not been processed
